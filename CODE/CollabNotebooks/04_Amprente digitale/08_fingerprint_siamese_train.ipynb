{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNEOpaq1cS6sfTKi7Sqm7aK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"ihTYFhOkPzaF","executionInfo":{"status":"ok","timestamp":1747436371905,"user_tz":-180,"elapsed":4,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import os\n","import random\n","from PIL import Image\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","\n","import os\n","import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import argparse\n","from tqdm import tqdm"]},{"cell_type":"code","source":["class FingerprintDataset(Dataset):\n","    def __init__(self, data_dir, input_size=(105, 105)):\n","        self.data_dir = data_dir\n","        self.image_paths = []\n","        self.input_size = input_size\n","\n","        # Collect all image paths\n","        for class_dir in os.listdir(data_dir):\n","            class_path = os.path.join(data_dir, class_dir)\n","            if os.path.isdir(class_path):\n","                for image_name in os.listdir(class_path):\n","                    self.image_paths.append(os.path.join(class_path, image_name))\n","\n","        # Define two different transform pipelines\n","        self.transform1 = transforms.Compose([\n","            transforms.Grayscale(num_output_channels=1),\n","            transforms.Resize(self.input_size),\n","            transforms.RandomRotation(10),\n","            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5], std=[0.5])\n","        ])\n","\n","        self.transform2 = transforms.Compose([\n","            transforms.Grayscale(num_output_channels=1),\n","            transforms.Resize(self.input_size),\n","            transforms.RandomRotation(10),\n","            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5], std=[0.5])\n","        ])\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img1_path = self.image_paths[idx]\n","        img1 = Image.open(img1_path).convert('RGB')\n","\n","        is_positive = random.choice([True, False])\n","\n","        if is_positive:\n","            img2_path = img1_path\n","            img2 = Image.open(img2_path).convert('RGB')\n","\n","            # Apply different augmentations for each image in the same pair\n","            img1 = self.transform1(img1)\n","            img2 = self.transform2(img2)\n","        else:\n","            img2_path = random.choice(self.image_paths)\n","            while img2_path == img1_path:\n","                img2_path = random.choice(self.image_paths)\n","            img2 = Image.open(img2_path).convert('RGB')\n","\n","            img1 = self.transform1(img1)\n","            img2 = self.transform2(img2)\n","\n","        return img1, img2, int(is_positive)"],"metadata":{"id":"RUMiaswCRmXM","executionInfo":{"status":"ok","timestamp":1747436376663,"user_tz":-180,"elapsed":53,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class SiameseNetwork(nn.Module):\n","    def __init__(self, embedding_dim=256):\n","        super(SiameseNetwork, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=7),  # Output: [64, 99, 99]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),                 # -> [64, 49, 49]\n","\n","            nn.Conv2d(64, 128, kernel_size=5),  # -> [128, 45, 45]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),                   # -> [128, 22, 22]\n","\n","            nn.Conv2d(128, 128, kernel_size=3),  # -> [128, 20, 20]\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)                     # -> [128, 10, 10]\n","        )\n","\n","        self.fc = nn.Sequential(\n","            nn.Linear(128 * 10 * 10, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, embedding_dim)  # Final output is the embedding\n","        )\n","\n","    def forward_one(self, x):\n","        x = self.conv(x)\n","        x = torch.flatten(x, 1)\n","        x = self.fc(x)\n","        return x\n","\n","    def forward(self, input1, input2):\n","        output1 = self.forward_one(input1)\n","        output2 = self.forward_one(input2)\n","        return output1, output2"],"metadata":{"id":"ep_TBIzBQG6D","executionInfo":{"status":"ok","timestamp":1747436381145,"user_tz":-180,"elapsed":11,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class ContrastiveLoss(nn.Module):\n","    def __init__(self, margin=50.0, reduction='mean'):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","        self.reduction = reduction\n","\n","    def forward(self, output1, output2, label):\n","        # Ensure label is float for proper math\n","        label = label.float()\n","\n","        euclidean_distance = F.pairwise_distance(output1, output2)\n","        positive_loss = label * torch.pow(euclidean_distance, 2)\n","        negative_loss = (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n","        loss = 0.5 * (positive_loss + negative_loss)\n","\n","        if self.reduction == 'mean':\n","            return loss.mean()\n","        elif self.reduction == 'sum':\n","            return loss.sum()\n","        else:\n","            return loss  # no reduction\n"],"metadata":{"id":"-zVDv8FFRs86","executionInfo":{"status":"ok","timestamp":1747436384956,"user_tz":-180,"elapsed":3,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train(input_directory, model_file, embedding_size, num_epochs, batch_size, learning_rate):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","    train_dataset = FingerprintDataset(input_directory)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    model = SiameseNetwork(embedding_dim=embedding_size).to(device)\n","    loss_function = ContrastiveLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    min_loss = float('inf')  # Set to infinity initially\n","\n","# Training loop\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0.0\n","\n","        for batch_idx, (img1, img2, label) in enumerate(train_loader, start=1):  # Use enumerate to get batch index\n","            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n","            optimizer.zero_grad()\n","            output1, output2 = model(img1, img2)\n","            loss = loss_function(output1, output2, label)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","            print(f\"Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item()}\")  # Include batch number\n","\n","        epoch_loss = total_loss / len(train_loader)\n","        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}')\n","\n","        # Save the model checkpoint for the current epoch\n","        # torch.save(model.state_dict(), f'siamese_model_epoch_{epoch+1}.pth')\n","\n","        # Check if this is the minimum loss so far\n","        if epoch_loss < min_loss:\n","            min_loss = epoch_loss\n","            torch.save(model.state_dict(), model_file)  # Save the model with minimum loss\n","            print(f\"New minimum loss achieved: {min_loss}. Model saved as 'siamese_model_min_loss.pth'.\")\n","\n","    print(\"Training finished!\")\n"],"metadata":{"id":"gNuRpUxLSemy","executionInfo":{"status":"ok","timestamp":1747436853489,"user_tz":-180,"elapsed":42,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DzC4aZOkVF0O","executionInfo":{"status":"ok","timestamp":1747436496308,"user_tz":-180,"elapsed":32044,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"be6549fd-e5a9-49ab-be7f-202817309f77"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["input_directory = '/content/drive/MyDrive/Facultate Informatica/Profesor/2024-2025/Sisteme expert si metode biometrice in securitatea informatiei/Curs/ColabMount/DATA/NISTDB4_RAW/train_set'\n","model_file = '/content/drive/MyDrive/Facultate Informatica/Profesor/2024-2025/Sisteme expert si metode biometrice in securitatea informatiei/Curs/ColabMount/Models/model_fingerprints.pth'\n","embedding_size = 128\n","epochs = 50\n","batch_size = 16\n","learning_rate = 0.0001"],"metadata":{"id":"v53ZncsbSm-p","executionInfo":{"status":"ok","timestamp":1747436858879,"user_tz":-180,"elapsed":2,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train(input_directory, model_file, embedding_size, epochs, batch_size, learning_rate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnX_czMVShms","executionInfo":{"status":"ok","timestamp":1747437949649,"user_tz":-180,"elapsed":1086185,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"d3ee503c-cbb6-474e-b540-9ed33166443a"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","Batch [1/105] Loss: 44.66823959350586\n","Batch [2/105] Loss: 14.511571884155273\n","Batch [3/105] Loss: 51.18972396850586\n","Batch [4/105] Loss: 31.339542388916016\n","Batch [5/105] Loss: 33.11433792114258\n","Batch [6/105] Loss: 29.36878204345703\n","Batch [7/105] Loss: 17.933698654174805\n","Batch [8/105] Loss: 55.77229309082031\n","Batch [9/105] Loss: 22.054370880126953\n","Batch [10/105] Loss: 70.9734878540039\n","Batch [11/105] Loss: 100.42759704589844\n","Batch [12/105] Loss: 27.30337142944336\n","Batch [13/105] Loss: 36.618385314941406\n","Batch [14/105] Loss: 29.474803924560547\n","Batch [15/105] Loss: 51.8868408203125\n","Batch [16/105] Loss: 33.62506866455078\n","Batch [17/105] Loss: 36.52508544921875\n","Batch [18/105] Loss: 75.40165710449219\n","Batch [19/105] Loss: 28.508760452270508\n","Batch [20/105] Loss: 31.573711395263672\n","Batch [21/105] Loss: 30.55251693725586\n","Batch [22/105] Loss: 12.240350723266602\n","Batch [23/105] Loss: 21.898818969726562\n","Batch [24/105] Loss: 41.615867614746094\n","Batch [25/105] Loss: 47.47239685058594\n","Batch [26/105] Loss: 48.475059509277344\n","Batch [27/105] Loss: 46.053009033203125\n","Batch [28/105] Loss: 85.67451477050781\n","Batch [29/105] Loss: 67.89408874511719\n","Batch [30/105] Loss: 75.07713317871094\n","Batch [31/105] Loss: 39.949005126953125\n","Batch [32/105] Loss: 49.68862533569336\n","Batch [33/105] Loss: 10.003270149230957\n","Batch [34/105] Loss: 28.884782791137695\n","Batch [35/105] Loss: 8.664230346679688\n","Batch [36/105] Loss: 64.75503540039062\n","Batch [37/105] Loss: 53.82664489746094\n","Batch [38/105] Loss: 4.118349552154541\n","Batch [39/105] Loss: 30.480846405029297\n","Batch [40/105] Loss: 81.41173553466797\n","Batch [41/105] Loss: 32.29798126220703\n","Batch [42/105] Loss: 76.21673583984375\n","Batch [43/105] Loss: 35.357513427734375\n","Batch [44/105] Loss: 9.428786277770996\n","Batch [45/105] Loss: 108.42288208007812\n","Batch [46/105] Loss: 42.471580505371094\n","Batch [47/105] Loss: 75.27494812011719\n","Batch [48/105] Loss: 13.614638328552246\n","Batch [49/105] Loss: 19.42929458618164\n","Batch [50/105] Loss: 33.53825378417969\n","Batch [51/105] Loss: 16.441165924072266\n","Batch [52/105] Loss: 70.38841247558594\n","Batch [53/105] Loss: 11.72143840789795\n","Batch [54/105] Loss: 41.779422760009766\n","Batch [55/105] Loss: 48.65375900268555\n","Batch [56/105] Loss: 70.494384765625\n","Batch [57/105] Loss: 51.27812194824219\n","Batch [58/105] Loss: 66.91059875488281\n","Batch [59/105] Loss: 60.8187141418457\n","Batch [60/105] Loss: 33.40752410888672\n","Batch [61/105] Loss: 18.040637969970703\n","Batch [62/105] Loss: 44.82288360595703\n","Batch [63/105] Loss: 14.737317085266113\n","Batch [64/105] Loss: 50.09199905395508\n","Batch [65/105] Loss: 77.85908508300781\n","Batch [66/105] Loss: 29.490520477294922\n","Batch [67/105] Loss: 9.25115966796875\n","Batch [68/105] Loss: 22.08584976196289\n","Batch [69/105] Loss: 39.38822937011719\n","Batch [70/105] Loss: 18.09317398071289\n","Batch [71/105] Loss: 25.726526260375977\n","Batch [72/105] Loss: 53.44538497924805\n","Batch [73/105] Loss: 37.206024169921875\n","Batch [74/105] Loss: 48.02650833129883\n","Batch [75/105] Loss: 48.06798553466797\n","Batch [76/105] Loss: 60.38301086425781\n","Batch [77/105] Loss: 20.814208984375\n","Batch [78/105] Loss: 33.64735794067383\n","Batch [79/105] Loss: 42.34615707397461\n","Batch [80/105] Loss: 13.2155179977417\n","Batch [81/105] Loss: 13.02426528930664\n","Batch [82/105] Loss: 48.464691162109375\n","Batch [83/105] Loss: 62.50297164916992\n","Batch [84/105] Loss: 25.91701889038086\n","Batch [85/105] Loss: 14.906147956848145\n","Batch [86/105] Loss: 30.48891830444336\n","Batch [87/105] Loss: 10.830657958984375\n","Batch [88/105] Loss: 95.03865051269531\n","Batch [89/105] Loss: 49.163455963134766\n","Batch [90/105] Loss: 12.866207122802734\n","Batch [91/105] Loss: 67.69204711914062\n","Batch [92/105] Loss: 28.823631286621094\n","Batch [93/105] Loss: 14.188121795654297\n","Batch [94/105] Loss: 26.74104118347168\n","Batch [95/105] Loss: 53.86056137084961\n","Batch [96/105] Loss: 51.9140739440918\n","Batch [97/105] Loss: 104.02525329589844\n","Batch [98/105] Loss: 72.79987335205078\n","Batch [99/105] Loss: 22.894947052001953\n","Batch [100/105] Loss: 50.23169708251953\n","Batch [101/105] Loss: 65.17583465576172\n","Batch [102/105] Loss: 74.80648040771484\n","Batch [103/105] Loss: 40.289825439453125\n","Batch [104/105] Loss: 73.15753173828125\n","Batch [105/105] Loss: 33.67374801635742\n","Epoch [4/50], Loss: 42.27781865710304\n","New minimum loss achieved: 42.27781865710304. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 47.59773635864258\n","Batch [2/105] Loss: 32.2191276550293\n","Batch [3/105] Loss: 19.258872985839844\n","Batch [4/105] Loss: 39.42416763305664\n","Batch [5/105] Loss: 37.493446350097656\n","Batch [6/105] Loss: 15.83110237121582\n","Batch [7/105] Loss: 46.602783203125\n","Batch [8/105] Loss: 70.74296569824219\n","Batch [9/105] Loss: 15.591729164123535\n","Batch [10/105] Loss: 50.20391845703125\n","Batch [11/105] Loss: 83.17524719238281\n","Batch [12/105] Loss: 31.273555755615234\n","Batch [13/105] Loss: 32.863670349121094\n","Batch [14/105] Loss: 26.00541877746582\n","Batch [15/105] Loss: 28.564952850341797\n","Batch [16/105] Loss: 23.08831214904785\n","Batch [17/105] Loss: 84.35311126708984\n","Batch [18/105] Loss: 94.71028900146484\n","Batch [19/105] Loss: 53.671669006347656\n","Batch [20/105] Loss: 25.81391716003418\n","Batch [21/105] Loss: 63.9916877746582\n","Batch [22/105] Loss: 77.62714385986328\n","Batch [23/105] Loss: 68.65507507324219\n","Batch [24/105] Loss: 60.38819122314453\n","Batch [25/105] Loss: 29.56841278076172\n","Batch [26/105] Loss: 48.29302215576172\n","Batch [27/105] Loss: 45.21200180053711\n","Batch [28/105] Loss: 49.25300598144531\n","Batch [29/105] Loss: 43.21382522583008\n","Batch [30/105] Loss: 81.40167236328125\n","Batch [31/105] Loss: 25.90109634399414\n","Batch [32/105] Loss: 47.54290771484375\n","Batch [33/105] Loss: 25.584550857543945\n","Batch [34/105] Loss: 43.68580627441406\n","Batch [35/105] Loss: 47.31159973144531\n","Batch [36/105] Loss: 59.333274841308594\n","Batch [37/105] Loss: 30.72777557373047\n","Batch [38/105] Loss: 7.829951763153076\n","Batch [39/105] Loss: 87.18543243408203\n","Batch [40/105] Loss: 67.74842071533203\n","Batch [41/105] Loss: 86.22952270507812\n","Batch [42/105] Loss: 80.26950073242188\n","Batch [43/105] Loss: 84.9173355102539\n","Batch [44/105] Loss: 16.799945831298828\n","Batch [45/105] Loss: 54.648231506347656\n","Batch [46/105] Loss: 28.855680465698242\n","Batch [47/105] Loss: 91.1014404296875\n","Batch [48/105] Loss: 61.83016586303711\n","Batch [49/105] Loss: 96.42803955078125\n","Batch [50/105] Loss: 46.38555908203125\n","Batch [51/105] Loss: 47.67820358276367\n","Batch [52/105] Loss: 53.69491958618164\n","Batch [53/105] Loss: 82.02959442138672\n","Batch [54/105] Loss: 8.546499252319336\n","Batch [55/105] Loss: 65.58059692382812\n","Batch [56/105] Loss: 57.56682586669922\n","Batch [57/105] Loss: 32.27558135986328\n","Batch [58/105] Loss: 32.97441864013672\n","Batch [59/105] Loss: 61.219207763671875\n","Batch [60/105] Loss: 27.648136138916016\n","Batch [61/105] Loss: 38.555816650390625\n","Batch [62/105] Loss: 24.035865783691406\n","Batch [63/105] Loss: 46.64415740966797\n","Batch [64/105] Loss: 46.87731170654297\n","Batch [65/105] Loss: 21.280906677246094\n","Batch [66/105] Loss: 66.57122802734375\n","Batch [67/105] Loss: 61.57754135131836\n","Batch [68/105] Loss: 52.933265686035156\n","Batch [69/105] Loss: 33.63014221191406\n","Batch [70/105] Loss: 5.497045993804932\n","Batch [71/105] Loss: 25.4739990234375\n","Batch [72/105] Loss: 53.654876708984375\n","Batch [73/105] Loss: 32.02946090698242\n","Batch [74/105] Loss: 75.87198638916016\n","Batch [75/105] Loss: 28.53096580505371\n","Batch [76/105] Loss: 104.55353546142578\n","Batch [77/105] Loss: 32.00880813598633\n","Batch [78/105] Loss: 49.25782775878906\n","Batch [79/105] Loss: 63.134220123291016\n","Batch [80/105] Loss: 50.003868103027344\n","Batch [81/105] Loss: 39.8099365234375\n","Batch [82/105] Loss: 4.6672444343566895\n","Batch [83/105] Loss: 24.767353057861328\n","Batch [84/105] Loss: 39.90997314453125\n","Batch [85/105] Loss: 19.33890151977539\n","Batch [86/105] Loss: 31.220680236816406\n","Batch [87/105] Loss: 43.65715789794922\n","Batch [88/105] Loss: 35.16142654418945\n","Batch [89/105] Loss: 26.569297790527344\n","Batch [90/105] Loss: 22.47112274169922\n","Batch [91/105] Loss: 63.35976791381836\n","Batch [92/105] Loss: 22.335487365722656\n","Batch [93/105] Loss: 29.755481719970703\n","Batch [94/105] Loss: 23.063838958740234\n","Batch [95/105] Loss: 45.1861457824707\n","Batch [96/105] Loss: 52.81818389892578\n","Batch [97/105] Loss: 22.739774703979492\n","Batch [98/105] Loss: 33.68456268310547\n","Batch [99/105] Loss: 50.13792037963867\n","Batch [100/105] Loss: 106.64649200439453\n","Batch [101/105] Loss: 27.036258697509766\n","Batch [102/105] Loss: 15.843465805053711\n","Batch [103/105] Loss: 9.319550514221191\n","Batch [104/105] Loss: 18.979747772216797\n","Batch [105/105] Loss: 31.573345184326172\n","Epoch [5/50], Loss: 45.12186857405163\n","Batch [1/105] Loss: 30.95466423034668\n","Batch [2/105] Loss: 67.97066497802734\n","Batch [3/105] Loss: 18.8765926361084\n","Batch [4/105] Loss: 76.93177795410156\n","Batch [5/105] Loss: 9.120195388793945\n","Batch [6/105] Loss: 20.252647399902344\n","Batch [7/105] Loss: 57.094486236572266\n","Batch [8/105] Loss: 42.14939880371094\n","Batch [9/105] Loss: 20.12994956970215\n","Batch [10/105] Loss: 48.085235595703125\n","Batch [11/105] Loss: 15.039867401123047\n","Batch [12/105] Loss: 54.29772186279297\n","Batch [13/105] Loss: 33.66878128051758\n","Batch [14/105] Loss: 76.64514923095703\n","Batch [15/105] Loss: 41.772003173828125\n","Batch [16/105] Loss: 42.10055160522461\n","Batch [17/105] Loss: 45.38141632080078\n","Batch [18/105] Loss: 22.060497283935547\n","Batch [19/105] Loss: 27.50911521911621\n","Batch [20/105] Loss: 15.130659103393555\n","Batch [21/105] Loss: 34.14313888549805\n","Batch [22/105] Loss: 41.91703796386719\n","Batch [23/105] Loss: 11.546260833740234\n","Batch [24/105] Loss: 78.16342163085938\n","Batch [25/105] Loss: 48.616676330566406\n","Batch [26/105] Loss: 49.28913116455078\n","Batch [27/105] Loss: 57.30066680908203\n","Batch [28/105] Loss: 41.36210632324219\n","Batch [29/105] Loss: 20.858644485473633\n","Batch [30/105] Loss: 26.537424087524414\n","Batch [31/105] Loss: 23.42495346069336\n","Batch [32/105] Loss: 28.630977630615234\n","Batch [33/105] Loss: 27.49386215209961\n","Batch [34/105] Loss: 56.02035140991211\n","Batch [35/105] Loss: 22.184078216552734\n","Batch [36/105] Loss: 71.59893798828125\n","Batch [37/105] Loss: 34.33776092529297\n","Batch [38/105] Loss: 47.34467315673828\n","Batch [39/105] Loss: 19.11744499206543\n","Batch [40/105] Loss: 18.277095794677734\n","Batch [41/105] Loss: 37.5729866027832\n","Batch [42/105] Loss: 94.05789184570312\n","Batch [43/105] Loss: 40.88421630859375\n","Batch [44/105] Loss: 16.964889526367188\n","Batch [45/105] Loss: 10.983633995056152\n","Batch [46/105] Loss: 25.992862701416016\n","Batch [47/105] Loss: 28.902999877929688\n","Batch [48/105] Loss: 54.227821350097656\n","Batch [49/105] Loss: 38.13393783569336\n","Batch [50/105] Loss: 47.77092742919922\n","Batch [51/105] Loss: 45.66542053222656\n","Batch [52/105] Loss: 75.48668670654297\n","Batch [53/105] Loss: 72.14505004882812\n","Batch [54/105] Loss: 27.309768676757812\n","Batch [55/105] Loss: 30.125974655151367\n","Batch [56/105] Loss: 35.29307556152344\n","Batch [57/105] Loss: 30.202373504638672\n","Batch [58/105] Loss: 25.40658950805664\n","Batch [59/105] Loss: 18.12496566772461\n","Batch [60/105] Loss: 15.250801086425781\n","Batch [61/105] Loss: 29.969682693481445\n","Batch [62/105] Loss: 26.406404495239258\n","Batch [63/105] Loss: 33.87291717529297\n","Batch [64/105] Loss: 32.87516784667969\n","Batch [65/105] Loss: 13.65553092956543\n","Batch [66/105] Loss: 36.53012466430664\n","Batch [67/105] Loss: 73.29811096191406\n","Batch [68/105] Loss: 56.14488983154297\n","Batch [69/105] Loss: 66.65065002441406\n","Batch [70/105] Loss: 36.37188720703125\n","Batch [71/105] Loss: 24.356555938720703\n","Batch [72/105] Loss: 67.7112808227539\n","Batch [73/105] Loss: 23.854185104370117\n","Batch [74/105] Loss: 54.956092834472656\n","Batch [75/105] Loss: 48.59349060058594\n","Batch [76/105] Loss: 22.032569885253906\n","Batch [77/105] Loss: 17.534040451049805\n","Batch [78/105] Loss: 33.092437744140625\n","Batch [79/105] Loss: 29.5620174407959\n","Batch [80/105] Loss: 28.480493545532227\n","Batch [81/105] Loss: 28.87769889831543\n","Batch [82/105] Loss: 68.96943664550781\n","Batch [83/105] Loss: 20.280391693115234\n","Batch [84/105] Loss: 35.85688018798828\n","Batch [85/105] Loss: 54.59421920776367\n","Batch [86/105] Loss: 75.04827117919922\n","Batch [87/105] Loss: 26.134334564208984\n","Batch [88/105] Loss: 61.72257614135742\n","Batch [89/105] Loss: 20.056503295898438\n","Batch [90/105] Loss: 33.76792907714844\n","Batch [91/105] Loss: 75.81130981445312\n","Batch [92/105] Loss: 49.72246551513672\n","Batch [93/105] Loss: 58.132606506347656\n","Batch [94/105] Loss: 38.776615142822266\n","Batch [95/105] Loss: 30.43994140625\n","Batch [96/105] Loss: 39.368614196777344\n","Batch [97/105] Loss: 59.693336486816406\n","Batch [98/105] Loss: 28.29666519165039\n","Batch [99/105] Loss: 22.06795883178711\n","Batch [100/105] Loss: 66.2565689086914\n","Batch [101/105] Loss: 17.211225509643555\n","Batch [102/105] Loss: 2.338505506515503\n","Batch [103/105] Loss: 36.81951904296875\n","Batch [104/105] Loss: 46.80636978149414\n","Batch [105/105] Loss: 84.5818099975586\n","Epoch [6/50], Loss: 39.34684929393587\n","New minimum loss achieved: 39.34684929393587. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 23.3414306640625\n","Batch [2/105] Loss: 46.15404510498047\n","Batch [3/105] Loss: 56.56667709350586\n","Batch [4/105] Loss: 34.57252502441406\n","Batch [5/105] Loss: 33.1796989440918\n","Batch [6/105] Loss: 39.02091598510742\n","Batch [7/105] Loss: 54.993614196777344\n","Batch [8/105] Loss: 96.79759216308594\n","Batch [9/105] Loss: 38.831600189208984\n","Batch [10/105] Loss: 6.927828788757324\n","Batch [11/105] Loss: 25.09244155883789\n","Batch [12/105] Loss: 41.98588943481445\n","Batch [13/105] Loss: 75.3161392211914\n","Batch [14/105] Loss: 99.1533432006836\n","Batch [15/105] Loss: 17.925979614257812\n","Batch [16/105] Loss: 13.908109664916992\n","Batch [17/105] Loss: 123.5466079711914\n","Batch [18/105] Loss: 26.054988861083984\n","Batch [19/105] Loss: 39.20930480957031\n","Batch [20/105] Loss: 37.68928527832031\n","Batch [21/105] Loss: 20.57782745361328\n","Batch [22/105] Loss: 43.48542404174805\n","Batch [23/105] Loss: 22.75137710571289\n","Batch [24/105] Loss: 33.25402069091797\n","Batch [25/105] Loss: 26.152565002441406\n","Batch [26/105] Loss: 46.10443878173828\n","Batch [27/105] Loss: 29.94820785522461\n","Batch [28/105] Loss: 27.337657928466797\n","Batch [29/105] Loss: 30.905258178710938\n","Batch [30/105] Loss: 17.228378295898438\n","Batch [31/105] Loss: 87.80393981933594\n","Batch [32/105] Loss: 39.05952072143555\n","Batch [33/105] Loss: 39.794281005859375\n","Batch [34/105] Loss: 10.976160049438477\n","Batch [35/105] Loss: 24.329883575439453\n","Batch [36/105] Loss: 98.06974029541016\n","Batch [37/105] Loss: 12.041299819946289\n","Batch [38/105] Loss: 22.411651611328125\n","Batch [39/105] Loss: 67.67119598388672\n","Batch [40/105] Loss: 14.088011741638184\n","Batch [41/105] Loss: 23.29973602294922\n","Batch [42/105] Loss: 13.747188568115234\n","Batch [43/105] Loss: 13.871288299560547\n","Batch [44/105] Loss: 31.743772506713867\n","Batch [45/105] Loss: 12.035734176635742\n","Batch [46/105] Loss: 15.71082878112793\n","Batch [47/105] Loss: 13.245509147644043\n","Batch [48/105] Loss: 89.85044860839844\n","Batch [49/105] Loss: 43.27275085449219\n","Batch [50/105] Loss: 42.53386688232422\n","Batch [51/105] Loss: 14.864042282104492\n","Batch [52/105] Loss: 54.75218200683594\n","Batch [53/105] Loss: 14.394831657409668\n","Batch [54/105] Loss: 78.1919174194336\n","Batch [55/105] Loss: 36.01730728149414\n","Batch [56/105] Loss: 8.436768531799316\n","Batch [57/105] Loss: 54.011436462402344\n","Batch [58/105] Loss: 55.04857635498047\n","Batch [59/105] Loss: 27.809200286865234\n","Batch [60/105] Loss: 113.81610107421875\n","Batch [61/105] Loss: 26.09308624267578\n","Batch [62/105] Loss: 56.814453125\n","Batch [63/105] Loss: 27.89223861694336\n","Batch [64/105] Loss: 77.408935546875\n","Batch [65/105] Loss: 12.013870239257812\n","Batch [66/105] Loss: 49.50514602661133\n","Batch [67/105] Loss: 50.73141098022461\n","Batch [68/105] Loss: 34.31621170043945\n","Batch [69/105] Loss: 76.48052978515625\n","Batch [70/105] Loss: 9.899101257324219\n","Batch [71/105] Loss: 48.36951446533203\n","Batch [72/105] Loss: 14.035721778869629\n","Batch [73/105] Loss: 10.835241317749023\n","Batch [74/105] Loss: 15.162217140197754\n","Batch [75/105] Loss: 29.085689544677734\n","Batch [76/105] Loss: 47.67681884765625\n","Batch [77/105] Loss: 50.86552429199219\n","Batch [78/105] Loss: 16.922706604003906\n","Batch [79/105] Loss: 28.525104522705078\n","Batch [80/105] Loss: 42.14717102050781\n","Batch [81/105] Loss: 46.495697021484375\n","Batch [82/105] Loss: 39.14059829711914\n","Batch [83/105] Loss: 64.77024841308594\n","Batch [84/105] Loss: 41.30139923095703\n","Batch [85/105] Loss: 25.826202392578125\n","Batch [86/105] Loss: 15.245484352111816\n","Batch [87/105] Loss: 30.233510971069336\n","Batch [88/105] Loss: 23.56937599182129\n","Batch [89/105] Loss: 15.42067813873291\n","Batch [90/105] Loss: 47.47950744628906\n","Batch [91/105] Loss: 64.21392059326172\n","Batch [92/105] Loss: 7.659000396728516\n","Batch [93/105] Loss: 9.285661697387695\n","Batch [94/105] Loss: 17.010780334472656\n","Batch [95/105] Loss: 26.086334228515625\n","Batch [96/105] Loss: 59.100372314453125\n","Batch [97/105] Loss: 13.753833770751953\n","Batch [98/105] Loss: 25.205936431884766\n","Batch [99/105] Loss: 17.977174758911133\n","Batch [100/105] Loss: 42.21685791015625\n","Batch [101/105] Loss: 16.595741271972656\n","Batch [102/105] Loss: 78.06423950195312\n","Batch [103/105] Loss: 24.47896957397461\n","Batch [104/105] Loss: 12.587566375732422\n","Batch [105/105] Loss: 12.392860412597656\n","Epoch [7/50], Loss: 37.16004752204532\n","New minimum loss achieved: 37.16004752204532. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 11.024129867553711\n","Batch [2/105] Loss: 36.60124969482422\n","Batch [3/105] Loss: 23.21436309814453\n","Batch [4/105] Loss: 42.11821746826172\n","Batch [5/105] Loss: 19.329015731811523\n","Batch [6/105] Loss: 76.24391174316406\n","Batch [7/105] Loss: 5.965427398681641\n","Batch [8/105] Loss: 20.555580139160156\n","Batch [9/105] Loss: 56.232059478759766\n","Batch [10/105] Loss: 22.895641326904297\n","Batch [11/105] Loss: 10.782222747802734\n","Batch [12/105] Loss: 14.61688232421875\n","Batch [13/105] Loss: 28.244613647460938\n","Batch [14/105] Loss: 30.46026611328125\n","Batch [15/105] Loss: 12.575101852416992\n","Batch [16/105] Loss: 51.81342697143555\n","Batch [17/105] Loss: 26.872299194335938\n","Batch [18/105] Loss: 20.489057540893555\n","Batch [19/105] Loss: 29.20589828491211\n","Batch [20/105] Loss: 33.1039924621582\n","Batch [21/105] Loss: 92.77063751220703\n","Batch [22/105] Loss: 72.79275512695312\n","Batch [23/105] Loss: 17.61088752746582\n","Batch [24/105] Loss: 36.309104919433594\n","Batch [25/105] Loss: 29.43534278869629\n","Batch [26/105] Loss: 22.340187072753906\n","Batch [27/105] Loss: 14.034122467041016\n","Batch [28/105] Loss: 25.431909561157227\n","Batch [29/105] Loss: 75.82037353515625\n","Batch [30/105] Loss: 37.20433807373047\n","Batch [31/105] Loss: 26.518146514892578\n","Batch [32/105] Loss: 40.011940002441406\n","Batch [33/105] Loss: 40.139244079589844\n","Batch [34/105] Loss: 17.981122970581055\n","Batch [35/105] Loss: 33.84164810180664\n","Batch [36/105] Loss: 36.86126708984375\n","Batch [37/105] Loss: 19.50704002380371\n","Batch [38/105] Loss: 16.61127281188965\n","Batch [39/105] Loss: 36.02708053588867\n","Batch [40/105] Loss: 36.799720764160156\n","Batch [41/105] Loss: 56.757179260253906\n","Batch [42/105] Loss: 62.2606086730957\n","Batch [43/105] Loss: 12.918100357055664\n","Batch [44/105] Loss: 52.62062072753906\n","Batch [45/105] Loss: 11.491825103759766\n","Batch [46/105] Loss: 48.34323501586914\n","Batch [47/105] Loss: 35.977684020996094\n","Batch [48/105] Loss: 26.095949172973633\n","Batch [49/105] Loss: 18.65972900390625\n","Batch [50/105] Loss: 53.47703170776367\n","Batch [51/105] Loss: 49.293235778808594\n","Batch [52/105] Loss: 29.78805923461914\n","Batch [53/105] Loss: 44.796417236328125\n","Batch [54/105] Loss: 28.193635940551758\n","Batch [55/105] Loss: 76.00885772705078\n","Batch [56/105] Loss: 32.86013412475586\n","Batch [57/105] Loss: 80.11725616455078\n","Batch [58/105] Loss: 33.29303741455078\n","Batch [59/105] Loss: 29.046701431274414\n","Batch [60/105] Loss: 59.460289001464844\n","Batch [61/105] Loss: 42.49776840209961\n","Batch [62/105] Loss: 55.78947448730469\n","Batch [63/105] Loss: 74.51943969726562\n","Batch [64/105] Loss: 47.09732437133789\n","Batch [65/105] Loss: 35.92667007446289\n","Batch [66/105] Loss: 32.03257369995117\n","Batch [67/105] Loss: 37.07498550415039\n","Batch [68/105] Loss: 48.24814224243164\n","Batch [69/105] Loss: 46.19546127319336\n","Batch [70/105] Loss: 8.329170227050781\n","Batch [71/105] Loss: 30.241783142089844\n","Batch [72/105] Loss: 17.526533126831055\n","Batch [73/105] Loss: 21.532211303710938\n","Batch [74/105] Loss: 105.37977600097656\n","Batch [75/105] Loss: 30.73130989074707\n","Batch [76/105] Loss: 18.346954345703125\n","Batch [77/105] Loss: 26.137496948242188\n","Batch [78/105] Loss: 34.14299011230469\n","Batch [79/105] Loss: 10.86734390258789\n","Batch [80/105] Loss: 3.957949161529541\n","Batch [81/105] Loss: 28.10122299194336\n","Batch [82/105] Loss: 47.67250442504883\n","Batch [83/105] Loss: 18.649272918701172\n","Batch [84/105] Loss: 18.755826950073242\n","Batch [85/105] Loss: 96.90658569335938\n","Batch [86/105] Loss: 15.001338958740234\n","Batch [87/105] Loss: 15.954273223876953\n","Batch [88/105] Loss: 70.22694396972656\n","Batch [89/105] Loss: 8.025776863098145\n","Batch [90/105] Loss: 31.462730407714844\n","Batch [91/105] Loss: 39.563072204589844\n","Batch [92/105] Loss: 30.949180603027344\n","Batch [93/105] Loss: 2.97257661819458\n","Batch [94/105] Loss: 11.973783493041992\n","Batch [95/105] Loss: 45.88017654418945\n","Batch [96/105] Loss: 24.4446964263916\n","Batch [97/105] Loss: 45.598697662353516\n","Batch [98/105] Loss: 32.82538604736328\n","Batch [99/105] Loss: 102.17412567138672\n","Batch [100/105] Loss: 20.010650634765625\n","Batch [101/105] Loss: 76.03465270996094\n","Batch [102/105] Loss: 16.600200653076172\n","Batch [103/105] Loss: 26.18319320678711\n","Batch [104/105] Loss: 44.45569610595703\n","Batch [105/105] Loss: 65.08232879638672\n","Epoch [8/50], Loss: 36.22791749863398\n","New minimum loss achieved: 36.22791749863398. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 8.651895523071289\n","Batch [2/105] Loss: 36.61970901489258\n","Batch [3/105] Loss: 25.9176082611084\n","Batch [4/105] Loss: 54.52928924560547\n","Batch [5/105] Loss: 39.665618896484375\n","Batch [6/105] Loss: 30.431949615478516\n","Batch [7/105] Loss: 33.1622314453125\n","Batch [8/105] Loss: 56.14042282104492\n","Batch [9/105] Loss: 41.33496856689453\n","Batch [10/105] Loss: 26.272075653076172\n","Batch [11/105] Loss: 3.352660655975342\n","Batch [12/105] Loss: 51.97291564941406\n","Batch [13/105] Loss: 22.211307525634766\n","Batch [14/105] Loss: 22.822715759277344\n","Batch [15/105] Loss: 47.85032653808594\n","Batch [16/105] Loss: 25.721046447753906\n","Batch [17/105] Loss: 41.48794174194336\n","Batch [18/105] Loss: 6.340198516845703\n","Batch [19/105] Loss: 18.881858825683594\n","Batch [20/105] Loss: 43.26994323730469\n","Batch [21/105] Loss: 35.057830810546875\n","Batch [22/105] Loss: 36.89518356323242\n","Batch [23/105] Loss: 14.358521461486816\n","Batch [24/105] Loss: 13.788642883300781\n","Batch [25/105] Loss: 16.98906707763672\n","Batch [26/105] Loss: 32.8319206237793\n","Batch [27/105] Loss: 43.07931137084961\n","Batch [28/105] Loss: 29.119260787963867\n","Batch [29/105] Loss: 70.77682495117188\n","Batch [30/105] Loss: 14.63880729675293\n","Batch [31/105] Loss: 26.576677322387695\n","Batch [32/105] Loss: 36.77690505981445\n","Batch [33/105] Loss: 36.824371337890625\n","Batch [34/105] Loss: 34.76618957519531\n","Batch [35/105] Loss: 38.275753021240234\n","Batch [36/105] Loss: 11.186896324157715\n","Batch [37/105] Loss: 80.85702514648438\n","Batch [38/105] Loss: 32.25948715209961\n","Batch [39/105] Loss: 29.920312881469727\n","Batch [40/105] Loss: 16.14751625061035\n","Batch [41/105] Loss: 34.549346923828125\n","Batch [42/105] Loss: 32.16543960571289\n","Batch [43/105] Loss: 30.882709503173828\n","Batch [44/105] Loss: 21.478160858154297\n","Batch [45/105] Loss: 48.87130355834961\n","Batch [46/105] Loss: 22.769115447998047\n","Batch [47/105] Loss: 57.462039947509766\n","Batch [48/105] Loss: 27.400279998779297\n","Batch [49/105] Loss: 62.76969909667969\n","Batch [50/105] Loss: 49.97918701171875\n","Batch [51/105] Loss: 44.77118682861328\n","Batch [52/105] Loss: 11.943465232849121\n","Batch [53/105] Loss: 25.265954971313477\n","Batch [54/105] Loss: 19.1243896484375\n","Batch [55/105] Loss: 39.3386116027832\n","Batch [56/105] Loss: 38.46482467651367\n","Batch [57/105] Loss: 12.759737014770508\n","Batch [58/105] Loss: 9.950326919555664\n","Batch [59/105] Loss: 13.29570198059082\n","Batch [60/105] Loss: 35.27880096435547\n","Batch [61/105] Loss: 68.01883697509766\n","Batch [62/105] Loss: 26.821487426757812\n","Batch [63/105] Loss: 38.12606430053711\n","Batch [64/105] Loss: 26.97107696533203\n","Batch [65/105] Loss: 42.29032516479492\n","Batch [66/105] Loss: 29.723012924194336\n","Batch [67/105] Loss: 38.55849075317383\n","Batch [68/105] Loss: 37.94585037231445\n","Batch [69/105] Loss: 17.36272621154785\n","Batch [70/105] Loss: 27.474348068237305\n","Batch [71/105] Loss: 55.60132598876953\n","Batch [72/105] Loss: 31.784385681152344\n","Batch [73/105] Loss: 64.0445785522461\n","Batch [74/105] Loss: 16.819246292114258\n","Batch [75/105] Loss: 25.500896453857422\n","Batch [76/105] Loss: 11.593986511230469\n","Batch [77/105] Loss: 39.2208137512207\n","Batch [78/105] Loss: 32.82536315917969\n","Batch [79/105] Loss: 18.287628173828125\n","Batch [80/105] Loss: 22.751930236816406\n","Batch [81/105] Loss: 36.941078186035156\n","Batch [82/105] Loss: 31.235179901123047\n","Batch [83/105] Loss: 42.49561309814453\n","Batch [84/105] Loss: 29.204204559326172\n","Batch [85/105] Loss: 14.176002502441406\n","Batch [86/105] Loss: 27.67629051208496\n","Batch [87/105] Loss: 18.17308807373047\n","Batch [88/105] Loss: 28.352397918701172\n","Batch [89/105] Loss: 54.518348693847656\n","Batch [90/105] Loss: 23.104286193847656\n","Batch [91/105] Loss: 2.917360305786133\n","Batch [92/105] Loss: 35.06687927246094\n","Batch [93/105] Loss: 26.01557159423828\n","Batch [94/105] Loss: 9.582569122314453\n","Batch [95/105] Loss: 25.087627410888672\n","Batch [96/105] Loss: 37.38227844238281\n","Batch [97/105] Loss: 25.566925048828125\n","Batch [98/105] Loss: 112.41098022460938\n","Batch [99/105] Loss: 68.54960632324219\n","Batch [100/105] Loss: 72.58658599853516\n","Batch [101/105] Loss: 19.457284927368164\n","Batch [102/105] Loss: 59.71284484863281\n","Batch [103/105] Loss: 15.345672607421875\n","Batch [104/105] Loss: 38.37903594970703\n","Batch [105/105] Loss: 8.841821670532227\n","Epoch [9/50], Loss: 32.9598607426598\n","New minimum loss achieved: 32.9598607426598. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 29.010578155517578\n","Batch [2/105] Loss: 15.025558471679688\n","Batch [3/105] Loss: 15.265226364135742\n","Batch [4/105] Loss: 22.80118179321289\n","Batch [5/105] Loss: 72.2406997680664\n","Batch [6/105] Loss: 53.36803436279297\n","Batch [7/105] Loss: 38.200565338134766\n","Batch [8/105] Loss: 22.553741455078125\n","Batch [9/105] Loss: 22.455230712890625\n","Batch [10/105] Loss: 21.502113342285156\n","Batch [11/105] Loss: 28.960588455200195\n","Batch [12/105] Loss: 13.127020835876465\n","Batch [13/105] Loss: 88.87052154541016\n","Batch [14/105] Loss: 13.573562622070312\n","Batch [15/105] Loss: 41.53573226928711\n","Batch [16/105] Loss: 38.392417907714844\n","Batch [17/105] Loss: 8.733515739440918\n","Batch [18/105] Loss: 18.614002227783203\n","Batch [19/105] Loss: 56.32797622680664\n","Batch [20/105] Loss: 36.72312927246094\n","Batch [21/105] Loss: 10.957465171813965\n","Batch [22/105] Loss: 37.61418151855469\n","Batch [23/105] Loss: 44.89011764526367\n","Batch [24/105] Loss: 29.059572219848633\n","Batch [25/105] Loss: 33.082881927490234\n","Batch [26/105] Loss: 55.86374282836914\n","Batch [27/105] Loss: 13.386974334716797\n","Batch [28/105] Loss: 11.642147064208984\n","Batch [29/105] Loss: 44.806373596191406\n","Batch [30/105] Loss: 12.408634185791016\n","Batch [31/105] Loss: 26.735626220703125\n","Batch [32/105] Loss: 5.2792463302612305\n","Batch [33/105] Loss: 77.78907012939453\n","Batch [34/105] Loss: 10.373831748962402\n","Batch [35/105] Loss: 23.834239959716797\n","Batch [36/105] Loss: 41.236392974853516\n","Batch [37/105] Loss: 42.75579833984375\n","Batch [38/105] Loss: 17.418306350708008\n","Batch [39/105] Loss: 11.960604667663574\n","Batch [40/105] Loss: 59.73833084106445\n","Batch [41/105] Loss: 19.250537872314453\n","Batch [42/105] Loss: 38.375\n","Batch [43/105] Loss: 44.0098876953125\n","Batch [44/105] Loss: 9.372705459594727\n","Batch [45/105] Loss: 21.099449157714844\n","Batch [46/105] Loss: 78.63926696777344\n","Batch [47/105] Loss: 14.669648170471191\n","Batch [48/105] Loss: 13.6895751953125\n","Batch [49/105] Loss: 12.91490364074707\n","Batch [50/105] Loss: 51.244354248046875\n","Batch [51/105] Loss: 19.143245697021484\n","Batch [52/105] Loss: 23.963275909423828\n","Batch [53/105] Loss: 15.035682678222656\n","Batch [54/105] Loss: 15.80760669708252\n","Batch [55/105] Loss: 17.416948318481445\n","Batch [56/105] Loss: 16.809690475463867\n","Batch [57/105] Loss: 30.038888931274414\n","Batch [58/105] Loss: 14.076671600341797\n","Batch [59/105] Loss: 64.85939025878906\n","Batch [60/105] Loss: 26.27250862121582\n","Batch [61/105] Loss: 4.897603988647461\n","Batch [62/105] Loss: 28.020212173461914\n","Batch [63/105] Loss: 38.3655891418457\n","Batch [64/105] Loss: 14.60080337524414\n","Batch [65/105] Loss: 21.852294921875\n","Batch [66/105] Loss: 98.6141357421875\n","Batch [67/105] Loss: 30.768085479736328\n","Batch [68/105] Loss: 81.7022705078125\n","Batch [69/105] Loss: 13.314828872680664\n","Batch [70/105] Loss: 17.032140731811523\n","Batch [71/105] Loss: 18.565635681152344\n","Batch [72/105] Loss: 8.779535293579102\n","Batch [73/105] Loss: 36.34811782836914\n","Batch [74/105] Loss: 19.062585830688477\n","Batch [75/105] Loss: 97.96916198730469\n","Batch [76/105] Loss: 37.971378326416016\n","Batch [77/105] Loss: 15.08171272277832\n","Batch [78/105] Loss: 36.4346809387207\n","Batch [79/105] Loss: 42.697174072265625\n","Batch [80/105] Loss: 19.58651351928711\n","Batch [81/105] Loss: 56.630958557128906\n","Batch [82/105] Loss: 23.784358978271484\n","Batch [83/105] Loss: 45.63758850097656\n","Batch [84/105] Loss: 38.74159622192383\n","Batch [85/105] Loss: 30.55744743347168\n","Batch [86/105] Loss: 38.58149337768555\n","Batch [87/105] Loss: 26.178298950195312\n","Batch [88/105] Loss: 30.342239379882812\n","Batch [89/105] Loss: 17.828065872192383\n","Batch [90/105] Loss: 30.68496322631836\n","Batch [91/105] Loss: 29.475133895874023\n","Batch [92/105] Loss: 21.23715591430664\n","Batch [93/105] Loss: 31.370014190673828\n","Batch [94/105] Loss: 11.478026390075684\n","Batch [95/105] Loss: 19.808822631835938\n","Batch [96/105] Loss: 17.185874938964844\n","Batch [97/105] Loss: 21.71076774597168\n","Batch [98/105] Loss: 45.908912658691406\n","Batch [99/105] Loss: 45.618064880371094\n","Batch [100/105] Loss: 21.377466201782227\n","Batch [101/105] Loss: 31.543302536010742\n","Batch [102/105] Loss: 28.933780670166016\n","Batch [103/105] Loss: 19.67291831970215\n","Batch [104/105] Loss: 12.467666625976562\n","Batch [105/105] Loss: 21.21973991394043\n","Epoch [10/50], Loss: 30.613745634896414\n","New minimum loss achieved: 30.613745634896414. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 21.550939559936523\n","Batch [2/105] Loss: 9.695405960083008\n","Batch [3/105] Loss: 19.224796295166016\n","Batch [4/105] Loss: 31.174623489379883\n","Batch [5/105] Loss: 40.17952346801758\n","Batch [6/105] Loss: 41.29230499267578\n","Batch [7/105] Loss: 5.085338592529297\n","Batch [8/105] Loss: 11.891410827636719\n","Batch [9/105] Loss: 27.66777801513672\n","Batch [10/105] Loss: 24.88751220703125\n","Batch [11/105] Loss: 11.385231018066406\n","Batch [12/105] Loss: 29.500350952148438\n","Batch [13/105] Loss: 46.3307991027832\n","Batch [14/105] Loss: 8.045435905456543\n","Batch [15/105] Loss: 10.892151832580566\n","Batch [16/105] Loss: 42.59910202026367\n","Batch [17/105] Loss: 24.808326721191406\n","Batch [18/105] Loss: 54.23471450805664\n","Batch [19/105] Loss: 88.8780517578125\n","Batch [20/105] Loss: 17.93592643737793\n","Batch [21/105] Loss: 24.96007537841797\n","Batch [22/105] Loss: 33.41484832763672\n","Batch [23/105] Loss: 27.04222869873047\n","Batch [24/105] Loss: 23.972396850585938\n","Batch [25/105] Loss: 44.28376007080078\n","Batch [26/105] Loss: 38.12138748168945\n","Batch [27/105] Loss: 26.97940444946289\n","Batch [28/105] Loss: 51.94617462158203\n","Batch [29/105] Loss: 25.559112548828125\n","Batch [30/105] Loss: 40.48396301269531\n","Batch [31/105] Loss: 19.216026306152344\n","Batch [32/105] Loss: 9.425464630126953\n","Batch [33/105] Loss: 12.35106086730957\n","Batch [34/105] Loss: 65.11871337890625\n","Batch [35/105] Loss: 9.065842628479004\n","Batch [36/105] Loss: 15.276900291442871\n","Batch [37/105] Loss: 14.763715744018555\n","Batch [38/105] Loss: 26.531463623046875\n","Batch [39/105] Loss: 23.94518280029297\n","Batch [40/105] Loss: 30.479543685913086\n","Batch [41/105] Loss: 51.82270812988281\n","Batch [42/105] Loss: 33.30743408203125\n","Batch [43/105] Loss: 15.524198532104492\n","Batch [44/105] Loss: 22.047584533691406\n","Batch [45/105] Loss: 41.83012771606445\n","Batch [46/105] Loss: 12.603578567504883\n","Batch [47/105] Loss: 67.2745132446289\n","Batch [48/105] Loss: 19.0660343170166\n","Batch [49/105] Loss: 31.90590476989746\n","Batch [50/105] Loss: 11.412399291992188\n","Batch [51/105] Loss: 53.267860412597656\n","Batch [52/105] Loss: 87.33553314208984\n","Batch [53/105] Loss: 43.91481399536133\n","Batch [54/105] Loss: 50.71559143066406\n","Batch [55/105] Loss: 65.13587188720703\n","Batch [56/105] Loss: 37.77928924560547\n","Batch [57/105] Loss: 45.36448669433594\n","Batch [58/105] Loss: 28.806398391723633\n","Batch [59/105] Loss: 71.24493408203125\n","Batch [60/105] Loss: 15.498579978942871\n","Batch [61/105] Loss: 32.9366340637207\n","Batch [62/105] Loss: 61.26725769042969\n","Batch [63/105] Loss: 57.06792449951172\n","Batch [64/105] Loss: 18.360916137695312\n","Batch [65/105] Loss: 49.016746520996094\n","Batch [66/105] Loss: 15.880024909973145\n","Batch [67/105] Loss: 37.13177490234375\n","Batch [68/105] Loss: 39.864768981933594\n","Batch [69/105] Loss: 21.03982925415039\n","Batch [70/105] Loss: 24.839839935302734\n","Batch [71/105] Loss: 17.082490921020508\n","Batch [72/105] Loss: 21.71177101135254\n","Batch [73/105] Loss: 32.90843200683594\n","Batch [74/105] Loss: 27.98196029663086\n","Batch [75/105] Loss: 20.098114013671875\n","Batch [76/105] Loss: 82.9067611694336\n","Batch [77/105] Loss: 11.397139549255371\n","Batch [78/105] Loss: 18.391756057739258\n","Batch [79/105] Loss: 13.784934997558594\n","Batch [80/105] Loss: 9.886260986328125\n","Batch [81/105] Loss: 14.31359577178955\n","Batch [82/105] Loss: 48.41873550415039\n","Batch [83/105] Loss: 25.34833335876465\n","Batch [84/105] Loss: 33.60700225830078\n","Batch [85/105] Loss: 57.88743591308594\n","Batch [86/105] Loss: 25.040508270263672\n","Batch [87/105] Loss: 19.59500503540039\n","Batch [88/105] Loss: 17.204891204833984\n","Batch [89/105] Loss: 40.19701385498047\n","Batch [90/105] Loss: 16.675325393676758\n","Batch [91/105] Loss: 29.322025299072266\n","Batch [92/105] Loss: 27.276805877685547\n","Batch [93/105] Loss: 21.87017059326172\n","Batch [94/105] Loss: 25.674274444580078\n","Batch [95/105] Loss: 25.798118591308594\n","Batch [96/105] Loss: 49.20555877685547\n","Batch [97/105] Loss: 20.644702911376953\n","Batch [98/105] Loss: 15.986221313476562\n","Batch [99/105] Loss: 44.35420227050781\n","Batch [100/105] Loss: 22.735349655151367\n","Batch [101/105] Loss: 69.2833480834961\n","Batch [102/105] Loss: 22.01987075805664\n","Batch [103/105] Loss: 8.90142822265625\n","Batch [104/105] Loss: 62.76345443725586\n","Batch [105/105] Loss: 35.224365234375\n","Epoch [11/50], Loss: 31.704361070905414\n","Batch [1/105] Loss: 24.865537643432617\n","Batch [2/105] Loss: 22.03589630126953\n","Batch [3/105] Loss: 34.3227424621582\n","Batch [4/105] Loss: 22.660003662109375\n","Batch [5/105] Loss: 59.58064270019531\n","Batch [6/105] Loss: 10.388118743896484\n","Batch [7/105] Loss: 27.455280303955078\n","Batch [8/105] Loss: 14.946953773498535\n","Batch [9/105] Loss: 33.628257751464844\n","Batch [10/105] Loss: 10.02133846282959\n","Batch [11/105] Loss: 23.34345817565918\n","Batch [12/105] Loss: 48.97478485107422\n","Batch [13/105] Loss: 12.35228443145752\n","Batch [14/105] Loss: 117.6569595336914\n","Batch [15/105] Loss: 59.21369934082031\n","Batch [16/105] Loss: 34.04483413696289\n","Batch [17/105] Loss: 53.03577423095703\n","Batch [18/105] Loss: 18.230207443237305\n","Batch [19/105] Loss: 17.902050018310547\n","Batch [20/105] Loss: 21.33894157409668\n","Batch [21/105] Loss: 12.28200912475586\n","Batch [22/105] Loss: 96.70677947998047\n","Batch [23/105] Loss: 14.982427597045898\n","Batch [24/105] Loss: 37.975276947021484\n","Batch [25/105] Loss: 14.750885963439941\n","Batch [26/105] Loss: 20.059703826904297\n","Batch [27/105] Loss: 19.0009708404541\n","Batch [28/105] Loss: 27.597888946533203\n","Batch [29/105] Loss: 72.92195129394531\n","Batch [30/105] Loss: 21.43834686279297\n","Batch [31/105] Loss: 20.959850311279297\n","Batch [32/105] Loss: 35.58415222167969\n","Batch [33/105] Loss: 42.383052825927734\n","Batch [34/105] Loss: 58.494651794433594\n","Batch [35/105] Loss: 23.07904815673828\n","Batch [36/105] Loss: 16.046730041503906\n","Batch [37/105] Loss: 26.16208267211914\n","Batch [38/105] Loss: 44.017574310302734\n","Batch [39/105] Loss: 26.485984802246094\n","Batch [40/105] Loss: 31.219640731811523\n","Batch [41/105] Loss: 45.04670333862305\n","Batch [42/105] Loss: 9.370891571044922\n","Batch [43/105] Loss: 28.102100372314453\n","Batch [44/105] Loss: 29.297157287597656\n","Batch [45/105] Loss: 37.02165222167969\n","Batch [46/105] Loss: 46.80710220336914\n","Batch [47/105] Loss: 19.87767791748047\n","Batch [48/105] Loss: 70.42115020751953\n","Batch [49/105] Loss: 11.512256622314453\n","Batch [50/105] Loss: 24.424972534179688\n","Batch [51/105] Loss: 16.541152954101562\n","Batch [52/105] Loss: 13.828815460205078\n","Batch [53/105] Loss: 22.607412338256836\n","Batch [54/105] Loss: 40.87498092651367\n","Batch [55/105] Loss: 11.757074356079102\n","Batch [56/105] Loss: 34.35935974121094\n","Batch [57/105] Loss: 42.57300567626953\n","Batch [58/105] Loss: 45.185302734375\n","Batch [59/105] Loss: 10.50918960571289\n","Batch [60/105] Loss: 17.891952514648438\n","Batch [61/105] Loss: 19.93794059753418\n","Batch [62/105] Loss: 15.981660842895508\n","Batch [63/105] Loss: 14.282295227050781\n","Batch [64/105] Loss: 21.688417434692383\n","Batch [65/105] Loss: 15.228675842285156\n","Batch [66/105] Loss: 66.18614196777344\n","Batch [67/105] Loss: 23.769725799560547\n","Batch [68/105] Loss: 13.696020126342773\n","Batch [69/105] Loss: 40.18294906616211\n","Batch [70/105] Loss: 30.844009399414062\n","Batch [71/105] Loss: 24.274736404418945\n","Batch [72/105] Loss: 20.755847930908203\n","Batch [73/105] Loss: 22.20526123046875\n","Batch [74/105] Loss: 39.67516326904297\n","Batch [75/105] Loss: 37.48277282714844\n","Batch [76/105] Loss: 33.74523162841797\n","Batch [77/105] Loss: 46.09815216064453\n","Batch [78/105] Loss: 46.622535705566406\n","Batch [79/105] Loss: 25.877073287963867\n","Batch [80/105] Loss: 73.55358123779297\n","Batch [81/105] Loss: 43.458580017089844\n","Batch [82/105] Loss: 14.848115921020508\n","Batch [83/105] Loss: 61.189064025878906\n","Batch [84/105] Loss: 17.094018936157227\n","Batch [85/105] Loss: 19.347536087036133\n","Batch [86/105] Loss: 44.22722625732422\n","Batch [87/105] Loss: 24.573719024658203\n","Batch [88/105] Loss: 14.247390747070312\n","Batch [89/105] Loss: 5.994389057159424\n","Batch [90/105] Loss: 16.829818725585938\n","Batch [91/105] Loss: 44.28669738769531\n","Batch [92/105] Loss: 65.37931823730469\n","Batch [93/105] Loss: 38.31810760498047\n","Batch [94/105] Loss: 46.05902862548828\n","Batch [95/105] Loss: 26.214590072631836\n","Batch [96/105] Loss: 25.255403518676758\n","Batch [97/105] Loss: 20.321422576904297\n","Batch [98/105] Loss: 48.47578811645508\n","Batch [99/105] Loss: 29.976289749145508\n","Batch [100/105] Loss: 15.596549987792969\n","Batch [101/105] Loss: 38.14622116088867\n","Batch [102/105] Loss: 53.25910186767578\n","Batch [103/105] Loss: 30.212703704833984\n","Batch [104/105] Loss: 24.47963523864746\n","Batch [105/105] Loss: 35.29084396362305\n","Epoch [12/50], Loss: 31.822156547364735\n","Batch [1/105] Loss: 25.265979766845703\n","Batch [2/105] Loss: 37.155433654785156\n","Batch [3/105] Loss: 22.317630767822266\n","Batch [4/105] Loss: 16.352062225341797\n","Batch [5/105] Loss: 59.0604362487793\n","Batch [6/105] Loss: 34.95248031616211\n","Batch [7/105] Loss: 32.531219482421875\n","Batch [8/105] Loss: 21.451541900634766\n","Batch [9/105] Loss: 75.30274200439453\n","Batch [10/105] Loss: 23.984264373779297\n","Batch [11/105] Loss: 28.32166290283203\n","Batch [12/105] Loss: 18.333282470703125\n","Batch [13/105] Loss: 45.057857513427734\n","Batch [14/105] Loss: 16.15747833251953\n","Batch [15/105] Loss: 21.26863670349121\n","Batch [16/105] Loss: 39.67607879638672\n","Batch [17/105] Loss: 15.867929458618164\n","Batch [18/105] Loss: 25.448984146118164\n","Batch [19/105] Loss: 13.855330467224121\n","Batch [20/105] Loss: 43.46487045288086\n","Batch [21/105] Loss: 40.14706039428711\n","Batch [22/105] Loss: 33.5182991027832\n","Batch [23/105] Loss: 13.35556411743164\n","Batch [24/105] Loss: 23.220726013183594\n","Batch [25/105] Loss: 50.56812286376953\n","Batch [26/105] Loss: 25.26140785217285\n","Batch [27/105] Loss: 28.574398040771484\n","Batch [28/105] Loss: 25.025054931640625\n","Batch [29/105] Loss: 32.11077880859375\n","Batch [30/105] Loss: 35.899009704589844\n","Batch [31/105] Loss: 59.074302673339844\n","Batch [32/105] Loss: 13.226922988891602\n","Batch [33/105] Loss: 35.5196533203125\n","Batch [34/105] Loss: 21.319347381591797\n","Batch [35/105] Loss: 32.251644134521484\n","Batch [36/105] Loss: 28.586257934570312\n","Batch [37/105] Loss: 47.086849212646484\n","Batch [38/105] Loss: 29.001441955566406\n","Batch [39/105] Loss: 68.26486206054688\n","Batch [40/105] Loss: 33.34136199951172\n","Batch [41/105] Loss: 31.63308334350586\n","Batch [42/105] Loss: 20.12965965270996\n","Batch [43/105] Loss: 12.525047302246094\n","Batch [44/105] Loss: 10.946175575256348\n","Batch [45/105] Loss: 15.90510368347168\n","Batch [46/105] Loss: 15.946651458740234\n","Batch [47/105] Loss: 39.87678527832031\n","Batch [48/105] Loss: 53.087303161621094\n","Batch [49/105] Loss: 29.3331298828125\n","Batch [50/105] Loss: 17.19036293029785\n","Batch [51/105] Loss: 14.591752052307129\n","Batch [52/105] Loss: 28.034074783325195\n","Batch [53/105] Loss: 45.177825927734375\n","Batch [54/105] Loss: 32.48303985595703\n","Batch [55/105] Loss: 43.69966125488281\n","Batch [56/105] Loss: 38.49304962158203\n","Batch [57/105] Loss: 52.45132064819336\n","Batch [58/105] Loss: 31.788434982299805\n","Batch [59/105] Loss: 14.751240730285645\n","Batch [60/105] Loss: 21.166629791259766\n","Batch [61/105] Loss: 73.66650390625\n","Batch [62/105] Loss: 33.74605941772461\n","Batch [63/105] Loss: 17.941944122314453\n","Batch [64/105] Loss: 11.035890579223633\n","Batch [65/105] Loss: 13.327844619750977\n","Batch [66/105] Loss: 26.730628967285156\n","Batch [67/105] Loss: 8.597108840942383\n","Batch [68/105] Loss: 65.3812484741211\n","Batch [69/105] Loss: 77.768798828125\n","Batch [70/105] Loss: 20.947067260742188\n","Batch [71/105] Loss: 12.135083198547363\n","Batch [72/105] Loss: 21.647838592529297\n","Batch [73/105] Loss: 15.454191207885742\n","Batch [74/105] Loss: 22.7709903717041\n","Batch [75/105] Loss: 36.090309143066406\n","Batch [76/105] Loss: 17.86479949951172\n","Batch [77/105] Loss: 13.543663024902344\n","Batch [78/105] Loss: 16.857603073120117\n","Batch [79/105] Loss: 25.608247756958008\n","Batch [80/105] Loss: 37.680389404296875\n","Batch [81/105] Loss: 27.481975555419922\n","Batch [82/105] Loss: 18.402545928955078\n","Batch [83/105] Loss: 15.568025588989258\n","Batch [84/105] Loss: 21.949359893798828\n","Batch [85/105] Loss: 54.85239791870117\n","Batch [86/105] Loss: 26.320756912231445\n","Batch [87/105] Loss: 11.064114570617676\n","Batch [88/105] Loss: 26.337120056152344\n","Batch [89/105] Loss: 18.849075317382812\n","Batch [90/105] Loss: 35.53516387939453\n","Batch [91/105] Loss: 64.03096008300781\n","Batch [92/105] Loss: 65.1941909790039\n","Batch [93/105] Loss: 15.492992401123047\n","Batch [94/105] Loss: 18.52545928955078\n","Batch [95/105] Loss: 19.644420623779297\n","Batch [96/105] Loss: 48.642704010009766\n","Batch [97/105] Loss: 9.622535705566406\n","Batch [98/105] Loss: 47.6427116394043\n","Batch [99/105] Loss: 29.31215476989746\n","Batch [100/105] Loss: 38.03187942504883\n","Batch [101/105] Loss: 9.689793586730957\n","Batch [102/105] Loss: 26.666980743408203\n","Batch [103/105] Loss: 24.335803985595703\n","Batch [104/105] Loss: 50.16547393798828\n","Batch [105/105] Loss: 25.30616569519043\n","Epoch [13/50], Loss: 30.265240687415712\n","New minimum loss achieved: 30.265240687415712. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 16.508602142333984\n","Batch [2/105] Loss: 33.058231353759766\n","Batch [3/105] Loss: 7.924596786499023\n","Batch [4/105] Loss: 49.50117492675781\n","Batch [5/105] Loss: 34.12297058105469\n","Batch [6/105] Loss: 47.205345153808594\n","Batch [7/105] Loss: 22.62120246887207\n","Batch [8/105] Loss: 40.15819549560547\n","Batch [9/105] Loss: 23.55101776123047\n","Batch [10/105] Loss: 11.724701881408691\n","Batch [11/105] Loss: 27.424100875854492\n","Batch [12/105] Loss: 54.616329193115234\n","Batch [13/105] Loss: 14.085926055908203\n","Batch [14/105] Loss: 32.33632278442383\n","Batch [15/105] Loss: 62.165287017822266\n","Batch [16/105] Loss: 20.48247528076172\n","Batch [17/105] Loss: 30.25889015197754\n","Batch [18/105] Loss: 23.935232162475586\n","Batch [19/105] Loss: 21.829334259033203\n","Batch [20/105] Loss: 52.76833724975586\n","Batch [21/105] Loss: 26.620880126953125\n","Batch [22/105] Loss: 14.10285758972168\n","Batch [23/105] Loss: 11.384125709533691\n","Batch [24/105] Loss: 18.732776641845703\n","Batch [25/105] Loss: 19.835418701171875\n","Batch [26/105] Loss: 15.838074684143066\n","Batch [27/105] Loss: 13.879206657409668\n","Batch [28/105] Loss: 18.121187210083008\n","Batch [29/105] Loss: 27.176345825195312\n","Batch [30/105] Loss: 43.510581970214844\n","Batch [31/105] Loss: 6.943854331970215\n","Batch [32/105] Loss: 19.59490966796875\n","Batch [33/105] Loss: 24.93496322631836\n","Batch [34/105] Loss: 44.220611572265625\n","Batch [35/105] Loss: 18.753782272338867\n","Batch [36/105] Loss: 41.97404098510742\n","Batch [37/105] Loss: 15.235494613647461\n","Batch [38/105] Loss: 15.608328819274902\n","Batch [39/105] Loss: 28.184925079345703\n","Batch [40/105] Loss: 37.62962341308594\n","Batch [41/105] Loss: 34.795108795166016\n","Batch [42/105] Loss: 51.31681823730469\n","Batch [43/105] Loss: 7.004360675811768\n","Batch [44/105] Loss: 34.09250259399414\n","Batch [45/105] Loss: 10.810461044311523\n","Batch [46/105] Loss: 10.858134269714355\n","Batch [47/105] Loss: 43.046913146972656\n","Batch [48/105] Loss: 12.24326229095459\n","Batch [49/105] Loss: 27.700374603271484\n","Batch [50/105] Loss: 12.276424407958984\n","Batch [51/105] Loss: 8.537935256958008\n","Batch [52/105] Loss: 29.332870483398438\n","Batch [53/105] Loss: 24.065013885498047\n","Batch [54/105] Loss: 21.657215118408203\n","Batch [55/105] Loss: 14.75280475616455\n","Batch [56/105] Loss: 27.358341217041016\n","Batch [57/105] Loss: 10.536060333251953\n","Batch [58/105] Loss: 31.731170654296875\n","Batch [59/105] Loss: 13.774144172668457\n","Batch [60/105] Loss: 11.901895523071289\n","Batch [61/105] Loss: 38.51955032348633\n","Batch [62/105] Loss: 33.60509490966797\n","Batch [63/105] Loss: 25.51727867126465\n","Batch [64/105] Loss: 42.45914840698242\n","Batch [65/105] Loss: 11.269929885864258\n","Batch [66/105] Loss: 8.805079460144043\n","Batch [67/105] Loss: 16.972280502319336\n","Batch [68/105] Loss: 40.074424743652344\n","Batch [69/105] Loss: 45.01129913330078\n","Batch [70/105] Loss: 19.24710464477539\n","Batch [71/105] Loss: 21.761308670043945\n","Batch [72/105] Loss: 7.66375732421875\n","Batch [73/105] Loss: 52.307395935058594\n","Batch [74/105] Loss: 25.029741287231445\n","Batch [75/105] Loss: 51.004051208496094\n","Batch [76/105] Loss: 36.02415084838867\n","Batch [77/105] Loss: 28.85535430908203\n","Batch [78/105] Loss: 40.320037841796875\n","Batch [79/105] Loss: 17.698345184326172\n","Batch [80/105] Loss: 11.327325820922852\n","Batch [81/105] Loss: 20.090316772460938\n","Batch [82/105] Loss: 25.067466735839844\n","Batch [83/105] Loss: 2.2771992683410645\n","Batch [84/105] Loss: 29.69931411743164\n","Batch [85/105] Loss: 35.428382873535156\n","Batch [86/105] Loss: 19.637977600097656\n","Batch [87/105] Loss: 92.32011413574219\n","Batch [88/105] Loss: 20.33939552307129\n","Batch [89/105] Loss: 23.4066219329834\n","Batch [90/105] Loss: 20.364974975585938\n","Batch [91/105] Loss: 8.429969787597656\n","Batch [92/105] Loss: 19.124515533447266\n","Batch [93/105] Loss: 23.708215713500977\n","Batch [94/105] Loss: 57.35454177856445\n","Batch [95/105] Loss: 52.908782958984375\n","Batch [96/105] Loss: 9.745122909545898\n","Batch [97/105] Loss: 22.455495834350586\n","Batch [98/105] Loss: 27.513954162597656\n","Batch [99/105] Loss: 29.08757972717285\n","Batch [100/105] Loss: 32.7412223815918\n","Batch [101/105] Loss: 5.792913913726807\n","Batch [102/105] Loss: 19.23206329345703\n","Batch [103/105] Loss: 7.7444047927856445\n","Batch [104/105] Loss: 37.38904571533203\n","Batch [105/105] Loss: 58.06715774536133\n","Epoch [14/50], Loss: 26.664299842289516\n","New minimum loss achieved: 26.664299842289516. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 52.411075592041016\n","Batch [2/105] Loss: 15.035211563110352\n","Batch [3/105] Loss: 14.453422546386719\n","Batch [4/105] Loss: 63.97229766845703\n","Batch [5/105] Loss: 29.070466995239258\n","Batch [6/105] Loss: 6.8581132888793945\n","Batch [7/105] Loss: 6.759485244750977\n","Batch [8/105] Loss: 66.86969757080078\n","Batch [9/105] Loss: 25.373638153076172\n","Batch [10/105] Loss: 14.727968215942383\n","Batch [11/105] Loss: 13.412542343139648\n","Batch [12/105] Loss: 28.615568161010742\n","Batch [13/105] Loss: 7.466707229614258\n","Batch [14/105] Loss: 39.423702239990234\n","Batch [15/105] Loss: 8.98779010772705\n","Batch [16/105] Loss: 46.81936264038086\n","Batch [17/105] Loss: 44.26837921142578\n","Batch [18/105] Loss: 25.646949768066406\n","Batch [19/105] Loss: 37.23456954956055\n","Batch [20/105] Loss: 10.168362617492676\n","Batch [21/105] Loss: 45.25929260253906\n","Batch [22/105] Loss: 21.642417907714844\n","Batch [23/105] Loss: 36.73566436767578\n","Batch [24/105] Loss: 7.359800338745117\n","Batch [25/105] Loss: 13.400140762329102\n","Batch [26/105] Loss: 20.663326263427734\n","Batch [27/105] Loss: 23.890499114990234\n","Batch [28/105] Loss: 16.40802001953125\n","Batch [29/105] Loss: 10.131574630737305\n","Batch [30/105] Loss: 16.917160034179688\n","Batch [31/105] Loss: 37.97223663330078\n","Batch [32/105] Loss: 41.1463737487793\n","Batch [33/105] Loss: 17.967103958129883\n","Batch [34/105] Loss: 17.598703384399414\n","Batch [35/105] Loss: 17.375667572021484\n","Batch [36/105] Loss: 11.372878074645996\n","Batch [37/105] Loss: 29.696609497070312\n","Batch [38/105] Loss: 30.333059310913086\n","Batch [39/105] Loss: 36.27972412109375\n","Batch [40/105] Loss: 8.731912612915039\n","Batch [41/105] Loss: 33.68177795410156\n","Batch [42/105] Loss: 20.140962600708008\n","Batch [43/105] Loss: 8.531450271606445\n","Batch [44/105] Loss: 37.459835052490234\n","Batch [45/105] Loss: 24.871976852416992\n","Batch [46/105] Loss: 8.866180419921875\n","Batch [47/105] Loss: 15.62928581237793\n","Batch [48/105] Loss: 10.070019721984863\n","Batch [49/105] Loss: 31.193927764892578\n","Batch [50/105] Loss: 28.620887756347656\n","Batch [51/105] Loss: 95.83035278320312\n","Batch [52/105] Loss: 35.215065002441406\n","Batch [53/105] Loss: 47.48567199707031\n","Batch [54/105] Loss: 31.94672393798828\n","Batch [55/105] Loss: 11.19214153289795\n","Batch [56/105] Loss: 19.3833065032959\n","Batch [57/105] Loss: 23.047204971313477\n","Batch [58/105] Loss: 17.500362396240234\n","Batch [59/105] Loss: 13.616727828979492\n","Batch [60/105] Loss: 13.5834379196167\n","Batch [61/105] Loss: 42.6953125\n","Batch [62/105] Loss: 12.972589492797852\n","Batch [63/105] Loss: 18.156295776367188\n","Batch [64/105] Loss: 20.148157119750977\n","Batch [65/105] Loss: 15.967849731445312\n","Batch [66/105] Loss: 27.892620086669922\n","Batch [67/105] Loss: 31.907325744628906\n","Batch [68/105] Loss: 16.547637939453125\n","Batch [69/105] Loss: 38.9854850769043\n","Batch [70/105] Loss: 56.5666618347168\n","Batch [71/105] Loss: 47.885292053222656\n","Batch [72/105] Loss: 33.89494323730469\n","Batch [73/105] Loss: 30.794654846191406\n","Batch [74/105] Loss: 25.37363052368164\n","Batch [75/105] Loss: 21.858325958251953\n","Batch [76/105] Loss: 14.518594741821289\n","Batch [77/105] Loss: 55.60391616821289\n","Batch [78/105] Loss: 19.13683319091797\n","Batch [79/105] Loss: 15.560674667358398\n","Batch [80/105] Loss: 23.22153091430664\n","Batch [81/105] Loss: 38.49791717529297\n","Batch [82/105] Loss: 55.498985290527344\n","Batch [83/105] Loss: 17.117944717407227\n","Batch [84/105] Loss: 31.053726196289062\n","Batch [85/105] Loss: 16.52170753479004\n","Batch [86/105] Loss: 26.93514633178711\n","Batch [87/105] Loss: 35.94209671020508\n","Batch [88/105] Loss: 43.441978454589844\n","Batch [89/105] Loss: 45.88469696044922\n","Batch [90/105] Loss: 29.540782928466797\n","Batch [91/105] Loss: 29.138687133789062\n","Batch [92/105] Loss: 20.034154891967773\n","Batch [93/105] Loss: 21.457382202148438\n","Batch [94/105] Loss: 21.60299301147461\n","Batch [95/105] Loss: 13.37364387512207\n","Batch [96/105] Loss: 4.731528282165527\n","Batch [97/105] Loss: 22.713037490844727\n","Batch [98/105] Loss: 31.28736114501953\n","Batch [99/105] Loss: 20.853347778320312\n","Batch [100/105] Loss: 15.703161239624023\n","Batch [101/105] Loss: 26.832216262817383\n","Batch [102/105] Loss: 41.880741119384766\n","Batch [103/105] Loss: 48.409400939941406\n","Batch [104/105] Loss: 23.733797073364258\n","Batch [105/105] Loss: 36.85506057739258\n","Epoch [15/50], Loss: 27.000520015898203\n","Batch [1/105] Loss: 8.455510139465332\n","Batch [2/105] Loss: 9.873225212097168\n","Batch [3/105] Loss: 16.433757781982422\n","Batch [4/105] Loss: 35.47428512573242\n","Batch [5/105] Loss: 13.477914810180664\n","Batch [6/105] Loss: 59.57636642456055\n","Batch [7/105] Loss: 29.001750946044922\n","Batch [8/105] Loss: 31.26239013671875\n","Batch [9/105] Loss: 38.68308639526367\n","Batch [10/105] Loss: 35.96941375732422\n","Batch [11/105] Loss: 17.988162994384766\n","Batch [12/105] Loss: 54.3795166015625\n","Batch [13/105] Loss: 27.275699615478516\n","Batch [14/105] Loss: 17.864070892333984\n","Batch [15/105] Loss: 11.783273696899414\n","Batch [16/105] Loss: 29.299495697021484\n","Batch [17/105] Loss: 12.830623626708984\n","Batch [18/105] Loss: 18.903270721435547\n","Batch [19/105] Loss: 23.539295196533203\n","Batch [20/105] Loss: 40.27458572387695\n","Batch [21/105] Loss: 42.850440979003906\n","Batch [22/105] Loss: 9.01914119720459\n","Batch [23/105] Loss: 11.39065170288086\n","Batch [24/105] Loss: 12.197250366210938\n","Batch [25/105] Loss: 18.74020004272461\n","Batch [26/105] Loss: 24.891788482666016\n","Batch [27/105] Loss: 60.63600540161133\n","Batch [28/105] Loss: 29.535903930664062\n","Batch [29/105] Loss: 36.88330841064453\n","Batch [30/105] Loss: 74.19500732421875\n","Batch [31/105] Loss: 18.434001922607422\n","Batch [32/105] Loss: 38.065269470214844\n","Batch [33/105] Loss: 12.960448265075684\n","Batch [34/105] Loss: 15.925653457641602\n","Batch [35/105] Loss: 68.294921875\n","Batch [36/105] Loss: 12.013763427734375\n","Batch [37/105] Loss: 38.11396026611328\n","Batch [38/105] Loss: 48.09568786621094\n","Batch [39/105] Loss: 22.853954315185547\n","Batch [40/105] Loss: 49.372955322265625\n","Batch [41/105] Loss: 16.270496368408203\n","Batch [42/105] Loss: 20.572322845458984\n","Batch [43/105] Loss: 41.349098205566406\n","Batch [44/105] Loss: 6.601252555847168\n","Batch [45/105] Loss: 17.013633728027344\n","Batch [46/105] Loss: 8.106998443603516\n","Batch [47/105] Loss: 19.90465545654297\n","Batch [48/105] Loss: 28.57724380493164\n","Batch [49/105] Loss: 22.25592613220215\n","Batch [50/105] Loss: 20.053264617919922\n","Batch [51/105] Loss: 47.813629150390625\n","Batch [52/105] Loss: 15.522945404052734\n","Batch [53/105] Loss: 15.03377914428711\n","Batch [54/105] Loss: 45.22861862182617\n","Batch [55/105] Loss: 34.317596435546875\n","Batch [56/105] Loss: 12.617944717407227\n","Batch [57/105] Loss: 12.609014511108398\n","Batch [58/105] Loss: 18.318435668945312\n","Batch [59/105] Loss: 17.94087791442871\n","Batch [60/105] Loss: 43.63855743408203\n","Batch [61/105] Loss: 14.8842191696167\n","Batch [62/105] Loss: 32.372928619384766\n","Batch [63/105] Loss: 34.11803436279297\n","Batch [64/105] Loss: 24.642009735107422\n","Batch [65/105] Loss: 16.76955223083496\n","Batch [66/105] Loss: 27.769447326660156\n","Batch [67/105] Loss: 10.369518280029297\n","Batch [68/105] Loss: 18.80767250061035\n","Batch [69/105] Loss: 15.881135940551758\n","Batch [70/105] Loss: 24.046550750732422\n","Batch [71/105] Loss: 17.960847854614258\n","Batch [72/105] Loss: 38.09797668457031\n","Batch [73/105] Loss: 62.97968673706055\n","Batch [74/105] Loss: 6.929418087005615\n","Batch [75/105] Loss: 10.428872108459473\n","Batch [76/105] Loss: 14.256048202514648\n","Batch [77/105] Loss: 17.758533477783203\n","Batch [78/105] Loss: 10.871946334838867\n","Batch [79/105] Loss: 12.881402969360352\n","Batch [80/105] Loss: 19.585891723632812\n","Batch [81/105] Loss: 23.444692611694336\n","Batch [82/105] Loss: 9.436882019042969\n","Batch [83/105] Loss: 22.552223205566406\n","Batch [84/105] Loss: 11.030047416687012\n","Batch [85/105] Loss: 10.959887504577637\n","Batch [86/105] Loss: 41.94561004638672\n","Batch [87/105] Loss: 85.53643798828125\n","Batch [88/105] Loss: 48.69219970703125\n","Batch [89/105] Loss: 12.732793807983398\n","Batch [90/105] Loss: 41.73435592651367\n","Batch [91/105] Loss: 12.643985748291016\n","Batch [92/105] Loss: 10.31512451171875\n","Batch [93/105] Loss: 36.29271697998047\n","Batch [94/105] Loss: 13.559679985046387\n","Batch [95/105] Loss: 31.56043243408203\n","Batch [96/105] Loss: 28.229244232177734\n","Batch [97/105] Loss: 14.256941795349121\n","Batch [98/105] Loss: 47.65025329589844\n","Batch [99/105] Loss: 15.90357494354248\n","Batch [100/105] Loss: 24.336421966552734\n","Batch [101/105] Loss: 31.11923599243164\n","Batch [102/105] Loss: 10.083184242248535\n","Batch [103/105] Loss: 35.3171272277832\n","Batch [104/105] Loss: 18.192623138427734\n","Batch [105/105] Loss: 20.629945755004883\n","Epoch [16/50], Loss: 26.00123444057646\n","New minimum loss achieved: 26.00123444057646. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 24.096534729003906\n","Batch [2/105] Loss: 12.014833450317383\n","Batch [3/105] Loss: 23.905481338500977\n","Batch [4/105] Loss: 19.841001510620117\n","Batch [5/105] Loss: 51.91347885131836\n","Batch [6/105] Loss: 3.3093655109405518\n","Batch [7/105] Loss: 7.741754531860352\n","Batch [8/105] Loss: 7.13539457321167\n","Batch [9/105] Loss: 24.853015899658203\n","Batch [10/105] Loss: 18.253461837768555\n","Batch [11/105] Loss: 34.136898040771484\n","Batch [12/105] Loss: 16.56982421875\n","Batch [13/105] Loss: 22.489492416381836\n","Batch [14/105] Loss: 31.026979446411133\n","Batch [15/105] Loss: 35.64469909667969\n","Batch [16/105] Loss: 18.818092346191406\n","Batch [17/105] Loss: 19.97321891784668\n","Batch [18/105] Loss: 9.646021842956543\n","Batch [19/105] Loss: 50.190399169921875\n","Batch [20/105] Loss: 52.533897399902344\n","Batch [21/105] Loss: 8.230091094970703\n","Batch [22/105] Loss: 13.137615203857422\n","Batch [23/105] Loss: 22.315147399902344\n","Batch [24/105] Loss: 29.428977966308594\n","Batch [25/105] Loss: 47.11155700683594\n","Batch [26/105] Loss: 21.239761352539062\n","Batch [27/105] Loss: 26.036264419555664\n","Batch [28/105] Loss: 24.049663543701172\n","Batch [29/105] Loss: 24.989749908447266\n","Batch [30/105] Loss: 14.216946601867676\n","Batch [31/105] Loss: 30.719160079956055\n","Batch [32/105] Loss: 28.448646545410156\n","Batch [33/105] Loss: 28.665111541748047\n","Batch [34/105] Loss: 44.61030197143555\n","Batch [35/105] Loss: 15.255155563354492\n","Batch [36/105] Loss: 17.23096466064453\n","Batch [37/105] Loss: 4.731345176696777\n","Batch [38/105] Loss: 16.64910888671875\n","Batch [39/105] Loss: 39.090599060058594\n","Batch [40/105] Loss: 32.61750793457031\n","Batch [41/105] Loss: 64.8698501586914\n","Batch [42/105] Loss: 34.41917419433594\n","Batch [43/105] Loss: 8.741360664367676\n","Batch [44/105] Loss: 15.405379295349121\n","Batch [45/105] Loss: 41.1373405456543\n","Batch [46/105] Loss: 64.86238098144531\n","Batch [47/105] Loss: 15.604360580444336\n","Batch [48/105] Loss: 28.361717224121094\n","Batch [49/105] Loss: 11.952244758605957\n","Batch [50/105] Loss: 16.133888244628906\n","Batch [51/105] Loss: 19.89822769165039\n","Batch [52/105] Loss: 28.713462829589844\n","Batch [53/105] Loss: 12.037788391113281\n","Batch [54/105] Loss: 30.00843048095703\n","Batch [55/105] Loss: 16.960308074951172\n","Batch [56/105] Loss: 37.361473083496094\n","Batch [57/105] Loss: 45.84148025512695\n","Batch [58/105] Loss: 4.483399391174316\n","Batch [59/105] Loss: 48.65308380126953\n","Batch [60/105] Loss: 25.752328872680664\n","Batch [61/105] Loss: 56.72722625732422\n","Batch [62/105] Loss: 15.6529541015625\n","Batch [63/105] Loss: 42.90628433227539\n","Batch [64/105] Loss: 44.80352020263672\n","Batch [65/105] Loss: 41.08842468261719\n","Batch [66/105] Loss: 58.460906982421875\n","Batch [67/105] Loss: 18.146392822265625\n","Batch [68/105] Loss: 32.35029602050781\n","Batch [69/105] Loss: 5.093989372253418\n","Batch [70/105] Loss: 28.339183807373047\n","Batch [71/105] Loss: 19.502105712890625\n","Batch [72/105] Loss: 25.805925369262695\n","Batch [73/105] Loss: 34.657161712646484\n","Batch [74/105] Loss: 16.591106414794922\n","Batch [75/105] Loss: 45.741554260253906\n","Batch [76/105] Loss: 19.28734588623047\n","Batch [77/105] Loss: 38.572059631347656\n","Batch [78/105] Loss: 30.763668060302734\n","Batch [79/105] Loss: 28.621641159057617\n","Batch [80/105] Loss: 40.283870697021484\n","Batch [81/105] Loss: 36.6331672668457\n","Batch [82/105] Loss: 10.169307708740234\n","Batch [83/105] Loss: 25.5782413482666\n","Batch [84/105] Loss: 13.932594299316406\n","Batch [85/105] Loss: 17.21965789794922\n","Batch [86/105] Loss: 79.68446350097656\n","Batch [87/105] Loss: 41.656429290771484\n","Batch [88/105] Loss: 7.671143531799316\n","Batch [89/105] Loss: 17.811683654785156\n","Batch [90/105] Loss: 19.567575454711914\n","Batch [91/105] Loss: 97.5481948852539\n","Batch [92/105] Loss: 17.182937622070312\n","Batch [93/105] Loss: 22.32478141784668\n","Batch [94/105] Loss: 70.2099838256836\n","Batch [95/105] Loss: 32.30310821533203\n","Batch [96/105] Loss: 23.44917106628418\n","Batch [97/105] Loss: 10.728145599365234\n","Batch [98/105] Loss: 25.342546463012695\n","Batch [99/105] Loss: 27.60051155090332\n","Batch [100/105] Loss: 39.10170364379883\n","Batch [101/105] Loss: 16.707027435302734\n","Batch [102/105] Loss: 24.232437133789062\n","Batch [103/105] Loss: 7.560538291931152\n","Batch [104/105] Loss: 44.86361312866211\n","Batch [105/105] Loss: 49.1486701965332\n","Epoch [17/50], Loss: 28.244651928402128\n","Batch [1/105] Loss: 14.466699600219727\n","Batch [2/105] Loss: 22.39751434326172\n","Batch [3/105] Loss: 16.906034469604492\n","Batch [4/105] Loss: 39.460182189941406\n","Batch [5/105] Loss: 28.73029136657715\n","Batch [6/105] Loss: 32.569007873535156\n","Batch [7/105] Loss: 12.694737434387207\n","Batch [8/105] Loss: 16.494258880615234\n","Batch [9/105] Loss: 11.478117942810059\n","Batch [10/105] Loss: 20.195228576660156\n","Batch [11/105] Loss: 24.607372283935547\n","Batch [12/105] Loss: 43.84521484375\n","Batch [13/105] Loss: 17.959928512573242\n","Batch [14/105] Loss: 21.424589157104492\n","Batch [15/105] Loss: 70.62849426269531\n","Batch [16/105] Loss: 8.882558822631836\n","Batch [17/105] Loss: 10.780174255371094\n","Batch [18/105] Loss: 24.209392547607422\n","Batch [19/105] Loss: 29.056476593017578\n","Batch [20/105] Loss: 18.714656829833984\n","Batch [21/105] Loss: 16.366504669189453\n","Batch [22/105] Loss: 38.098751068115234\n","Batch [23/105] Loss: 7.121894359588623\n","Batch [24/105] Loss: 26.669357299804688\n","Batch [25/105] Loss: 27.49262237548828\n","Batch [26/105] Loss: 19.952125549316406\n","Batch [27/105] Loss: 23.42184066772461\n","Batch [28/105] Loss: 37.05361557006836\n","Batch [29/105] Loss: 20.040098190307617\n","Batch [30/105] Loss: 39.041786193847656\n","Batch [31/105] Loss: 22.843788146972656\n","Batch [32/105] Loss: 12.441934585571289\n","Batch [33/105] Loss: 19.92707633972168\n","Batch [34/105] Loss: 12.889119148254395\n","Batch [35/105] Loss: 33.04909896850586\n","Batch [36/105] Loss: 25.405920028686523\n","Batch [37/105] Loss: 27.89120864868164\n","Batch [38/105] Loss: 28.499025344848633\n","Batch [39/105] Loss: 29.90817642211914\n","Batch [40/105] Loss: 12.17117977142334\n","Batch [41/105] Loss: 12.712400436401367\n","Batch [42/105] Loss: 17.67111587524414\n","Batch [43/105] Loss: 17.96495246887207\n","Batch [44/105] Loss: 22.322021484375\n","Batch [45/105] Loss: 27.016826629638672\n","Batch [46/105] Loss: 13.431709289550781\n","Batch [47/105] Loss: 70.09042358398438\n","Batch [48/105] Loss: 49.214500427246094\n","Batch [49/105] Loss: 35.34455108642578\n","Batch [50/105] Loss: 55.89555358886719\n","Batch [51/105] Loss: 10.700043678283691\n","Batch [52/105] Loss: 51.005882263183594\n","Batch [53/105] Loss: 46.03362274169922\n","Batch [54/105] Loss: 12.259655952453613\n","Batch [55/105] Loss: 21.877117156982422\n","Batch [56/105] Loss: 51.223724365234375\n","Batch [57/105] Loss: 12.500043869018555\n","Batch [58/105] Loss: 16.834550857543945\n","Batch [59/105] Loss: 7.159015655517578\n","Batch [60/105] Loss: 17.506723403930664\n","Batch [61/105] Loss: 18.37258529663086\n","Batch [62/105] Loss: 6.620787620544434\n","Batch [63/105] Loss: 27.673219680786133\n","Batch [64/105] Loss: 28.415769577026367\n","Batch [65/105] Loss: 47.22510528564453\n","Batch [66/105] Loss: 21.26938819885254\n","Batch [67/105] Loss: 17.1230411529541\n","Batch [68/105] Loss: 16.31574058532715\n","Batch [69/105] Loss: 20.794628143310547\n","Batch [70/105] Loss: 16.680166244506836\n","Batch [71/105] Loss: 47.78428649902344\n","Batch [72/105] Loss: 35.285274505615234\n","Batch [73/105] Loss: 30.78567123413086\n","Batch [74/105] Loss: 17.085159301757812\n","Batch [75/105] Loss: 29.690967559814453\n","Batch [76/105] Loss: 15.56007194519043\n","Batch [77/105] Loss: 36.743186950683594\n","Batch [78/105] Loss: 20.97568130493164\n","Batch [79/105] Loss: 21.51755142211914\n","Batch [80/105] Loss: 23.74152946472168\n","Batch [81/105] Loss: 48.36174774169922\n","Batch [82/105] Loss: 26.492334365844727\n","Batch [83/105] Loss: 32.64861297607422\n","Batch [84/105] Loss: 34.81166076660156\n","Batch [85/105] Loss: 13.122993469238281\n","Batch [86/105] Loss: 10.883541107177734\n","Batch [87/105] Loss: 37.688865661621094\n","Batch [88/105] Loss: 13.766691207885742\n","Batch [89/105] Loss: 46.93553924560547\n","Batch [90/105] Loss: 12.922079086303711\n","Batch [91/105] Loss: 34.58414077758789\n","Batch [92/105] Loss: 21.13544464111328\n","Batch [93/105] Loss: 31.08104133605957\n","Batch [94/105] Loss: 23.865083694458008\n","Batch [95/105] Loss: 57.3893928527832\n","Batch [96/105] Loss: 17.43037986755371\n","Batch [97/105] Loss: 15.336620330810547\n","Batch [98/105] Loss: 21.870664596557617\n","Batch [99/105] Loss: 38.63677978515625\n","Batch [100/105] Loss: 32.477333068847656\n","Batch [101/105] Loss: 13.439077377319336\n","Batch [102/105] Loss: 36.66283416748047\n","Batch [103/105] Loss: 40.881935119628906\n","Batch [104/105] Loss: 15.298548698425293\n","Batch [105/105] Loss: 10.440560340881348\n","Epoch [18/50], Loss: 25.927373363858177\n","New minimum loss achieved: 25.927373363858177. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 42.24100112915039\n","Batch [2/105] Loss: 41.563472747802734\n","Batch [3/105] Loss: 29.652660369873047\n","Batch [4/105] Loss: 12.691699981689453\n","Batch [5/105] Loss: 17.64986801147461\n","Batch [6/105] Loss: 38.49452590942383\n","Batch [7/105] Loss: 19.371034622192383\n","Batch [8/105] Loss: 16.193958282470703\n","Batch [9/105] Loss: 48.645023345947266\n","Batch [10/105] Loss: 16.635356903076172\n","Batch [11/105] Loss: 9.572571754455566\n","Batch [12/105] Loss: 31.552471160888672\n","Batch [13/105] Loss: 27.231670379638672\n","Batch [14/105] Loss: 49.741432189941406\n","Batch [15/105] Loss: 28.609281539916992\n","Batch [16/105] Loss: 15.80928897857666\n","Batch [17/105] Loss: 32.73265838623047\n","Batch [18/105] Loss: 18.830432891845703\n","Batch [19/105] Loss: 13.136573791503906\n","Batch [20/105] Loss: 17.9215087890625\n","Batch [21/105] Loss: 9.653801918029785\n","Batch [22/105] Loss: 31.450580596923828\n","Batch [23/105] Loss: 16.275848388671875\n","Batch [24/105] Loss: 32.84672927856445\n","Batch [25/105] Loss: 24.424165725708008\n","Batch [26/105] Loss: 43.35417556762695\n","Batch [27/105] Loss: 45.91461944580078\n","Batch [28/105] Loss: 23.13582992553711\n","Batch [29/105] Loss: 3.556938886642456\n","Batch [30/105] Loss: 9.581969261169434\n","Batch [31/105] Loss: 24.908092498779297\n","Batch [32/105] Loss: 13.867122650146484\n","Batch [33/105] Loss: 17.031951904296875\n","Batch [34/105] Loss: 40.73479080200195\n","Batch [35/105] Loss: 42.60038757324219\n","Batch [36/105] Loss: 21.281314849853516\n","Batch [37/105] Loss: 28.611099243164062\n","Batch [38/105] Loss: 36.37443542480469\n","Batch [39/105] Loss: 15.730135917663574\n","Batch [40/105] Loss: 59.654075622558594\n","Batch [41/105] Loss: 16.022926330566406\n","Batch [42/105] Loss: 20.797527313232422\n","Batch [43/105] Loss: 57.4589729309082\n","Batch [44/105] Loss: 21.478662490844727\n","Batch [45/105] Loss: 19.40162467956543\n","Batch [46/105] Loss: 12.135984420776367\n","Batch [47/105] Loss: 10.02110481262207\n","Batch [48/105] Loss: 14.41152572631836\n","Batch [49/105] Loss: 50.052188873291016\n","Batch [50/105] Loss: 14.876656532287598\n","Batch [51/105] Loss: 23.55466079711914\n","Batch [52/105] Loss: 31.169761657714844\n","Batch [53/105] Loss: 38.56916809082031\n","Batch [54/105] Loss: 25.744430541992188\n","Batch [55/105] Loss: 14.734870910644531\n","Batch [56/105] Loss: 14.238587379455566\n","Batch [57/105] Loss: 10.057621955871582\n","Batch [58/105] Loss: 15.453930854797363\n","Batch [59/105] Loss: 16.746177673339844\n","Batch [60/105] Loss: 11.736648559570312\n","Batch [61/105] Loss: 52.827449798583984\n","Batch [62/105] Loss: 23.27667236328125\n","Batch [63/105] Loss: 64.26983642578125\n","Batch [64/105] Loss: 4.954129219055176\n","Batch [65/105] Loss: 19.582927703857422\n","Batch [66/105] Loss: 11.47024154663086\n","Batch [67/105] Loss: 34.01598358154297\n","Batch [68/105] Loss: 24.140239715576172\n","Batch [69/105] Loss: 11.049144744873047\n","Batch [70/105] Loss: 5.689858436584473\n","Batch [71/105] Loss: 7.66926908493042\n","Batch [72/105] Loss: 73.12734985351562\n","Batch [73/105] Loss: 11.884909629821777\n","Batch [74/105] Loss: 10.958980560302734\n","Batch [75/105] Loss: 20.46790885925293\n","Batch [76/105] Loss: 22.615297317504883\n","Batch [77/105] Loss: 18.77089500427246\n","Batch [78/105] Loss: 18.669662475585938\n","Batch [79/105] Loss: 34.883575439453125\n","Batch [80/105] Loss: 31.773014068603516\n","Batch [81/105] Loss: 49.16148376464844\n","Batch [82/105] Loss: 16.825790405273438\n","Batch [83/105] Loss: 14.751144409179688\n","Batch [84/105] Loss: 21.659870147705078\n","Batch [85/105] Loss: 46.55144500732422\n","Batch [86/105] Loss: 18.03815460205078\n","Batch [87/105] Loss: 28.330005645751953\n","Batch [88/105] Loss: 23.232589721679688\n","Batch [89/105] Loss: 31.43035888671875\n","Batch [90/105] Loss: 20.661823272705078\n","Batch [91/105] Loss: 9.627633094787598\n","Batch [92/105] Loss: 7.5719146728515625\n","Batch [93/105] Loss: 21.787376403808594\n","Batch [94/105] Loss: 24.22531509399414\n","Batch [95/105] Loss: 12.096384048461914\n","Batch [96/105] Loss: 11.965828895568848\n","Batch [97/105] Loss: 42.312889099121094\n","Batch [98/105] Loss: 10.716111183166504\n","Batch [99/105] Loss: 39.667659759521484\n","Batch [100/105] Loss: 14.927011489868164\n","Batch [101/105] Loss: 41.276554107666016\n","Batch [102/105] Loss: 30.399696350097656\n","Batch [103/105] Loss: 18.13393783569336\n","Batch [104/105] Loss: 21.972126007080078\n","Batch [105/105] Loss: 14.756851196289062\n","Epoch [19/50], Loss: 24.781951334362937\n","New minimum loss achieved: 24.781951334362937. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 19.631086349487305\n","Batch [2/105] Loss: 28.540252685546875\n","Batch [3/105] Loss: 10.875436782836914\n","Batch [4/105] Loss: 30.828750610351562\n","Batch [5/105] Loss: 40.69833755493164\n","Batch [6/105] Loss: 23.597444534301758\n","Batch [7/105] Loss: 7.854373931884766\n","Batch [8/105] Loss: 32.721031188964844\n","Batch [9/105] Loss: 51.209922790527344\n","Batch [10/105] Loss: 44.01600646972656\n","Batch [11/105] Loss: 27.813215255737305\n","Batch [12/105] Loss: 41.67719268798828\n","Batch [13/105] Loss: 27.80764389038086\n","Batch [14/105] Loss: 23.547527313232422\n","Batch [15/105] Loss: 31.62421226501465\n","Batch [16/105] Loss: 18.946575164794922\n","Batch [17/105] Loss: 18.95465660095215\n","Batch [18/105] Loss: 31.459747314453125\n","Batch [19/105] Loss: 19.883495330810547\n","Batch [20/105] Loss: 18.693492889404297\n","Batch [21/105] Loss: 35.978084564208984\n","Batch [22/105] Loss: 21.792774200439453\n","Batch [23/105] Loss: 28.091659545898438\n","Batch [24/105] Loss: 39.177310943603516\n","Batch [25/105] Loss: 25.457090377807617\n","Batch [26/105] Loss: 43.01543426513672\n","Batch [27/105] Loss: 15.813432693481445\n","Batch [28/105] Loss: 19.892196655273438\n","Batch [29/105] Loss: 49.54198455810547\n","Batch [30/105] Loss: 47.22547912597656\n","Batch [31/105] Loss: 25.62779998779297\n","Batch [32/105] Loss: 17.96393585205078\n","Batch [33/105] Loss: 22.880762100219727\n","Batch [34/105] Loss: 20.89992904663086\n","Batch [35/105] Loss: 82.15070343017578\n","Batch [36/105] Loss: 28.01801872253418\n","Batch [37/105] Loss: 23.499521255493164\n","Batch [38/105] Loss: 26.484664916992188\n","Batch [39/105] Loss: 25.592365264892578\n","Batch [40/105] Loss: 21.99007225036621\n","Batch [41/105] Loss: 16.744369506835938\n","Batch [42/105] Loss: 49.87649917602539\n","Batch [43/105] Loss: 27.232982635498047\n","Batch [44/105] Loss: 16.20854377746582\n","Batch [45/105] Loss: 48.64772033691406\n","Batch [46/105] Loss: 21.516874313354492\n","Batch [47/105] Loss: 12.496843338012695\n","Batch [48/105] Loss: 12.393514633178711\n","Batch [49/105] Loss: 21.543655395507812\n","Batch [50/105] Loss: 6.532499313354492\n","Batch [51/105] Loss: 19.249500274658203\n","Batch [52/105] Loss: 15.70467472076416\n","Batch [53/105] Loss: 12.641824722290039\n","Batch [54/105] Loss: 8.25344181060791\n","Batch [55/105] Loss: 35.790313720703125\n","Batch [56/105] Loss: 6.569479942321777\n","Batch [57/105] Loss: 16.294567108154297\n","Batch [58/105] Loss: 16.486129760742188\n","Batch [59/105] Loss: 14.673738479614258\n","Batch [60/105] Loss: 25.805967330932617\n","Batch [61/105] Loss: 68.45032501220703\n","Batch [62/105] Loss: 10.152706146240234\n","Batch [63/105] Loss: 25.109683990478516\n","Batch [64/105] Loss: 29.47935676574707\n","Batch [65/105] Loss: 61.3660888671875\n","Batch [66/105] Loss: 17.628612518310547\n","Batch [67/105] Loss: 25.915565490722656\n","Batch [68/105] Loss: 71.22940826416016\n","Batch [69/105] Loss: 8.826009750366211\n","Batch [70/105] Loss: 9.719640731811523\n","Batch [71/105] Loss: 30.650236129760742\n","Batch [72/105] Loss: 24.44672393798828\n","Batch [73/105] Loss: 14.847726821899414\n","Batch [74/105] Loss: 55.14606857299805\n","Batch [75/105] Loss: 42.409332275390625\n","Batch [76/105] Loss: 28.06122589111328\n","Batch [77/105] Loss: 14.545973777770996\n","Batch [78/105] Loss: 15.063191413879395\n","Batch [79/105] Loss: 38.11798858642578\n","Batch [80/105] Loss: 29.01849365234375\n","Batch [81/105] Loss: 27.675762176513672\n","Batch [82/105] Loss: 56.6554069519043\n","Batch [83/105] Loss: 37.513458251953125\n","Batch [84/105] Loss: 17.5972900390625\n","Batch [85/105] Loss: 10.57691764831543\n","Batch [86/105] Loss: 18.275047302246094\n","Batch [87/105] Loss: 55.771484375\n","Batch [88/105] Loss: 21.746984481811523\n","Batch [89/105] Loss: 27.421924591064453\n","Batch [90/105] Loss: 26.42298698425293\n","Batch [91/105] Loss: 36.89468765258789\n","Batch [92/105] Loss: 20.227895736694336\n","Batch [93/105] Loss: 26.04164695739746\n","Batch [94/105] Loss: 25.219341278076172\n","Batch [95/105] Loss: 9.175084114074707\n","Batch [96/105] Loss: 27.06723976135254\n","Batch [97/105] Loss: 12.27605152130127\n","Batch [98/105] Loss: 37.10178756713867\n","Batch [99/105] Loss: 34.31698226928711\n","Batch [100/105] Loss: 11.739720344543457\n","Batch [101/105] Loss: 9.138103485107422\n","Batch [102/105] Loss: 37.14720916748047\n","Batch [103/105] Loss: 20.627504348754883\n","Batch [104/105] Loss: 63.94673156738281\n","Batch [105/105] Loss: 9.815264701843262\n","Epoch [20/50], Loss: 27.397272700355167\n","Batch [1/105] Loss: 56.4080810546875\n","Batch [2/105] Loss: 10.195596694946289\n","Batch [3/105] Loss: 13.164530754089355\n","Batch [4/105] Loss: 8.936636924743652\n","Batch [5/105] Loss: 21.199155807495117\n","Batch [6/105] Loss: 9.918328285217285\n","Batch [7/105] Loss: 8.840869903564453\n","Batch [8/105] Loss: 12.320268630981445\n","Batch [9/105] Loss: 38.80595397949219\n","Batch [10/105] Loss: 9.603029251098633\n","Batch [11/105] Loss: 22.670570373535156\n","Batch [12/105] Loss: 19.441720962524414\n","Batch [13/105] Loss: 30.437015533447266\n","Batch [14/105] Loss: 24.811634063720703\n","Batch [15/105] Loss: 49.52765655517578\n","Batch [16/105] Loss: 22.214649200439453\n","Batch [17/105] Loss: 21.055044174194336\n","Batch [18/105] Loss: 70.55084991455078\n","Batch [19/105] Loss: 26.931163787841797\n","Batch [20/105] Loss: 12.286420822143555\n","Batch [21/105] Loss: 30.463241577148438\n","Batch [22/105] Loss: 8.53135871887207\n","Batch [23/105] Loss: 13.827413558959961\n","Batch [24/105] Loss: 25.328689575195312\n","Batch [25/105] Loss: 14.306324005126953\n","Batch [26/105] Loss: 13.517097473144531\n","Batch [27/105] Loss: 55.50641632080078\n","Batch [28/105] Loss: 28.091827392578125\n","Batch [29/105] Loss: 11.527849197387695\n","Batch [30/105] Loss: 7.201559066772461\n","Batch [31/105] Loss: 54.492835998535156\n","Batch [32/105] Loss: 34.148494720458984\n","Batch [33/105] Loss: 5.734818458557129\n","Batch [34/105] Loss: 10.945549964904785\n","Batch [35/105] Loss: 24.51692771911621\n","Batch [36/105] Loss: 6.729999542236328\n","Batch [37/105] Loss: 12.515032768249512\n","Batch [38/105] Loss: 19.116451263427734\n","Batch [39/105] Loss: 34.917930603027344\n","Batch [40/105] Loss: 14.859085083007812\n","Batch [41/105] Loss: 20.471403121948242\n","Batch [42/105] Loss: 10.517642974853516\n","Batch [43/105] Loss: 35.042728424072266\n","Batch [44/105] Loss: 26.983285903930664\n","Batch [45/105] Loss: 25.168987274169922\n","Batch [46/105] Loss: 7.5196943283081055\n","Batch [47/105] Loss: 24.199291229248047\n","Batch [48/105] Loss: 19.166126251220703\n","Batch [49/105] Loss: 39.13689422607422\n","Batch [50/105] Loss: 19.722370147705078\n","Batch [51/105] Loss: 26.358144760131836\n","Batch [52/105] Loss: 20.81505012512207\n","Batch [53/105] Loss: 39.761322021484375\n","Batch [54/105] Loss: 23.678131103515625\n","Batch [55/105] Loss: 25.725982666015625\n","Batch [56/105] Loss: 7.272295951843262\n","Batch [57/105] Loss: 7.631659507751465\n","Batch [58/105] Loss: 20.643104553222656\n","Batch [59/105] Loss: 16.202770233154297\n","Batch [60/105] Loss: 20.096601486206055\n","Batch [61/105] Loss: 39.17054748535156\n","Batch [62/105] Loss: 16.617029190063477\n","Batch [63/105] Loss: 13.157928466796875\n","Batch [64/105] Loss: 17.179086685180664\n","Batch [65/105] Loss: 27.420223236083984\n","Batch [66/105] Loss: 15.200881958007812\n","Batch [67/105] Loss: 47.197608947753906\n","Batch [68/105] Loss: 19.142086029052734\n","Batch [69/105] Loss: 23.511852264404297\n","Batch [70/105] Loss: 18.43103790283203\n","Batch [71/105] Loss: 22.17254638671875\n","Batch [72/105] Loss: 44.562015533447266\n","Batch [73/105] Loss: 28.31521224975586\n","Batch [74/105] Loss: 38.34678649902344\n","Batch [75/105] Loss: 38.90467071533203\n","Batch [76/105] Loss: 19.53380012512207\n","Batch [77/105] Loss: 12.363103866577148\n","Batch [78/105] Loss: 33.340694427490234\n","Batch [79/105] Loss: 25.583148956298828\n","Batch [80/105] Loss: 72.8663330078125\n","Batch [81/105] Loss: 21.04709815979004\n","Batch [82/105] Loss: 14.23674201965332\n","Batch [83/105] Loss: 10.707074165344238\n","Batch [84/105] Loss: 33.76382064819336\n","Batch [85/105] Loss: 8.973654747009277\n","Batch [86/105] Loss: 10.306441307067871\n","Batch [87/105] Loss: 37.469791412353516\n","Batch [88/105] Loss: 15.434990882873535\n","Batch [89/105] Loss: 22.897546768188477\n","Batch [90/105] Loss: 21.380722045898438\n","Batch [91/105] Loss: 45.23751449584961\n","Batch [92/105] Loss: 15.797576904296875\n","Batch [93/105] Loss: 14.745656967163086\n","Batch [94/105] Loss: 20.903818130493164\n","Batch [95/105] Loss: 14.117330551147461\n","Batch [96/105] Loss: 39.066139221191406\n","Batch [97/105] Loss: 26.462142944335938\n","Batch [98/105] Loss: 26.655418395996094\n","Batch [99/105] Loss: 33.21757507324219\n","Batch [100/105] Loss: 13.781425476074219\n","Batch [101/105] Loss: 12.322479248046875\n","Batch [102/105] Loss: 7.367964267730713\n","Batch [103/105] Loss: 12.285979270935059\n","Batch [104/105] Loss: 17.03984832763672\n","Batch [105/105] Loss: 13.526001930236816\n","Epoch [21/50], Loss: 23.17593250728789\n","New minimum loss achieved: 23.17593250728789. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 13.389314651489258\n","Batch [2/105] Loss: 11.10488224029541\n","Batch [3/105] Loss: 6.578935623168945\n","Batch [4/105] Loss: 36.86968994140625\n","Batch [5/105] Loss: 8.773242950439453\n","Batch [6/105] Loss: 31.690282821655273\n","Batch [7/105] Loss: 30.680011749267578\n","Batch [8/105] Loss: 30.28437042236328\n","Batch [9/105] Loss: 21.95464324951172\n","Batch [10/105] Loss: 29.315149307250977\n","Batch [11/105] Loss: 7.413164138793945\n","Batch [12/105] Loss: 10.677847862243652\n","Batch [13/105] Loss: 26.739274978637695\n","Batch [14/105] Loss: 40.76922607421875\n","Batch [15/105] Loss: 32.29433059692383\n","Batch [16/105] Loss: 17.08966827392578\n","Batch [17/105] Loss: 17.56844139099121\n","Batch [18/105] Loss: 6.111910343170166\n","Batch [19/105] Loss: 30.58905029296875\n","Batch [20/105] Loss: 20.59636688232422\n","Batch [21/105] Loss: 21.52055549621582\n","Batch [22/105] Loss: 30.42983055114746\n","Batch [23/105] Loss: 36.283809661865234\n","Batch [24/105] Loss: 15.008045196533203\n","Batch [25/105] Loss: 22.57090187072754\n","Batch [26/105] Loss: 47.15227127075195\n","Batch [27/105] Loss: 36.51530456542969\n","Batch [28/105] Loss: 13.411996841430664\n","Batch [29/105] Loss: 11.579554557800293\n","Batch [30/105] Loss: 17.85619354248047\n","Batch [31/105] Loss: 16.045320510864258\n","Batch [32/105] Loss: 74.19666290283203\n","Batch [33/105] Loss: 56.27855682373047\n","Batch [34/105] Loss: 20.498458862304688\n","Batch [35/105] Loss: 11.458263397216797\n","Batch [36/105] Loss: 20.34372329711914\n","Batch [37/105] Loss: 21.02446746826172\n","Batch [38/105] Loss: 14.52471923828125\n","Batch [39/105] Loss: 20.290237426757812\n","Batch [40/105] Loss: 30.17206573486328\n","Batch [41/105] Loss: 35.36787414550781\n","Batch [42/105] Loss: 24.580509185791016\n","Batch [43/105] Loss: 29.705364227294922\n","Batch [44/105] Loss: 20.392602920532227\n","Batch [45/105] Loss: 48.70099639892578\n","Batch [46/105] Loss: 21.01036834716797\n","Batch [47/105] Loss: 23.74751853942871\n","Batch [48/105] Loss: 25.203323364257812\n","Batch [49/105] Loss: 21.475894927978516\n","Batch [50/105] Loss: 10.586174011230469\n","Batch [51/105] Loss: 41.257877349853516\n","Batch [52/105] Loss: 8.222551345825195\n","Batch [53/105] Loss: 52.69196319580078\n","Batch [54/105] Loss: 24.566234588623047\n","Batch [55/105] Loss: 20.304454803466797\n","Batch [56/105] Loss: 24.891578674316406\n","Batch [57/105] Loss: 23.70711326599121\n","Batch [58/105] Loss: 41.731178283691406\n","Batch [59/105] Loss: 71.16822814941406\n","Batch [60/105] Loss: 16.85381317138672\n","Batch [61/105] Loss: 30.694292068481445\n","Batch [62/105] Loss: 10.530105590820312\n","Batch [63/105] Loss: 51.440757751464844\n","Batch [64/105] Loss: 30.528743743896484\n","Batch [65/105] Loss: 10.120804786682129\n","Batch [66/105] Loss: 22.203094482421875\n","Batch [67/105] Loss: 31.07714080810547\n","Batch [68/105] Loss: 56.3951416015625\n","Batch [69/105] Loss: 7.882246017456055\n","Batch [70/105] Loss: 30.74736213684082\n","Batch [71/105] Loss: 82.45684814453125\n","Batch [72/105] Loss: 20.98409652709961\n","Batch [73/105] Loss: 10.680904388427734\n","Batch [74/105] Loss: 14.100077629089355\n","Batch [75/105] Loss: 21.375823974609375\n","Batch [76/105] Loss: 13.274322509765625\n","Batch [77/105] Loss: 29.79071807861328\n","Batch [78/105] Loss: 14.977520942687988\n","Batch [79/105] Loss: 94.9324951171875\n","Batch [80/105] Loss: 18.996871948242188\n","Batch [81/105] Loss: 15.560174942016602\n","Batch [82/105] Loss: 10.310517311096191\n","Batch [83/105] Loss: 20.097076416015625\n","Batch [84/105] Loss: 10.544819831848145\n","Batch [85/105] Loss: 53.15570831298828\n","Batch [86/105] Loss: 8.228541374206543\n","Batch [87/105] Loss: 17.56832504272461\n","Batch [88/105] Loss: 29.597667694091797\n","Batch [89/105] Loss: 17.875125885009766\n","Batch [90/105] Loss: 20.92689323425293\n","Batch [91/105] Loss: 58.1070556640625\n","Batch [92/105] Loss: 20.383256912231445\n","Batch [93/105] Loss: 24.48973846435547\n","Batch [94/105] Loss: 17.91303253173828\n","Batch [95/105] Loss: 12.75423812866211\n","Batch [96/105] Loss: 29.82105255126953\n","Batch [97/105] Loss: 14.29207992553711\n","Batch [98/105] Loss: 28.164608001708984\n","Batch [99/105] Loss: 33.74408721923828\n","Batch [100/105] Loss: 33.91329574584961\n","Batch [101/105] Loss: 22.87854766845703\n","Batch [102/105] Loss: 18.584110260009766\n","Batch [103/105] Loss: 12.315284729003906\n","Batch [104/105] Loss: 16.206253051757812\n","Batch [105/105] Loss: 16.738697052001953\n","Epoch [22/50], Loss: 25.915961124783472\n","Batch [1/105] Loss: 30.557506561279297\n","Batch [2/105] Loss: 13.961129188537598\n","Batch [3/105] Loss: 39.43218231201172\n","Batch [4/105] Loss: 38.18288803100586\n","Batch [5/105] Loss: 19.28152847290039\n","Batch [6/105] Loss: 41.815608978271484\n","Batch [7/105] Loss: 31.92137908935547\n","Batch [8/105] Loss: 13.33262825012207\n","Batch [9/105] Loss: 18.896621704101562\n","Batch [10/105] Loss: 5.824915885925293\n","Batch [11/105] Loss: 16.760990142822266\n","Batch [12/105] Loss: 30.328941345214844\n","Batch [13/105] Loss: 20.03817367553711\n","Batch [14/105] Loss: 10.423474311828613\n","Batch [15/105] Loss: 27.667064666748047\n","Batch [16/105] Loss: 35.500267028808594\n","Batch [17/105] Loss: 18.63619613647461\n","Batch [18/105] Loss: 14.52817440032959\n","Batch [19/105] Loss: 39.808509826660156\n","Batch [20/105] Loss: 32.544769287109375\n","Batch [21/105] Loss: 42.0038948059082\n","Batch [22/105] Loss: 30.987892150878906\n","Batch [23/105] Loss: 4.348661422729492\n","Batch [24/105] Loss: 43.65393829345703\n","Batch [25/105] Loss: 50.371665954589844\n","Batch [26/105] Loss: 21.695850372314453\n","Batch [27/105] Loss: 33.32847595214844\n","Batch [28/105] Loss: 68.94385528564453\n","Batch [29/105] Loss: 31.613712310791016\n","Batch [30/105] Loss: 21.105464935302734\n","Batch [31/105] Loss: 27.412288665771484\n","Batch [32/105] Loss: 37.512001037597656\n","Batch [33/105] Loss: 16.055160522460938\n","Batch [34/105] Loss: 10.96348762512207\n","Batch [35/105] Loss: 57.18688201904297\n","Batch [36/105] Loss: 7.61855936050415\n","Batch [37/105] Loss: 19.000015258789062\n","Batch [38/105] Loss: 29.655691146850586\n","Batch [39/105] Loss: 28.372787475585938\n","Batch [40/105] Loss: 37.90629577636719\n","Batch [41/105] Loss: 12.216607093811035\n","Batch [42/105] Loss: 9.147743225097656\n","Batch [43/105] Loss: 18.839006423950195\n","Batch [44/105] Loss: 56.45790100097656\n","Batch [45/105] Loss: 22.019447326660156\n","Batch [46/105] Loss: 18.789323806762695\n","Batch [47/105] Loss: 19.419448852539062\n","Batch [48/105] Loss: 17.526784896850586\n","Batch [49/105] Loss: 7.359565258026123\n","Batch [50/105] Loss: 22.262414932250977\n","Batch [51/105] Loss: 39.851261138916016\n","Batch [52/105] Loss: 32.79241180419922\n","Batch [53/105] Loss: 24.361215591430664\n","Batch [54/105] Loss: 23.073726654052734\n","Batch [55/105] Loss: 21.778635025024414\n","Batch [56/105] Loss: 19.825904846191406\n","Batch [57/105] Loss: 32.147010803222656\n","Batch [58/105] Loss: 13.698848724365234\n","Batch [59/105] Loss: 4.0392680168151855\n","Batch [60/105] Loss: 36.61955261230469\n","Batch [61/105] Loss: 52.13744354248047\n","Batch [62/105] Loss: 4.754491806030273\n","Batch [63/105] Loss: 24.81937026977539\n","Batch [64/105] Loss: 32.46746826171875\n","Batch [65/105] Loss: 20.919540405273438\n","Batch [66/105] Loss: 13.599588394165039\n","Batch [67/105] Loss: 56.952247619628906\n","Batch [68/105] Loss: 4.18792200088501\n","Batch [69/105] Loss: 21.962289810180664\n","Batch [70/105] Loss: 30.952980041503906\n","Batch [71/105] Loss: 28.257047653198242\n","Batch [72/105] Loss: 20.79015350341797\n","Batch [73/105] Loss: 6.173514366149902\n","Batch [74/105] Loss: 8.13005542755127\n","Batch [75/105] Loss: 6.019669532775879\n","Batch [76/105] Loss: 21.298908233642578\n","Batch [77/105] Loss: 8.232894897460938\n","Batch [78/105] Loss: 33.89983367919922\n","Batch [79/105] Loss: 30.966888427734375\n","Batch [80/105] Loss: 21.429853439331055\n","Batch [81/105] Loss: 13.551366806030273\n","Batch [82/105] Loss: 20.85426902770996\n","Batch [83/105] Loss: 11.637472152709961\n","Batch [84/105] Loss: 10.85060977935791\n","Batch [85/105] Loss: 34.95777130126953\n","Batch [86/105] Loss: 21.50383758544922\n","Batch [87/105] Loss: 8.442438125610352\n","Batch [88/105] Loss: 8.18264102935791\n","Batch [89/105] Loss: 14.19715404510498\n","Batch [90/105] Loss: 10.529464721679688\n","Batch [91/105] Loss: 24.810321807861328\n","Batch [92/105] Loss: 69.26824188232422\n","Batch [93/105] Loss: 19.506755828857422\n","Batch [94/105] Loss: 18.341941833496094\n","Batch [95/105] Loss: 11.49428653717041\n","Batch [96/105] Loss: 10.194353103637695\n","Batch [97/105] Loss: 8.306707382202148\n","Batch [98/105] Loss: 32.938079833984375\n","Batch [99/105] Loss: 11.889572143554688\n","Batch [100/105] Loss: 11.082002639770508\n","Batch [101/105] Loss: 42.33119201660156\n","Batch [102/105] Loss: 42.330528259277344\n","Batch [103/105] Loss: 8.341095924377441\n","Batch [104/105] Loss: 84.71987915039062\n","Batch [105/105] Loss: 33.29172897338867\n","Epoch [23/50], Loss: 24.7896331514631\n","Batch [1/105] Loss: 17.90170669555664\n","Batch [2/105] Loss: 29.843814849853516\n","Batch [3/105] Loss: 5.0238261222839355\n","Batch [4/105] Loss: 12.732821464538574\n","Batch [5/105] Loss: 20.024578094482422\n","Batch [6/105] Loss: 19.819679260253906\n","Batch [7/105] Loss: 31.256200790405273\n","Batch [8/105] Loss: 23.123441696166992\n","Batch [9/105] Loss: 5.719764709472656\n","Batch [10/105] Loss: 32.157527923583984\n","Batch [11/105] Loss: 25.656728744506836\n","Batch [12/105] Loss: 23.24496078491211\n","Batch [13/105] Loss: 19.907102584838867\n","Batch [14/105] Loss: 14.722330093383789\n","Batch [15/105] Loss: 22.100418090820312\n","Batch [16/105] Loss: 45.063255310058594\n","Batch [17/105] Loss: 12.331424713134766\n","Batch [18/105] Loss: 28.882381439208984\n","Batch [19/105] Loss: 15.213967323303223\n","Batch [20/105] Loss: 25.613689422607422\n","Batch [21/105] Loss: 25.66960906982422\n","Batch [22/105] Loss: 29.43514633178711\n","Batch [23/105] Loss: 11.604962348937988\n","Batch [24/105] Loss: 20.404193878173828\n","Batch [25/105] Loss: 59.2857551574707\n","Batch [26/105] Loss: 21.40735626220703\n","Batch [27/105] Loss: 29.840837478637695\n","Batch [28/105] Loss: 11.223945617675781\n","Batch [29/105] Loss: 8.348172187805176\n","Batch [30/105] Loss: 22.211238861083984\n","Batch [31/105] Loss: 25.565330505371094\n","Batch [32/105] Loss: 4.067511081695557\n","Batch [33/105] Loss: 19.565780639648438\n","Batch [34/105] Loss: 30.75267219543457\n","Batch [35/105] Loss: 19.501853942871094\n","Batch [36/105] Loss: 59.81499481201172\n","Batch [37/105] Loss: 17.138320922851562\n","Batch [38/105] Loss: 10.718720436096191\n","Batch [39/105] Loss: 26.921024322509766\n","Batch [40/105] Loss: 40.15193176269531\n","Batch [41/105] Loss: 18.340335845947266\n","Batch [42/105] Loss: 14.786020278930664\n","Batch [43/105] Loss: 5.720113754272461\n","Batch [44/105] Loss: 13.271490097045898\n","Batch [45/105] Loss: 43.26154327392578\n","Batch [46/105] Loss: 8.267197608947754\n","Batch [47/105] Loss: 35.369441986083984\n","Batch [48/105] Loss: 8.706612586975098\n","Batch [49/105] Loss: 28.70816421508789\n","Batch [50/105] Loss: 33.81603240966797\n","Batch [51/105] Loss: 17.309906005859375\n","Batch [52/105] Loss: 14.63538932800293\n","Batch [53/105] Loss: 37.50028610229492\n","Batch [54/105] Loss: 47.33777618408203\n","Batch [55/105] Loss: 6.524228096008301\n","Batch [56/105] Loss: 30.567626953125\n","Batch [57/105] Loss: 5.228367328643799\n","Batch [58/105] Loss: 18.847740173339844\n","Batch [59/105] Loss: 28.271270751953125\n","Batch [60/105] Loss: 15.43537712097168\n","Batch [61/105] Loss: 18.403987884521484\n","Batch [62/105] Loss: 49.39574432373047\n","Batch [63/105] Loss: 15.560312271118164\n","Batch [64/105] Loss: 23.981801986694336\n","Batch [65/105] Loss: 26.258647918701172\n","Batch [66/105] Loss: 16.891469955444336\n","Batch [67/105] Loss: 22.21139144897461\n","Batch [68/105] Loss: 13.746255874633789\n","Batch [69/105] Loss: 6.8887939453125\n","Batch [70/105] Loss: 38.577362060546875\n","Batch [71/105] Loss: 28.147594451904297\n","Batch [72/105] Loss: 21.042476654052734\n","Batch [73/105] Loss: 68.0824966430664\n","Batch [74/105] Loss: 16.347713470458984\n","Batch [75/105] Loss: 11.533374786376953\n","Batch [76/105] Loss: 24.28780174255371\n","Batch [77/105] Loss: 8.51388931274414\n","Batch [78/105] Loss: 14.031603813171387\n","Batch [79/105] Loss: 6.524025917053223\n","Batch [80/105] Loss: 17.221336364746094\n","Batch [81/105] Loss: 7.673099040985107\n","Batch [82/105] Loss: 23.294837951660156\n","Batch [83/105] Loss: 30.39988136291504\n","Batch [84/105] Loss: 71.689453125\n","Batch [85/105] Loss: 45.97468566894531\n","Batch [86/105] Loss: 35.43656921386719\n","Batch [87/105] Loss: 45.942726135253906\n","Batch [88/105] Loss: 22.930078506469727\n","Batch [89/105] Loss: 66.64350891113281\n","Batch [90/105] Loss: 24.273330688476562\n","Batch [91/105] Loss: 10.261502265930176\n","Batch [92/105] Loss: 15.9426908493042\n","Batch [93/105] Loss: 6.784738540649414\n","Batch [94/105] Loss: 15.988348007202148\n","Batch [95/105] Loss: 12.977117538452148\n","Batch [96/105] Loss: 6.389354705810547\n","Batch [97/105] Loss: 20.63652992248535\n","Batch [98/105] Loss: 6.204086780548096\n","Batch [99/105] Loss: 22.77369499206543\n","Batch [100/105] Loss: 15.76458740234375\n","Batch [101/105] Loss: 18.895387649536133\n","Batch [102/105] Loss: 30.117305755615234\n","Batch [103/105] Loss: 42.68443298339844\n","Batch [104/105] Loss: 14.786063194274902\n","Batch [105/105] Loss: 19.208839416503906\n","Epoch [24/50], Loss: 23.21137932822818\n","Batch [1/105] Loss: 18.613834381103516\n","Batch [2/105] Loss: 13.662884712219238\n","Batch [3/105] Loss: 23.811351776123047\n","Batch [4/105] Loss: 67.64647674560547\n","Batch [5/105] Loss: 25.770709991455078\n","Batch [6/105] Loss: 27.583955764770508\n","Batch [7/105] Loss: 21.102996826171875\n","Batch [8/105] Loss: 22.69243049621582\n","Batch [9/105] Loss: 3.20692777633667\n","Batch [10/105] Loss: 13.912737846374512\n","Batch [11/105] Loss: 25.579940795898438\n","Batch [12/105] Loss: 23.680438995361328\n","Batch [13/105] Loss: 15.54944896697998\n","Batch [14/105] Loss: 14.99499225616455\n","Batch [15/105] Loss: 9.576457977294922\n","Batch [16/105] Loss: 5.045830249786377\n","Batch [17/105] Loss: 44.27689743041992\n","Batch [18/105] Loss: 53.326255798339844\n","Batch [19/105] Loss: 12.042274475097656\n","Batch [20/105] Loss: 21.045032501220703\n","Batch [21/105] Loss: 34.243160247802734\n","Batch [22/105] Loss: 25.923086166381836\n","Batch [23/105] Loss: 22.436159133911133\n","Batch [24/105] Loss: 10.17236328125\n","Batch [25/105] Loss: 22.553184509277344\n","Batch [26/105] Loss: 29.02853012084961\n","Batch [27/105] Loss: 27.836944580078125\n","Batch [28/105] Loss: 19.476415634155273\n","Batch [29/105] Loss: 11.674298286437988\n","Batch [30/105] Loss: 16.387676239013672\n","Batch [31/105] Loss: 19.73419952392578\n","Batch [32/105] Loss: 20.420808792114258\n","Batch [33/105] Loss: 8.917547225952148\n","Batch [34/105] Loss: 15.43702507019043\n","Batch [35/105] Loss: 15.603017807006836\n","Batch [36/105] Loss: 11.301300048828125\n","Batch [37/105] Loss: 71.5964126586914\n","Batch [38/105] Loss: 33.206783294677734\n","Batch [39/105] Loss: 30.963111877441406\n","Batch [40/105] Loss: 34.261817932128906\n","Batch [41/105] Loss: 33.701202392578125\n","Batch [42/105] Loss: 23.37126922607422\n","Batch [43/105] Loss: 11.575671195983887\n","Batch [44/105] Loss: 32.797386169433594\n","Batch [45/105] Loss: 8.510602951049805\n","Batch [46/105] Loss: 14.568222045898438\n","Batch [47/105] Loss: 9.459174156188965\n","Batch [48/105] Loss: 8.993160247802734\n","Batch [49/105] Loss: 9.73293685913086\n","Batch [50/105] Loss: 28.749706268310547\n","Batch [51/105] Loss: 17.884445190429688\n","Batch [52/105] Loss: 32.30093002319336\n","Batch [53/105] Loss: 29.59597396850586\n","Batch [54/105] Loss: 11.373271942138672\n","Batch [55/105] Loss: 33.92770767211914\n","Batch [56/105] Loss: 10.753902435302734\n","Batch [57/105] Loss: 29.595951080322266\n","Batch [58/105] Loss: 5.286550045013428\n","Batch [59/105] Loss: 23.511539459228516\n","Batch [60/105] Loss: 35.47922134399414\n","Batch [61/105] Loss: 11.461923599243164\n","Batch [62/105] Loss: 24.994991302490234\n","Batch [63/105] Loss: 19.299699783325195\n","Batch [64/105] Loss: 47.1876335144043\n","Batch [65/105] Loss: 12.488840103149414\n","Batch [66/105] Loss: 7.703853130340576\n","Batch [67/105] Loss: 14.85515308380127\n","Batch [68/105] Loss: 19.257644653320312\n","Batch [69/105] Loss: 15.044644355773926\n","Batch [70/105] Loss: 40.1434211730957\n","Batch [71/105] Loss: 20.209205627441406\n","Batch [72/105] Loss: 31.736860275268555\n","Batch [73/105] Loss: 22.548717498779297\n","Batch [74/105] Loss: 11.576414108276367\n","Batch [75/105] Loss: 15.738336563110352\n","Batch [76/105] Loss: 35.02239227294922\n","Batch [77/105] Loss: 42.235504150390625\n","Batch [78/105] Loss: 46.02142333984375\n","Batch [79/105] Loss: 25.64071273803711\n","Batch [80/105] Loss: 8.380687713623047\n","Batch [81/105] Loss: 7.481537818908691\n","Batch [82/105] Loss: 40.36433410644531\n","Batch [83/105] Loss: 28.689706802368164\n","Batch [84/105] Loss: 15.454575538635254\n","Batch [85/105] Loss: 34.245487213134766\n","Batch [86/105] Loss: 13.711443901062012\n","Batch [87/105] Loss: 15.809837341308594\n","Batch [88/105] Loss: 37.0652961730957\n","Batch [89/105] Loss: 19.097993850708008\n","Batch [90/105] Loss: 23.685396194458008\n","Batch [91/105] Loss: 19.542465209960938\n","Batch [92/105] Loss: 20.213701248168945\n","Batch [93/105] Loss: 27.051401138305664\n","Batch [94/105] Loss: 18.26325225830078\n","Batch [95/105] Loss: 17.52337646484375\n","Batch [96/105] Loss: 19.407817840576172\n","Batch [97/105] Loss: 34.592689514160156\n","Batch [98/105] Loss: 20.544811248779297\n","Batch [99/105] Loss: 13.65552043914795\n","Batch [100/105] Loss: 32.44742202758789\n","Batch [101/105] Loss: 28.026752471923828\n","Batch [102/105] Loss: 37.449363708496094\n","Batch [103/105] Loss: 24.223541259765625\n","Batch [104/105] Loss: 37.276123046875\n","Batch [105/105] Loss: 19.28217887878418\n","Epoch [25/50], Loss: 23.163034548078265\n","New minimum loss achieved: 23.163034548078265. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 13.123964309692383\n","Batch [2/105] Loss: 12.82390308380127\n","Batch [3/105] Loss: 19.66579246520996\n","Batch [4/105] Loss: 10.905247688293457\n","Batch [5/105] Loss: 44.84912109375\n","Batch [6/105] Loss: 35.25749206542969\n","Batch [7/105] Loss: 38.47615432739258\n","Batch [8/105] Loss: 22.371414184570312\n","Batch [9/105] Loss: 36.08103942871094\n","Batch [10/105] Loss: 19.238048553466797\n","Batch [11/105] Loss: 8.58867073059082\n","Batch [12/105] Loss: 70.4631576538086\n","Batch [13/105] Loss: 19.605018615722656\n","Batch [14/105] Loss: 20.467369079589844\n","Batch [15/105] Loss: 34.1463623046875\n","Batch [16/105] Loss: 52.855743408203125\n","Batch [17/105] Loss: 14.935968399047852\n","Batch [18/105] Loss: 11.908077239990234\n","Batch [19/105] Loss: 12.045883178710938\n","Batch [20/105] Loss: 16.127382278442383\n","Batch [21/105] Loss: 33.87544250488281\n","Batch [22/105] Loss: 39.57919692993164\n","Batch [23/105] Loss: 47.58596420288086\n","Batch [24/105] Loss: 54.24605941772461\n","Batch [25/105] Loss: 31.417171478271484\n","Batch [26/105] Loss: 9.663105010986328\n","Batch [27/105] Loss: 17.77606201171875\n","Batch [28/105] Loss: 15.285848617553711\n","Batch [29/105] Loss: 10.774206161499023\n","Batch [30/105] Loss: 26.7166690826416\n","Batch [31/105] Loss: 13.985784530639648\n","Batch [32/105] Loss: 47.64604187011719\n","Batch [33/105] Loss: 24.888992309570312\n","Batch [34/105] Loss: 18.913240432739258\n","Batch [35/105] Loss: 8.229360580444336\n","Batch [36/105] Loss: 37.2958984375\n","Batch [37/105] Loss: 57.643524169921875\n","Batch [38/105] Loss: 16.917627334594727\n","Batch [39/105] Loss: 19.82028579711914\n","Batch [40/105] Loss: 25.434579849243164\n","Batch [41/105] Loss: 21.085533142089844\n","Batch [42/105] Loss: 32.195533752441406\n","Batch [43/105] Loss: 10.823102951049805\n","Batch [44/105] Loss: 9.591976165771484\n","Batch [45/105] Loss: 9.983043670654297\n","Batch [46/105] Loss: 27.493192672729492\n","Batch [47/105] Loss: 18.05723762512207\n","Batch [48/105] Loss: 23.060895919799805\n","Batch [49/105] Loss: 54.5494270324707\n","Batch [50/105] Loss: 37.227928161621094\n","Batch [51/105] Loss: 14.754717826843262\n","Batch [52/105] Loss: 24.85995101928711\n","Batch [53/105] Loss: 16.245834350585938\n","Batch [54/105] Loss: 27.397382736206055\n","Batch [55/105] Loss: 30.98200225830078\n","Batch [56/105] Loss: 19.39012336730957\n","Batch [57/105] Loss: 28.463390350341797\n","Batch [58/105] Loss: 38.99866485595703\n","Batch [59/105] Loss: 29.148914337158203\n","Batch [60/105] Loss: 7.237789154052734\n","Batch [61/105] Loss: 6.975214004516602\n","Batch [62/105] Loss: 33.97563171386719\n","Batch [63/105] Loss: 23.910791397094727\n","Batch [64/105] Loss: 35.011497497558594\n","Batch [65/105] Loss: 33.3416633605957\n","Batch [66/105] Loss: 11.715022087097168\n","Batch [67/105] Loss: 22.579069137573242\n","Batch [68/105] Loss: 7.292750835418701\n","Batch [69/105] Loss: 45.16986083984375\n","Batch [70/105] Loss: 21.24951934814453\n","Batch [71/105] Loss: 14.160440444946289\n","Batch [72/105] Loss: 16.07899284362793\n","Batch [73/105] Loss: 18.46600341796875\n","Batch [74/105] Loss: 46.44907760620117\n","Batch [75/105] Loss: 41.070892333984375\n","Batch [76/105] Loss: 39.67240524291992\n","Batch [77/105] Loss: 12.812019348144531\n","Batch [78/105] Loss: 47.675132751464844\n","Batch [79/105] Loss: 11.505607604980469\n","Batch [80/105] Loss: 9.93661880493164\n","Batch [81/105] Loss: 24.72252655029297\n","Batch [82/105] Loss: 15.019420623779297\n","Batch [83/105] Loss: 14.138132095336914\n","Batch [84/105] Loss: 14.372929573059082\n","Batch [85/105] Loss: 15.177349090576172\n","Batch [86/105] Loss: 13.00819206237793\n","Batch [87/105] Loss: 43.562408447265625\n","Batch [88/105] Loss: 15.336665153503418\n","Batch [89/105] Loss: 31.395395278930664\n","Batch [90/105] Loss: 14.135689735412598\n","Batch [91/105] Loss: 8.724451065063477\n","Batch [92/105] Loss: 24.949661254882812\n","Batch [93/105] Loss: 28.646469116210938\n","Batch [94/105] Loss: 10.16797161102295\n","Batch [95/105] Loss: 33.107505798339844\n","Batch [96/105] Loss: 11.545491218566895\n","Batch [97/105] Loss: 32.590614318847656\n","Batch [98/105] Loss: 12.931986808776855\n","Batch [99/105] Loss: 10.047629356384277\n","Batch [100/105] Loss: 18.838157653808594\n","Batch [101/105] Loss: 14.785348892211914\n","Batch [102/105] Loss: 17.308305740356445\n","Batch [103/105] Loss: 19.11298179626465\n","Batch [104/105] Loss: 18.99492645263672\n","Batch [105/105] Loss: 10.573055267333984\n","Epoch [26/50], Loss: 24.051609407152448\n","Batch [1/105] Loss: 22.105789184570312\n","Batch [2/105] Loss: 10.503559112548828\n","Batch [3/105] Loss: 13.685750961303711\n","Batch [4/105] Loss: 15.880810737609863\n","Batch [5/105] Loss: 7.778255462646484\n","Batch [6/105] Loss: 9.97327709197998\n","Batch [7/105] Loss: 11.501110076904297\n","Batch [8/105] Loss: 15.135454177856445\n","Batch [9/105] Loss: 15.33348560333252\n","Batch [10/105] Loss: 28.986568450927734\n","Batch [11/105] Loss: 30.395288467407227\n","Batch [12/105] Loss: 30.787256240844727\n","Batch [13/105] Loss: 11.542200088500977\n","Batch [14/105] Loss: 28.265766143798828\n","Batch [15/105] Loss: 29.687768936157227\n","Batch [16/105] Loss: 10.086305618286133\n","Batch [17/105] Loss: 23.506914138793945\n","Batch [18/105] Loss: 71.35826110839844\n","Batch [19/105] Loss: 17.256542205810547\n","Batch [20/105] Loss: 52.652530670166016\n","Batch [21/105] Loss: 24.431018829345703\n","Batch [22/105] Loss: 7.587130069732666\n","Batch [23/105] Loss: 14.107233047485352\n","Batch [24/105] Loss: 39.961326599121094\n","Batch [25/105] Loss: 44.51774978637695\n","Batch [26/105] Loss: 29.82438850402832\n","Batch [27/105] Loss: 21.296279907226562\n","Batch [28/105] Loss: 10.933709144592285\n","Batch [29/105] Loss: 29.280742645263672\n","Batch [30/105] Loss: 20.351367950439453\n","Batch [31/105] Loss: 41.897735595703125\n","Batch [32/105] Loss: 22.867359161376953\n","Batch [33/105] Loss: 17.218467712402344\n","Batch [34/105] Loss: 22.892202377319336\n","Batch [35/105] Loss: 21.73836898803711\n","Batch [36/105] Loss: 12.796932220458984\n","Batch [37/105] Loss: 40.71254348754883\n","Batch [38/105] Loss: 33.023895263671875\n","Batch [39/105] Loss: 65.75914764404297\n","Batch [40/105] Loss: 21.63916015625\n","Batch [41/105] Loss: 11.366969108581543\n","Batch [42/105] Loss: 15.079425811767578\n","Batch [43/105] Loss: 21.06198501586914\n","Batch [44/105] Loss: 52.027076721191406\n","Batch [45/105] Loss: 36.280277252197266\n","Batch [46/105] Loss: 5.902905464172363\n","Batch [47/105] Loss: 40.73810577392578\n","Batch [48/105] Loss: 52.996681213378906\n","Batch [49/105] Loss: 13.334684371948242\n","Batch [50/105] Loss: 31.98641586303711\n","Batch [51/105] Loss: 13.849893569946289\n","Batch [52/105] Loss: 46.80852508544922\n","Batch [53/105] Loss: 14.262681007385254\n","Batch [54/105] Loss: 9.966485977172852\n","Batch [55/105] Loss: 6.1454925537109375\n","Batch [56/105] Loss: 22.874380111694336\n","Batch [57/105] Loss: 42.114078521728516\n","Batch [58/105] Loss: 28.833953857421875\n","Batch [59/105] Loss: 19.249160766601562\n","Batch [60/105] Loss: 11.379727363586426\n","Batch [61/105] Loss: 4.775569915771484\n","Batch [62/105] Loss: 14.192838668823242\n","Batch [63/105] Loss: 28.956871032714844\n","Batch [64/105] Loss: 65.29777526855469\n","Batch [65/105] Loss: 23.260372161865234\n","Batch [66/105] Loss: 14.956966400146484\n","Batch [67/105] Loss: 51.99313735961914\n","Batch [68/105] Loss: 51.63825988769531\n","Batch [69/105] Loss: 26.01921844482422\n","Batch [70/105] Loss: 8.296939849853516\n","Batch [71/105] Loss: 32.260337829589844\n","Batch [72/105] Loss: 21.62490463256836\n","Batch [73/105] Loss: 37.71528625488281\n","Batch [74/105] Loss: 29.782176971435547\n","Batch [75/105] Loss: 16.162443161010742\n","Batch [76/105] Loss: 14.649611473083496\n","Batch [77/105] Loss: 52.365779876708984\n","Batch [78/105] Loss: 18.58043670654297\n","Batch [79/105] Loss: 17.62111473083496\n","Batch [80/105] Loss: 8.58350658416748\n","Batch [81/105] Loss: 19.737916946411133\n","Batch [82/105] Loss: 39.571468353271484\n","Batch [83/105] Loss: 18.719844818115234\n","Batch [84/105] Loss: 26.25485610961914\n","Batch [85/105] Loss: 13.154354095458984\n","Batch [86/105] Loss: 13.1727933883667\n","Batch [87/105] Loss: 18.544300079345703\n","Batch [88/105] Loss: 47.16012191772461\n","Batch [89/105] Loss: 27.816287994384766\n","Batch [90/105] Loss: 14.441741943359375\n","Batch [91/105] Loss: 15.394728660583496\n","Batch [92/105] Loss: 25.388843536376953\n","Batch [93/105] Loss: 29.723922729492188\n","Batch [94/105] Loss: 60.34206771850586\n","Batch [95/105] Loss: 55.092498779296875\n","Batch [96/105] Loss: 73.77804565429688\n","Batch [97/105] Loss: 26.894298553466797\n","Batch [98/105] Loss: 15.77963638305664\n","Batch [99/105] Loss: 25.155658721923828\n","Batch [100/105] Loss: 23.060436248779297\n","Batch [101/105] Loss: 36.79303741455078\n","Batch [102/105] Loss: 15.503622055053711\n","Batch [103/105] Loss: 21.582321166992188\n","Batch [104/105] Loss: 14.253644943237305\n","Batch [105/105] Loss: 27.254985809326172\n","Epoch [27/50], Loss: 26.08403371629261\n","Batch [1/105] Loss: 48.90669631958008\n","Batch [2/105] Loss: 13.28411865234375\n","Batch [3/105] Loss: 26.705326080322266\n","Batch [4/105] Loss: 21.264650344848633\n","Batch [5/105] Loss: 29.601486206054688\n","Batch [6/105] Loss: 22.60441017150879\n","Batch [7/105] Loss: 77.84761047363281\n","Batch [8/105] Loss: 31.35605239868164\n","Batch [9/105] Loss: 23.9570369720459\n","Batch [10/105] Loss: 21.296100616455078\n","Batch [11/105] Loss: 40.77682113647461\n","Batch [12/105] Loss: 66.36891174316406\n","Batch [13/105] Loss: 28.078453063964844\n","Batch [14/105] Loss: 23.574527740478516\n","Batch [15/105] Loss: 14.257125854492188\n","Batch [16/105] Loss: 47.43610763549805\n","Batch [17/105] Loss: 21.424718856811523\n","Batch [18/105] Loss: 22.293155670166016\n","Batch [19/105] Loss: 30.228477478027344\n","Batch [20/105] Loss: 23.05487060546875\n","Batch [21/105] Loss: 12.213041305541992\n","Batch [22/105] Loss: 13.691959381103516\n","Batch [23/105] Loss: 10.334088325500488\n","Batch [24/105] Loss: 11.454231262207031\n","Batch [25/105] Loss: 17.779312133789062\n","Batch [26/105] Loss: 18.39997673034668\n","Batch [27/105] Loss: 16.245807647705078\n","Batch [28/105] Loss: 8.106735229492188\n","Batch [29/105] Loss: 62.76874542236328\n","Batch [30/105] Loss: 7.201769828796387\n","Batch [31/105] Loss: 10.605403900146484\n","Batch [32/105] Loss: 23.395902633666992\n","Batch [33/105] Loss: 13.387042999267578\n","Batch [34/105] Loss: 36.83892822265625\n","Batch [35/105] Loss: 23.755327224731445\n","Batch [36/105] Loss: 23.35942268371582\n","Batch [37/105] Loss: 13.080251693725586\n","Batch [38/105] Loss: 15.118194580078125\n","Batch [39/105] Loss: 12.933724403381348\n","Batch [40/105] Loss: 33.77273178100586\n","Batch [41/105] Loss: 26.74913787841797\n","Batch [42/105] Loss: 14.666128158569336\n","Batch [43/105] Loss: 12.114582061767578\n","Batch [44/105] Loss: 45.795753479003906\n","Batch [45/105] Loss: 9.50145149230957\n","Batch [46/105] Loss: 13.27347183227539\n","Batch [47/105] Loss: 14.763168334960938\n","Batch [48/105] Loss: 11.469480514526367\n","Batch [49/105] Loss: 6.980378150939941\n","Batch [50/105] Loss: 16.744850158691406\n","Batch [51/105] Loss: 6.94680118560791\n","Batch [52/105] Loss: 14.574363708496094\n","Batch [53/105] Loss: 9.391252517700195\n","Batch [54/105] Loss: 9.22825813293457\n","Batch [55/105] Loss: 1.985996961593628\n","Batch [56/105] Loss: 16.762493133544922\n","Batch [57/105] Loss: 14.795697212219238\n","Batch [58/105] Loss: 8.209023475646973\n","Batch [59/105] Loss: 7.279985427856445\n","Batch [60/105] Loss: 24.059215545654297\n","Batch [61/105] Loss: 19.10312271118164\n","Batch [62/105] Loss: 23.709205627441406\n","Batch [63/105] Loss: 5.631223678588867\n","Batch [64/105] Loss: 17.650802612304688\n","Batch [65/105] Loss: 9.061737060546875\n","Batch [66/105] Loss: 23.659687042236328\n","Batch [67/105] Loss: 9.147642135620117\n","Batch [68/105] Loss: 26.901348114013672\n","Batch [69/105] Loss: 8.718120574951172\n","Batch [70/105] Loss: 17.247821807861328\n","Batch [71/105] Loss: 47.102088928222656\n","Batch [72/105] Loss: 28.722972869873047\n","Batch [73/105] Loss: 16.201318740844727\n","Batch [74/105] Loss: 6.708317756652832\n","Batch [75/105] Loss: 8.62670612335205\n","Batch [76/105] Loss: 20.717609405517578\n","Batch [77/105] Loss: 7.358949661254883\n","Batch [78/105] Loss: 33.67469024658203\n","Batch [79/105] Loss: 41.056976318359375\n","Batch [80/105] Loss: 13.154071807861328\n","Batch [81/105] Loss: 41.19715881347656\n","Batch [82/105] Loss: 18.040180206298828\n","Batch [83/105] Loss: 39.83116149902344\n","Batch [84/105] Loss: 9.493171691894531\n","Batch [85/105] Loss: 23.505136489868164\n","Batch [86/105] Loss: 21.647056579589844\n","Batch [87/105] Loss: 12.128385543823242\n","Batch [88/105] Loss: 24.49608612060547\n","Batch [89/105] Loss: 16.32461166381836\n","Batch [90/105] Loss: 7.25218391418457\n","Batch [91/105] Loss: 16.93313980102539\n","Batch [92/105] Loss: 29.45147132873535\n","Batch [93/105] Loss: 11.99148178100586\n","Batch [94/105] Loss: 71.74461364746094\n","Batch [95/105] Loss: 18.73504638671875\n","Batch [96/105] Loss: 59.28340148925781\n","Batch [97/105] Loss: 43.65638732910156\n","Batch [98/105] Loss: 13.35720443725586\n","Batch [99/105] Loss: 22.541149139404297\n","Batch [100/105] Loss: 12.577695846557617\n","Batch [101/105] Loss: 16.378202438354492\n","Batch [102/105] Loss: 16.16123390197754\n","Batch [103/105] Loss: 24.398391723632812\n","Batch [104/105] Loss: 22.41423797607422\n","Batch [105/105] Loss: 16.044097900390625\n","Epoch [28/50], Loss: 21.88369567280724\n","New minimum loss achieved: 21.88369567280724. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 23.75806999206543\n","Batch [2/105] Loss: 64.06301879882812\n","Batch [3/105] Loss: 16.306415557861328\n","Batch [4/105] Loss: 12.097495079040527\n","Batch [5/105] Loss: 30.572803497314453\n","Batch [6/105] Loss: 12.84494400024414\n","Batch [7/105] Loss: 13.867101669311523\n","Batch [8/105] Loss: 56.046897888183594\n","Batch [9/105] Loss: 44.69723892211914\n","Batch [10/105] Loss: 39.40004348754883\n","Batch [11/105] Loss: 21.52229881286621\n","Batch [12/105] Loss: 17.18327522277832\n","Batch [13/105] Loss: 10.366771697998047\n","Batch [14/105] Loss: 21.003284454345703\n","Batch [15/105] Loss: 10.990255355834961\n","Batch [16/105] Loss: 9.707387924194336\n","Batch [17/105] Loss: 28.37340545654297\n","Batch [18/105] Loss: 18.701812744140625\n","Batch [19/105] Loss: 59.268985748291016\n","Batch [20/105] Loss: 27.97774314880371\n","Batch [21/105] Loss: 12.467226028442383\n","Batch [22/105] Loss: 12.984695434570312\n","Batch [23/105] Loss: 20.34608268737793\n","Batch [24/105] Loss: 14.126909255981445\n","Batch [25/105] Loss: 33.395591735839844\n","Batch [26/105] Loss: 9.341604232788086\n","Batch [27/105] Loss: 8.347977638244629\n","Batch [28/105] Loss: 18.16520881652832\n","Batch [29/105] Loss: 10.32097339630127\n","Batch [30/105] Loss: 24.99238395690918\n","Batch [31/105] Loss: 20.274707794189453\n","Batch [32/105] Loss: 39.99367904663086\n","Batch [33/105] Loss: 13.97049331665039\n","Batch [34/105] Loss: 21.581636428833008\n","Batch [35/105] Loss: 14.008015632629395\n","Batch [36/105] Loss: 11.262895584106445\n","Batch [37/105] Loss: 15.8362398147583\n","Batch [38/105] Loss: 15.480303764343262\n","Batch [39/105] Loss: 10.682319641113281\n","Batch [40/105] Loss: 26.591249465942383\n","Batch [41/105] Loss: 49.40116882324219\n","Batch [42/105] Loss: 24.029891967773438\n","Batch [43/105] Loss: 50.49402618408203\n","Batch [44/105] Loss: 15.62770938873291\n","Batch [45/105] Loss: 18.702903747558594\n","Batch [46/105] Loss: 17.212491989135742\n","Batch [47/105] Loss: 74.29337310791016\n","Batch [48/105] Loss: 6.669482231140137\n","Batch [49/105] Loss: 35.56369400024414\n","Batch [50/105] Loss: 15.7125244140625\n","Batch [51/105] Loss: 17.71151351928711\n","Batch [52/105] Loss: 15.920456886291504\n","Batch [53/105] Loss: 43.92823791503906\n","Batch [54/105] Loss: 12.629215240478516\n","Batch [55/105] Loss: 19.445302963256836\n","Batch [56/105] Loss: 6.26348876953125\n","Batch [57/105] Loss: 23.81406021118164\n","Batch [58/105] Loss: 8.907625198364258\n","Batch [59/105] Loss: 15.657613754272461\n","Batch [60/105] Loss: 42.460235595703125\n","Batch [61/105] Loss: 18.44879913330078\n","Batch [62/105] Loss: 22.8973331451416\n","Batch [63/105] Loss: 19.8635196685791\n","Batch [64/105] Loss: 14.838043212890625\n","Batch [65/105] Loss: 22.876493453979492\n","Batch [66/105] Loss: 17.50920867919922\n","Batch [67/105] Loss: 24.962528228759766\n","Batch [68/105] Loss: 19.068328857421875\n","Batch [69/105] Loss: 19.61905860900879\n","Batch [70/105] Loss: 8.552451133728027\n","Batch [71/105] Loss: 22.242340087890625\n","Batch [72/105] Loss: 15.436142921447754\n","Batch [73/105] Loss: 14.33900260925293\n","Batch [74/105] Loss: 19.13315200805664\n","Batch [75/105] Loss: 35.1424560546875\n","Batch [76/105] Loss: 21.56003189086914\n","Batch [77/105] Loss: 6.084226131439209\n","Batch [78/105] Loss: 23.40376091003418\n","Batch [79/105] Loss: 6.355451583862305\n","Batch [80/105] Loss: 15.978267669677734\n","Batch [81/105] Loss: 52.83252716064453\n","Batch [82/105] Loss: 25.938186645507812\n","Batch [83/105] Loss: 53.54273986816406\n","Batch [84/105] Loss: 20.11373519897461\n","Batch [85/105] Loss: 25.30210304260254\n","Batch [86/105] Loss: 17.55636978149414\n","Batch [87/105] Loss: 26.18277931213379\n","Batch [88/105] Loss: 43.671085357666016\n","Batch [89/105] Loss: 40.180084228515625\n","Batch [90/105] Loss: 21.12125015258789\n","Batch [91/105] Loss: 43.0701904296875\n","Batch [92/105] Loss: 15.401548385620117\n","Batch [93/105] Loss: 16.649669647216797\n","Batch [94/105] Loss: 47.207313537597656\n","Batch [95/105] Loss: 37.15407180786133\n","Batch [96/105] Loss: 25.439685821533203\n","Batch [97/105] Loss: 42.64939880371094\n","Batch [98/105] Loss: 18.627788543701172\n","Batch [99/105] Loss: 22.367748260498047\n","Batch [100/105] Loss: 30.53321075439453\n","Batch [101/105] Loss: 44.556480407714844\n","Batch [102/105] Loss: 25.943086624145508\n","Batch [103/105] Loss: 23.18524932861328\n","Batch [104/105] Loss: 40.63318634033203\n","Batch [105/105] Loss: 16.903076171875\n","Epoch [29/50], Loss: 24.30892972037906\n","Batch [1/105] Loss: 10.17625617980957\n","Batch [2/105] Loss: 14.462626457214355\n","Batch [3/105] Loss: 12.971932411193848\n","Batch [4/105] Loss: 9.694730758666992\n","Batch [5/105] Loss: 23.23625946044922\n","Batch [6/105] Loss: 67.40166473388672\n","Batch [7/105] Loss: 14.152963638305664\n","Batch [8/105] Loss: 19.012516021728516\n","Batch [9/105] Loss: 7.063002109527588\n","Batch [10/105] Loss: 41.926109313964844\n","Batch [11/105] Loss: 42.15715026855469\n","Batch [12/105] Loss: 10.014873504638672\n","Batch [13/105] Loss: 6.485576152801514\n","Batch [14/105] Loss: 15.869382858276367\n","Batch [15/105] Loss: 77.27299499511719\n","Batch [16/105] Loss: 29.58334732055664\n","Batch [17/105] Loss: 13.733242988586426\n","Batch [18/105] Loss: 21.092321395874023\n","Batch [19/105] Loss: 13.271392822265625\n","Batch [20/105] Loss: 13.049128532409668\n","Batch [21/105] Loss: 10.443855285644531\n","Batch [22/105] Loss: 9.648652076721191\n","Batch [23/105] Loss: 6.116156101226807\n","Batch [24/105] Loss: 15.792496681213379\n","Batch [25/105] Loss: 41.619388580322266\n","Batch [26/105] Loss: 48.756507873535156\n","Batch [27/105] Loss: 18.807533264160156\n","Batch [28/105] Loss: 28.4849910736084\n","Batch [29/105] Loss: 23.979175567626953\n","Batch [30/105] Loss: 26.269702911376953\n","Batch [31/105] Loss: 75.58163452148438\n","Batch [32/105] Loss: 51.904205322265625\n","Batch [33/105] Loss: 19.37618064880371\n","Batch [34/105] Loss: 20.853172302246094\n","Batch [35/105] Loss: 15.753351211547852\n","Batch [36/105] Loss: 10.035943984985352\n","Batch [37/105] Loss: 17.51537322998047\n","Batch [38/105] Loss: 9.375568389892578\n","Batch [39/105] Loss: 22.057554244995117\n","Batch [40/105] Loss: 21.20741844177246\n","Batch [41/105] Loss: 5.382104396820068\n","Batch [42/105] Loss: 41.36960983276367\n","Batch [43/105] Loss: 6.601940155029297\n","Batch [44/105] Loss: 43.490478515625\n","Batch [45/105] Loss: 27.534854888916016\n","Batch [46/105] Loss: 13.669645309448242\n","Batch [47/105] Loss: 26.70145606994629\n","Batch [48/105] Loss: 14.960962295532227\n","Batch [49/105] Loss: 25.375585556030273\n","Batch [50/105] Loss: 27.449195861816406\n","Batch [51/105] Loss: 14.256433486938477\n","Batch [52/105] Loss: 23.839763641357422\n","Batch [53/105] Loss: 16.006675720214844\n","Batch [54/105] Loss: 53.00764083862305\n","Batch [55/105] Loss: 6.258745193481445\n","Batch [56/105] Loss: 11.621484756469727\n","Batch [57/105] Loss: 13.94656753540039\n","Batch [58/105] Loss: 19.591106414794922\n","Batch [59/105] Loss: 52.89093780517578\n","Batch [60/105] Loss: 29.961685180664062\n","Batch [61/105] Loss: 17.070587158203125\n","Batch [62/105] Loss: 14.825666427612305\n","Batch [63/105] Loss: 11.226805686950684\n","Batch [64/105] Loss: 53.363555908203125\n","Batch [65/105] Loss: 30.98923110961914\n","Batch [66/105] Loss: 55.137908935546875\n","Batch [67/105] Loss: 28.076492309570312\n","Batch [68/105] Loss: 10.155698776245117\n","Batch [69/105] Loss: 16.445518493652344\n","Batch [70/105] Loss: 23.114974975585938\n","Batch [71/105] Loss: 12.482246398925781\n","Batch [72/105] Loss: 11.14743423461914\n","Batch [73/105] Loss: 48.58270263671875\n","Batch [74/105] Loss: 11.886945724487305\n","Batch [75/105] Loss: 11.491555213928223\n","Batch [76/105] Loss: 23.045730590820312\n","Batch [77/105] Loss: 34.15361022949219\n","Batch [78/105] Loss: 28.20618438720703\n","Batch [79/105] Loss: 22.091522216796875\n","Batch [80/105] Loss: 17.938093185424805\n","Batch [81/105] Loss: 22.884384155273438\n","Batch [82/105] Loss: 19.075855255126953\n","Batch [83/105] Loss: 26.67108917236328\n","Batch [84/105] Loss: 24.522634506225586\n","Batch [85/105] Loss: 19.41634750366211\n","Batch [86/105] Loss: 24.341245651245117\n","Batch [87/105] Loss: 28.66044807434082\n","Batch [88/105] Loss: 19.616640090942383\n","Batch [89/105] Loss: 46.186065673828125\n","Batch [90/105] Loss: 19.03330421447754\n","Batch [91/105] Loss: 20.685028076171875\n","Batch [92/105] Loss: 14.437949180603027\n","Batch [93/105] Loss: 24.565595626831055\n","Batch [94/105] Loss: 67.84485626220703\n","Batch [95/105] Loss: 18.122501373291016\n","Batch [96/105] Loss: 18.72128677368164\n","Batch [97/105] Loss: 15.973987579345703\n","Batch [98/105] Loss: 9.362560272216797\n","Batch [99/105] Loss: 11.278120040893555\n","Batch [100/105] Loss: 24.25723648071289\n","Batch [101/105] Loss: 6.266087532043457\n","Batch [102/105] Loss: 62.9211311340332\n","Batch [103/105] Loss: 7.795286178588867\n","Batch [104/105] Loss: 9.52101993560791\n","Batch [105/105] Loss: 22.198699951171875\n","Epoch [30/50], Loss: 23.770619356064568\n","Batch [1/105] Loss: 12.904986381530762\n","Batch [2/105] Loss: 29.192821502685547\n","Batch [3/105] Loss: 13.291020393371582\n","Batch [4/105] Loss: 12.114534378051758\n","Batch [5/105] Loss: 11.751016616821289\n","Batch [6/105] Loss: 15.220605850219727\n","Batch [7/105] Loss: 8.586917877197266\n","Batch [8/105] Loss: 20.12885284423828\n","Batch [9/105] Loss: 13.833497047424316\n","Batch [10/105] Loss: 26.16082191467285\n","Batch [11/105] Loss: 64.49310302734375\n","Batch [12/105] Loss: 17.986507415771484\n","Batch [13/105] Loss: 13.616165161132812\n","Batch [14/105] Loss: 17.517269134521484\n","Batch [15/105] Loss: 28.295185089111328\n","Batch [16/105] Loss: 47.72475814819336\n","Batch [17/105] Loss: 25.768526077270508\n","Batch [18/105] Loss: 70.20405578613281\n","Batch [19/105] Loss: 21.98552703857422\n","Batch [20/105] Loss: 14.672101020812988\n","Batch [21/105] Loss: 40.6649169921875\n","Batch [22/105] Loss: 17.393917083740234\n","Batch [23/105] Loss: 35.1701545715332\n","Batch [24/105] Loss: 24.813514709472656\n","Batch [25/105] Loss: 29.409767150878906\n","Batch [26/105] Loss: 10.977245330810547\n","Batch [27/105] Loss: 36.87077713012695\n","Batch [28/105] Loss: 15.940064430236816\n","Batch [29/105] Loss: 27.159175872802734\n","Batch [30/105] Loss: 6.366019248962402\n","Batch [31/105] Loss: 10.386429786682129\n","Batch [32/105] Loss: 19.75604248046875\n","Batch [33/105] Loss: 49.42930603027344\n","Batch [34/105] Loss: 28.523540496826172\n","Batch [35/105] Loss: 10.403003692626953\n","Batch [36/105] Loss: 10.061638832092285\n","Batch [37/105] Loss: 29.885887145996094\n","Batch [38/105] Loss: 23.10340118408203\n","Batch [39/105] Loss: 15.266332626342773\n","Batch [40/105] Loss: 32.18909454345703\n","Batch [41/105] Loss: 18.83209228515625\n","Batch [42/105] Loss: 32.18434524536133\n","Batch [43/105] Loss: 12.754159927368164\n","Batch [44/105] Loss: 11.471138000488281\n","Batch [45/105] Loss: 10.461874008178711\n","Batch [46/105] Loss: 37.396461486816406\n","Batch [47/105] Loss: 8.740177154541016\n","Batch [48/105] Loss: 31.969633102416992\n","Batch [49/105] Loss: 30.870098114013672\n","Batch [50/105] Loss: 12.158878326416016\n","Batch [51/105] Loss: 17.931785583496094\n","Batch [52/105] Loss: 26.170438766479492\n","Batch [53/105] Loss: 16.040328979492188\n","Batch [54/105] Loss: 7.188923358917236\n","Batch [55/105] Loss: 11.948468208312988\n","Batch [56/105] Loss: 7.6527180671691895\n","Batch [57/105] Loss: 17.387645721435547\n","Batch [58/105] Loss: 14.390263557434082\n","Batch [59/105] Loss: 21.891658782958984\n","Batch [60/105] Loss: 26.643640518188477\n","Batch [61/105] Loss: 21.236557006835938\n","Batch [62/105] Loss: 32.86338806152344\n","Batch [63/105] Loss: 66.10362243652344\n","Batch [64/105] Loss: 19.770206451416016\n","Batch [65/105] Loss: 15.566802978515625\n","Batch [66/105] Loss: 12.541902542114258\n","Batch [67/105] Loss: 18.220067977905273\n","Batch [68/105] Loss: 5.762251377105713\n","Batch [69/105] Loss: 21.601200103759766\n","Batch [70/105] Loss: 24.06781005859375\n","Batch [71/105] Loss: 75.16346740722656\n","Batch [72/105] Loss: 7.546632766723633\n","Batch [73/105] Loss: 13.706136703491211\n","Batch [74/105] Loss: 25.501073837280273\n","Batch [75/105] Loss: 16.410654067993164\n","Batch [76/105] Loss: 14.238136291503906\n","Batch [77/105] Loss: 28.804346084594727\n","Batch [78/105] Loss: 11.229063987731934\n","Batch [79/105] Loss: 6.099689483642578\n","Batch [80/105] Loss: 16.744958877563477\n","Batch [81/105] Loss: 11.599539756774902\n","Batch [82/105] Loss: 30.424957275390625\n","Batch [83/105] Loss: 7.90106201171875\n","Batch [84/105] Loss: 14.055257797241211\n","Batch [85/105] Loss: 36.57661437988281\n","Batch [86/105] Loss: 29.844356536865234\n","Batch [87/105] Loss: 18.47049903869629\n","Batch [88/105] Loss: 9.738862991333008\n","Batch [89/105] Loss: 22.394977569580078\n","Batch [90/105] Loss: 54.105133056640625\n","Batch [91/105] Loss: 24.62624740600586\n","Batch [92/105] Loss: 45.03976821899414\n","Batch [93/105] Loss: 20.378870010375977\n","Batch [94/105] Loss: 28.974624633789062\n","Batch [95/105] Loss: 23.707733154296875\n","Batch [96/105] Loss: 24.591766357421875\n","Batch [97/105] Loss: 12.977254867553711\n","Batch [98/105] Loss: 9.404976844787598\n","Batch [99/105] Loss: 65.11236572265625\n","Batch [100/105] Loss: 22.19548797607422\n","Batch [101/105] Loss: 7.465565204620361\n","Batch [102/105] Loss: 20.046632766723633\n","Batch [103/105] Loss: 26.113582611083984\n","Batch [104/105] Loss: 7.861924171447754\n","Batch [105/105] Loss: 18.976564407348633\n","Epoch [31/50], Loss: 22.6577697572254\n","Batch [1/105] Loss: 12.377219200134277\n","Batch [2/105] Loss: 21.553617477416992\n","Batch [3/105] Loss: 33.32148742675781\n","Batch [4/105] Loss: 36.01179122924805\n","Batch [5/105] Loss: 38.055419921875\n","Batch [6/105] Loss: 10.965494155883789\n","Batch [7/105] Loss: 52.68584442138672\n","Batch [8/105] Loss: 16.478303909301758\n","Batch [9/105] Loss: 9.948175430297852\n","Batch [10/105] Loss: 34.264442443847656\n","Batch [11/105] Loss: 12.507125854492188\n","Batch [12/105] Loss: 16.23906707763672\n","Batch [13/105] Loss: 18.285480499267578\n","Batch [14/105] Loss: 27.522449493408203\n","Batch [15/105] Loss: 24.026077270507812\n","Batch [16/105] Loss: 18.286540985107422\n","Batch [17/105] Loss: 33.57596206665039\n","Batch [18/105] Loss: 21.166316986083984\n","Batch [19/105] Loss: 6.461859703063965\n","Batch [20/105] Loss: 6.954159259796143\n","Batch [21/105] Loss: 6.8664116859436035\n","Batch [22/105] Loss: 22.867643356323242\n","Batch [23/105] Loss: 10.656557083129883\n","Batch [24/105] Loss: 44.381893157958984\n","Batch [25/105] Loss: 9.750448226928711\n","Batch [26/105] Loss: 11.039525985717773\n","Batch [27/105] Loss: 14.599255561828613\n","Batch [28/105] Loss: 30.267484664916992\n","Batch [29/105] Loss: 33.59297180175781\n","Batch [30/105] Loss: 23.91680908203125\n","Batch [31/105] Loss: 9.113824844360352\n","Batch [32/105] Loss: 33.51523971557617\n","Batch [33/105] Loss: 23.260971069335938\n","Batch [34/105] Loss: 10.030389785766602\n","Batch [35/105] Loss: 18.02069854736328\n","Batch [36/105] Loss: 38.694984436035156\n","Batch [37/105] Loss: 12.990297317504883\n","Batch [38/105] Loss: 62.2894287109375\n","Batch [39/105] Loss: 22.539169311523438\n","Batch [40/105] Loss: 12.04940414428711\n","Batch [41/105] Loss: 52.68284606933594\n","Batch [42/105] Loss: 32.8170166015625\n","Batch [43/105] Loss: 22.850130081176758\n","Batch [44/105] Loss: 18.03915786743164\n","Batch [45/105] Loss: 33.51342010498047\n","Batch [46/105] Loss: 17.637598037719727\n","Batch [47/105] Loss: 15.501413345336914\n","Batch [48/105] Loss: 16.207015991210938\n","Batch [49/105] Loss: 30.667266845703125\n","Batch [50/105] Loss: 21.256263732910156\n","Batch [51/105] Loss: 28.23207664489746\n","Batch [52/105] Loss: 43.69419479370117\n","Batch [53/105] Loss: 21.00469970703125\n","Batch [54/105] Loss: 16.92595863342285\n","Batch [55/105] Loss: 29.904659271240234\n","Batch [56/105] Loss: 14.557790756225586\n","Batch [57/105] Loss: 13.180315017700195\n","Batch [58/105] Loss: 9.500510215759277\n","Batch [59/105] Loss: 15.233772277832031\n","Batch [60/105] Loss: 39.98176956176758\n","Batch [61/105] Loss: 57.83074188232422\n","Batch [62/105] Loss: 8.087363243103027\n","Batch [63/105] Loss: 16.015762329101562\n","Batch [64/105] Loss: 17.777652740478516\n","Batch [65/105] Loss: 21.285436630249023\n","Batch [66/105] Loss: 26.78235626220703\n","Batch [67/105] Loss: 71.22300720214844\n","Batch [68/105] Loss: 5.793420314788818\n","Batch [69/105] Loss: 10.935437202453613\n","Batch [70/105] Loss: 9.518643379211426\n","Batch [71/105] Loss: 10.052521705627441\n","Batch [72/105] Loss: 4.677764415740967\n","Batch [73/105] Loss: 11.907247543334961\n","Batch [74/105] Loss: 25.506872177124023\n","Batch [75/105] Loss: 11.865876197814941\n","Batch [76/105] Loss: 12.144510269165039\n","Batch [77/105] Loss: 15.823583602905273\n","Batch [78/105] Loss: 5.179596424102783\n","Batch [79/105] Loss: 7.950009822845459\n","Batch [80/105] Loss: 18.163814544677734\n","Batch [81/105] Loss: 13.79702377319336\n","Batch [82/105] Loss: 25.22062873840332\n","Batch [83/105] Loss: 37.844024658203125\n","Batch [84/105] Loss: 37.2739372253418\n","Batch [85/105] Loss: 7.01789665222168\n","Batch [86/105] Loss: 23.206298828125\n","Batch [87/105] Loss: 7.408693313598633\n","Batch [88/105] Loss: 5.7083868980407715\n","Batch [89/105] Loss: 8.684372901916504\n","Batch [90/105] Loss: 8.437479972839355\n","Batch [91/105] Loss: 3.5871994495391846\n","Batch [92/105] Loss: 11.861291885375977\n","Batch [93/105] Loss: 14.088916778564453\n","Batch [94/105] Loss: 13.67081069946289\n","Batch [95/105] Loss: 19.745037078857422\n","Batch [96/105] Loss: 14.44890308380127\n","Batch [97/105] Loss: 14.098943710327148\n","Batch [98/105] Loss: 46.984066009521484\n","Batch [99/105] Loss: 6.602545738220215\n","Batch [100/105] Loss: 14.55720329284668\n","Batch [101/105] Loss: 7.35658073425293\n","Batch [102/105] Loss: 4.642226696014404\n","Batch [103/105] Loss: 9.228382110595703\n","Batch [104/105] Loss: 16.489830017089844\n","Batch [105/105] Loss: 19.238908767700195\n","Epoch [32/50], Loss: 20.516565007255192\n","New minimum loss achieved: 20.516565007255192. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 20.377925872802734\n","Batch [2/105] Loss: 21.896028518676758\n","Batch [3/105] Loss: 22.623411178588867\n","Batch [4/105] Loss: 16.645265579223633\n","Batch [5/105] Loss: 25.56867790222168\n","Batch [6/105] Loss: 17.06708526611328\n","Batch [7/105] Loss: 19.764102935791016\n","Batch [8/105] Loss: 12.065492630004883\n","Batch [9/105] Loss: 55.32204055786133\n","Batch [10/105] Loss: 30.75141716003418\n","Batch [11/105] Loss: 18.251066207885742\n","Batch [12/105] Loss: 38.70372009277344\n","Batch [13/105] Loss: 13.947577476501465\n","Batch [14/105] Loss: 13.266339302062988\n","Batch [15/105] Loss: 15.221240043640137\n","Batch [16/105] Loss: 33.93123245239258\n","Batch [17/105] Loss: 7.540045738220215\n","Batch [18/105] Loss: 11.215995788574219\n","Batch [19/105] Loss: 13.48619270324707\n","Batch [20/105] Loss: 23.484159469604492\n","Batch [21/105] Loss: 58.33331298828125\n","Batch [22/105] Loss: 12.05062484741211\n","Batch [23/105] Loss: 18.345361709594727\n","Batch [24/105] Loss: 22.588382720947266\n","Batch [25/105] Loss: 14.430538177490234\n","Batch [26/105] Loss: 5.358178615570068\n","Batch [27/105] Loss: 19.91571807861328\n","Batch [28/105] Loss: 8.37585163116455\n","Batch [29/105] Loss: 11.25651741027832\n","Batch [30/105] Loss: 19.1986026763916\n","Batch [31/105] Loss: 30.664134979248047\n","Batch [32/105] Loss: 10.852651596069336\n","Batch [33/105] Loss: 7.8831562995910645\n","Batch [34/105] Loss: 8.333230018615723\n","Batch [35/105] Loss: 15.570789337158203\n","Batch [36/105] Loss: 36.552146911621094\n","Batch [37/105] Loss: 13.247779846191406\n","Batch [38/105] Loss: 17.48077392578125\n","Batch [39/105] Loss: 48.09185028076172\n","Batch [40/105] Loss: 10.230802536010742\n","Batch [41/105] Loss: 17.39429473876953\n","Batch [42/105] Loss: 21.95807647705078\n","Batch [43/105] Loss: 38.83279037475586\n","Batch [44/105] Loss: 29.582050323486328\n","Batch [45/105] Loss: 16.028614044189453\n","Batch [46/105] Loss: 5.327849388122559\n","Batch [47/105] Loss: 18.433353424072266\n","Batch [48/105] Loss: 23.727584838867188\n","Batch [49/105] Loss: 2.917731285095215\n","Batch [50/105] Loss: 12.80357551574707\n","Batch [51/105] Loss: 15.823192596435547\n","Batch [52/105] Loss: 13.447813034057617\n","Batch [53/105] Loss: 30.638147354125977\n","Batch [54/105] Loss: 20.13813018798828\n","Batch [55/105] Loss: 25.49105453491211\n","Batch [56/105] Loss: 8.961174964904785\n","Batch [57/105] Loss: 43.463531494140625\n","Batch [58/105] Loss: 34.16168212890625\n","Batch [59/105] Loss: 24.73806381225586\n","Batch [60/105] Loss: 57.313438415527344\n","Batch [61/105] Loss: 35.45547866821289\n","Batch [62/105] Loss: 26.308269500732422\n","Batch [63/105] Loss: 14.22212028503418\n","Batch [64/105] Loss: 25.53629493713379\n","Batch [65/105] Loss: 26.461450576782227\n","Batch [66/105] Loss: 18.065696716308594\n","Batch [67/105] Loss: 19.262359619140625\n","Batch [68/105] Loss: 21.0419864654541\n","Batch [69/105] Loss: 12.106172561645508\n","Batch [70/105] Loss: 38.181617736816406\n","Batch [71/105] Loss: 14.304817199707031\n","Batch [72/105] Loss: 27.97265625\n","Batch [73/105] Loss: 8.894966125488281\n","Batch [74/105] Loss: 19.55554962158203\n","Batch [75/105] Loss: 11.702577590942383\n","Batch [76/105] Loss: 24.188831329345703\n","Batch [77/105] Loss: 4.617305278778076\n","Batch [78/105] Loss: 14.595335960388184\n","Batch [79/105] Loss: 14.211723327636719\n","Batch [80/105] Loss: 33.3000602722168\n","Batch [81/105] Loss: 13.171401023864746\n","Batch [82/105] Loss: 54.55357360839844\n","Batch [83/105] Loss: 6.887641429901123\n","Batch [84/105] Loss: 29.803512573242188\n","Batch [85/105] Loss: 43.25846481323242\n","Batch [86/105] Loss: 31.147258758544922\n","Batch [87/105] Loss: 8.587124824523926\n","Batch [88/105] Loss: 20.22794532775879\n","Batch [89/105] Loss: 13.512798309326172\n","Batch [90/105] Loss: 33.29462432861328\n","Batch [91/105] Loss: 18.439617156982422\n","Batch [92/105] Loss: 49.57157897949219\n","Batch [93/105] Loss: 21.21598243713379\n","Batch [94/105] Loss: 11.005277633666992\n","Batch [95/105] Loss: 28.21405029296875\n","Batch [96/105] Loss: 8.106630325317383\n","Batch [97/105] Loss: 12.27324104309082\n","Batch [98/105] Loss: 33.561832427978516\n","Batch [99/105] Loss: 10.807418823242188\n","Batch [100/105] Loss: 58.326072692871094\n","Batch [101/105] Loss: 12.952825546264648\n","Batch [102/105] Loss: 11.663267135620117\n","Batch [103/105] Loss: 20.925081253051758\n","Batch [104/105] Loss: 22.565011978149414\n","Batch [105/105] Loss: 9.309147834777832\n","Epoch [33/50], Loss: 21.661316390264602\n","Batch [1/105] Loss: 10.65557861328125\n","Batch [2/105] Loss: 9.042552947998047\n","Batch [3/105] Loss: 16.65719985961914\n","Batch [4/105] Loss: 14.864974975585938\n","Batch [5/105] Loss: 67.19259643554688\n","Batch [6/105] Loss: 27.37369155883789\n","Batch [7/105] Loss: 21.960494995117188\n","Batch [8/105] Loss: 19.83468246459961\n","Batch [9/105] Loss: 42.107627868652344\n","Batch [10/105] Loss: 16.445293426513672\n","Batch [11/105] Loss: 34.104881286621094\n","Batch [12/105] Loss: 30.327842712402344\n","Batch [13/105] Loss: 18.21639060974121\n","Batch [14/105] Loss: 8.527597427368164\n","Batch [15/105] Loss: 19.649574279785156\n","Batch [16/105] Loss: 11.68933391571045\n","Batch [17/105] Loss: 9.146299362182617\n","Batch [18/105] Loss: 17.223440170288086\n","Batch [19/105] Loss: 4.61220645904541\n","Batch [20/105] Loss: 31.617137908935547\n","Batch [21/105] Loss: 15.872299194335938\n","Batch [22/105] Loss: 42.889869689941406\n","Batch [23/105] Loss: 58.40312957763672\n","Batch [24/105] Loss: 16.71802520751953\n","Batch [25/105] Loss: 18.824905395507812\n","Batch [26/105] Loss: 27.838661193847656\n","Batch [27/105] Loss: 57.77520751953125\n","Batch [28/105] Loss: 35.35013198852539\n","Batch [29/105] Loss: 8.851763725280762\n","Batch [30/105] Loss: 57.93255615234375\n","Batch [31/105] Loss: 18.532150268554688\n","Batch [32/105] Loss: 36.30971908569336\n","Batch [33/105] Loss: 5.043622016906738\n","Batch [34/105] Loss: 8.504528045654297\n","Batch [35/105] Loss: 22.591705322265625\n","Batch [36/105] Loss: 22.49596405029297\n","Batch [37/105] Loss: 13.491422653198242\n","Batch [38/105] Loss: 24.358245849609375\n","Batch [39/105] Loss: 21.789846420288086\n","Batch [40/105] Loss: 13.025922775268555\n","Batch [41/105] Loss: 34.807891845703125\n","Batch [42/105] Loss: 8.762090682983398\n","Batch [43/105] Loss: 13.461716651916504\n","Batch [44/105] Loss: 33.945701599121094\n","Batch [45/105] Loss: 9.395383834838867\n","Batch [46/105] Loss: 19.248308181762695\n","Batch [47/105] Loss: 31.06938934326172\n","Batch [48/105] Loss: 21.349708557128906\n","Batch [49/105] Loss: 45.48503112792969\n","Batch [50/105] Loss: 26.32647705078125\n","Batch [51/105] Loss: 21.909299850463867\n","Batch [52/105] Loss: 19.93864631652832\n","Batch [53/105] Loss: 16.066606521606445\n","Batch [54/105] Loss: 53.812068939208984\n","Batch [55/105] Loss: 16.745426177978516\n","Batch [56/105] Loss: 6.091601371765137\n","Batch [57/105] Loss: 6.379627227783203\n","Batch [58/105] Loss: 6.443980693817139\n","Batch [59/105] Loss: 15.978219985961914\n","Batch [60/105] Loss: 25.540010452270508\n","Batch [61/105] Loss: 43.98871994018555\n","Batch [62/105] Loss: 20.500045776367188\n","Batch [63/105] Loss: 40.36235427856445\n","Batch [64/105] Loss: 37.338043212890625\n","Batch [65/105] Loss: 38.781864166259766\n","Batch [66/105] Loss: 14.576639175415039\n","Batch [67/105] Loss: 63.33744430541992\n","Batch [68/105] Loss: 34.419403076171875\n","Batch [69/105] Loss: 10.999543190002441\n","Batch [70/105] Loss: 15.883296966552734\n","Batch [71/105] Loss: 14.447134017944336\n","Batch [72/105] Loss: 38.58572006225586\n","Batch [73/105] Loss: 14.154648780822754\n","Batch [74/105] Loss: 8.408060073852539\n","Batch [75/105] Loss: 13.909002304077148\n","Batch [76/105] Loss: 55.18511962890625\n","Batch [77/105] Loss: 32.10703659057617\n","Batch [78/105] Loss: 16.09453773498535\n","Batch [79/105] Loss: 14.031286239624023\n","Batch [80/105] Loss: 22.103879928588867\n","Batch [81/105] Loss: 19.970806121826172\n","Batch [82/105] Loss: 32.74170684814453\n","Batch [83/105] Loss: 15.281076431274414\n","Batch [84/105] Loss: 10.600465774536133\n","Batch [85/105] Loss: 17.306217193603516\n","Batch [86/105] Loss: 9.927741050720215\n","Batch [87/105] Loss: 11.105607986450195\n","Batch [88/105] Loss: 7.090909481048584\n","Batch [89/105] Loss: 20.5139102935791\n","Batch [90/105] Loss: 12.550460815429688\n","Batch [91/105] Loss: 18.188997268676758\n","Batch [92/105] Loss: 50.2137451171875\n","Batch [93/105] Loss: 12.12683391571045\n","Batch [94/105] Loss: 17.4885311126709\n","Batch [95/105] Loss: 18.919021606445312\n","Batch [96/105] Loss: 17.551685333251953\n","Batch [97/105] Loss: 13.887205123901367\n","Batch [98/105] Loss: 14.926647186279297\n","Batch [99/105] Loss: 18.616737365722656\n","Batch [100/105] Loss: 16.87440299987793\n","Batch [101/105] Loss: 32.71111297607422\n","Batch [102/105] Loss: 7.592769622802734\n","Batch [103/105] Loss: 18.952194213867188\n","Batch [104/105] Loss: 31.046730041503906\n","Batch [105/105] Loss: 14.855006217956543\n","Epoch [34/50], Loss: 22.865338679722377\n","Batch [1/105] Loss: 56.90135955810547\n","Batch [2/105] Loss: 11.246739387512207\n","Batch [3/105] Loss: 38.90576934814453\n","Batch [4/105] Loss: 21.751079559326172\n","Batch [5/105] Loss: 11.713226318359375\n","Batch [6/105] Loss: 7.691334247589111\n","Batch [7/105] Loss: 39.844940185546875\n","Batch [8/105] Loss: 14.181524276733398\n","Batch [9/105] Loss: 11.674595832824707\n","Batch [10/105] Loss: 65.17390441894531\n","Batch [11/105] Loss: 21.690185546875\n","Batch [12/105] Loss: 16.882814407348633\n","Batch [13/105] Loss: 21.339441299438477\n","Batch [14/105] Loss: 11.791814804077148\n","Batch [15/105] Loss: 23.8268985748291\n","Batch [16/105] Loss: 47.54645919799805\n","Batch [17/105] Loss: 27.26418685913086\n","Batch [18/105] Loss: 12.647697448730469\n","Batch [19/105] Loss: 19.25495147705078\n","Batch [20/105] Loss: 12.558816909790039\n","Batch [21/105] Loss: 9.672653198242188\n","Batch [22/105] Loss: 24.999649047851562\n","Batch [23/105] Loss: 21.123659133911133\n","Batch [24/105] Loss: 11.079952239990234\n","Batch [25/105] Loss: 13.814112663269043\n","Batch [26/105] Loss: 39.964508056640625\n","Batch [27/105] Loss: 23.156522750854492\n","Batch [28/105] Loss: 15.213323593139648\n","Batch [29/105] Loss: 17.10027313232422\n","Batch [30/105] Loss: 26.586942672729492\n","Batch [31/105] Loss: 12.91015911102295\n","Batch [32/105] Loss: 26.122032165527344\n","Batch [33/105] Loss: 22.22727394104004\n","Batch [34/105] Loss: 13.391225814819336\n","Batch [35/105] Loss: 10.906232833862305\n","Batch [36/105] Loss: 6.720365524291992\n","Batch [37/105] Loss: 13.661835670471191\n","Batch [38/105] Loss: 9.503161430358887\n","Batch [39/105] Loss: 45.771575927734375\n","Batch [40/105] Loss: 16.07752799987793\n","Batch [41/105] Loss: 5.106513977050781\n","Batch [42/105] Loss: 25.435279846191406\n","Batch [43/105] Loss: 37.224769592285156\n","Batch [44/105] Loss: 13.516085624694824\n","Batch [45/105] Loss: 19.467098236083984\n","Batch [46/105] Loss: 27.756105422973633\n","Batch [47/105] Loss: 10.374399185180664\n","Batch [48/105] Loss: 36.446083068847656\n","Batch [49/105] Loss: 19.89049530029297\n","Batch [50/105] Loss: 10.441493034362793\n","Batch [51/105] Loss: 9.852359771728516\n","Batch [52/105] Loss: 19.500041961669922\n","Batch [53/105] Loss: 37.57501220703125\n","Batch [54/105] Loss: 10.769431114196777\n","Batch [55/105] Loss: 15.249277114868164\n","Batch [56/105] Loss: 10.9594144821167\n","Batch [57/105] Loss: 3.8023176193237305\n","Batch [58/105] Loss: 28.267274856567383\n","Batch [59/105] Loss: 17.32986068725586\n","Batch [60/105] Loss: 14.438770294189453\n","Batch [61/105] Loss: 45.2344970703125\n","Batch [62/105] Loss: 14.237998962402344\n","Batch [63/105] Loss: 52.899658203125\n","Batch [64/105] Loss: 10.479269981384277\n","Batch [65/105] Loss: 8.557897567749023\n","Batch [66/105] Loss: 36.185646057128906\n","Batch [67/105] Loss: 35.66814041137695\n","Batch [68/105] Loss: 16.910057067871094\n","Batch [69/105] Loss: 4.146349906921387\n","Batch [70/105] Loss: 16.255781173706055\n","Batch [71/105] Loss: 6.568513870239258\n","Batch [72/105] Loss: 18.71891212463379\n","Batch [73/105] Loss: 5.096700668334961\n","Batch [74/105] Loss: 19.265838623046875\n","Batch [75/105] Loss: 10.716053009033203\n","Batch [76/105] Loss: 18.280248641967773\n","Batch [77/105] Loss: 10.17013168334961\n","Batch [78/105] Loss: 12.182565689086914\n","Batch [79/105] Loss: 32.81370544433594\n","Batch [80/105] Loss: 11.40178108215332\n","Batch [81/105] Loss: 7.477415084838867\n","Batch [82/105] Loss: 23.947036743164062\n","Batch [83/105] Loss: 12.444467544555664\n","Batch [84/105] Loss: 21.378353118896484\n","Batch [85/105] Loss: 15.971481323242188\n","Batch [86/105] Loss: 6.672642707824707\n","Batch [87/105] Loss: 20.83905029296875\n","Batch [88/105] Loss: 12.777222633361816\n","Batch [89/105] Loss: 29.409711837768555\n","Batch [90/105] Loss: 6.3350725173950195\n","Batch [91/105] Loss: 30.521148681640625\n","Batch [92/105] Loss: 6.187502384185791\n","Batch [93/105] Loss: 31.711742401123047\n","Batch [94/105] Loss: 28.505386352539062\n","Batch [95/105] Loss: 24.754901885986328\n","Batch [96/105] Loss: 28.99239730834961\n","Batch [97/105] Loss: 22.685771942138672\n","Batch [98/105] Loss: 13.277921676635742\n","Batch [99/105] Loss: 27.009809494018555\n","Batch [100/105] Loss: 40.3991813659668\n","Batch [101/105] Loss: 23.172300338745117\n","Batch [102/105] Loss: 41.429813385009766\n","Batch [103/105] Loss: 30.84362030029297\n","Batch [104/105] Loss: 12.078495025634766\n","Batch [105/105] Loss: 59.57607650756836\n","Epoch [35/50], Loss: 21.061724571954635\n","Batch [1/105] Loss: 17.527759552001953\n","Batch [2/105] Loss: 23.432382583618164\n","Batch [3/105] Loss: 38.792476654052734\n","Batch [4/105] Loss: 125.66192626953125\n","Batch [5/105] Loss: 16.994380950927734\n","Batch [6/105] Loss: 21.772438049316406\n","Batch [7/105] Loss: 28.130767822265625\n","Batch [8/105] Loss: 7.206548690795898\n","Batch [9/105] Loss: 15.242011070251465\n","Batch [10/105] Loss: 22.739795684814453\n","Batch [11/105] Loss: 7.2668328285217285\n","Batch [12/105] Loss: 9.182814598083496\n","Batch [13/105] Loss: 25.082401275634766\n","Batch [14/105] Loss: 30.882585525512695\n","Batch [15/105] Loss: 7.931719779968262\n","Batch [16/105] Loss: 17.56641387939453\n","Batch [17/105] Loss: 19.161819458007812\n","Batch [18/105] Loss: 15.380929946899414\n","Batch [19/105] Loss: 9.68111801147461\n","Batch [20/105] Loss: 15.2609281539917\n","Batch [21/105] Loss: 40.84752655029297\n","Batch [22/105] Loss: 6.491489887237549\n","Batch [23/105] Loss: 7.386196136474609\n","Batch [24/105] Loss: 19.12797737121582\n","Batch [25/105] Loss: 28.18858528137207\n","Batch [26/105] Loss: 13.551490783691406\n","Batch [27/105] Loss: 36.716896057128906\n","Batch [28/105] Loss: 60.282684326171875\n","Batch [29/105] Loss: 18.24544906616211\n","Batch [30/105] Loss: 23.518352508544922\n","Batch [31/105] Loss: 16.62555694580078\n","Batch [32/105] Loss: 29.133729934692383\n","Batch [33/105] Loss: 23.76908302307129\n","Batch [34/105] Loss: 46.29629898071289\n","Batch [35/105] Loss: 12.142194747924805\n","Batch [36/105] Loss: 8.811494827270508\n","Batch [37/105] Loss: 10.480668067932129\n","Batch [38/105] Loss: 36.32140350341797\n","Batch [39/105] Loss: 14.815482139587402\n","Batch [40/105] Loss: 12.85866641998291\n","Batch [41/105] Loss: 18.72475814819336\n","Batch [42/105] Loss: 13.546039581298828\n","Batch [43/105] Loss: 15.50151252746582\n","Batch [44/105] Loss: 29.90485382080078\n","Batch [45/105] Loss: 28.418771743774414\n","Batch [46/105] Loss: 20.11919593811035\n","Batch [47/105] Loss: 29.455162048339844\n","Batch [48/105] Loss: 19.14577865600586\n","Batch [49/105] Loss: 47.47578048706055\n","Batch [50/105] Loss: 7.928325176239014\n","Batch [51/105] Loss: 13.26542854309082\n","Batch [52/105] Loss: 12.718242645263672\n","Batch [53/105] Loss: 4.492379188537598\n","Batch [54/105] Loss: 11.80431079864502\n","Batch [55/105] Loss: 12.904670715332031\n","Batch [56/105] Loss: 14.813326835632324\n","Batch [57/105] Loss: 49.29022216796875\n","Batch [58/105] Loss: 10.901711463928223\n","Batch [59/105] Loss: 51.077972412109375\n","Batch [60/105] Loss: 2.8235697746276855\n","Batch [61/105] Loss: 8.110424041748047\n","Batch [62/105] Loss: 26.627952575683594\n","Batch [63/105] Loss: 29.79514503479004\n","Batch [64/105] Loss: 17.171228408813477\n","Batch [65/105] Loss: 18.66962432861328\n","Batch [66/105] Loss: 11.874090194702148\n","Batch [67/105] Loss: 17.131805419921875\n","Batch [68/105] Loss: 22.121662139892578\n","Batch [69/105] Loss: 8.881468772888184\n","Batch [70/105] Loss: 21.413597106933594\n","Batch [71/105] Loss: 8.784542083740234\n","Batch [72/105] Loss: 3.6192543506622314\n","Batch [73/105] Loss: 17.09427833557129\n","Batch [74/105] Loss: 34.537479400634766\n","Batch [75/105] Loss: 7.996625900268555\n","Batch [76/105] Loss: 44.834739685058594\n","Batch [77/105] Loss: 70.80620574951172\n","Batch [78/105] Loss: 9.876187324523926\n","Batch [79/105] Loss: 10.886470794677734\n","Batch [80/105] Loss: 12.39179801940918\n","Batch [81/105] Loss: 48.914878845214844\n","Batch [82/105] Loss: 7.473091125488281\n","Batch [83/105] Loss: 9.97625732421875\n","Batch [84/105] Loss: 15.458303451538086\n","Batch [85/105] Loss: 28.91397476196289\n","Batch [86/105] Loss: 13.408123016357422\n","Batch [87/105] Loss: 11.243009567260742\n","Batch [88/105] Loss: 5.734806060791016\n","Batch [89/105] Loss: 24.21637725830078\n","Batch [90/105] Loss: 43.20996856689453\n","Batch [91/105] Loss: 7.771306037902832\n","Batch [92/105] Loss: 8.656242370605469\n","Batch [93/105] Loss: 12.559883117675781\n","Batch [94/105] Loss: 47.93133544921875\n","Batch [95/105] Loss: 10.380556106567383\n","Batch [96/105] Loss: 12.851351737976074\n","Batch [97/105] Loss: 47.340824127197266\n","Batch [98/105] Loss: 13.662551879882812\n","Batch [99/105] Loss: 20.413047790527344\n","Batch [100/105] Loss: 27.05994987487793\n","Batch [101/105] Loss: 17.01276969909668\n","Batch [102/105] Loss: 7.895371437072754\n","Batch [103/105] Loss: 15.85003662109375\n","Batch [104/105] Loss: 19.1854248046875\n","Batch [105/105] Loss: 83.47348022460938\n","Epoch [36/50], Loss: 22.07655991372608\n","Batch [1/105] Loss: 8.146995544433594\n","Batch [2/105] Loss: 14.477429389953613\n","Batch [3/105] Loss: 31.582847595214844\n","Batch [4/105] Loss: 15.287985801696777\n","Batch [5/105] Loss: 17.847850799560547\n","Batch [6/105] Loss: 12.665864944458008\n","Batch [7/105] Loss: 18.233257293701172\n","Batch [8/105] Loss: 32.136077880859375\n","Batch [9/105] Loss: 17.449010848999023\n","Batch [10/105] Loss: 31.486242294311523\n","Batch [11/105] Loss: 12.918542861938477\n","Batch [12/105] Loss: 37.042564392089844\n","Batch [13/105] Loss: 13.709424018859863\n","Batch [14/105] Loss: 11.5678129196167\n","Batch [15/105] Loss: 12.769201278686523\n","Batch [16/105] Loss: 9.001574516296387\n","Batch [17/105] Loss: 16.509445190429688\n","Batch [18/105] Loss: 24.42611312866211\n","Batch [19/105] Loss: 21.814136505126953\n","Batch [20/105] Loss: 5.033003807067871\n","Batch [21/105] Loss: 13.34388256072998\n","Batch [22/105] Loss: 6.038679122924805\n","Batch [23/105] Loss: 19.118026733398438\n","Batch [24/105] Loss: 16.432392120361328\n","Batch [25/105] Loss: 17.570383071899414\n","Batch [26/105] Loss: 6.887432098388672\n","Batch [27/105] Loss: 12.597739219665527\n","Batch [28/105] Loss: 65.43156433105469\n","Batch [29/105] Loss: 42.7292366027832\n","Batch [30/105] Loss: 5.765142440795898\n","Batch [31/105] Loss: 25.28919792175293\n","Batch [32/105] Loss: 6.88986349105835\n","Batch [33/105] Loss: 10.483881950378418\n","Batch [34/105] Loss: 21.96967315673828\n","Batch [35/105] Loss: 67.86647033691406\n","Batch [36/105] Loss: 52.4366455078125\n","Batch [37/105] Loss: 21.107009887695312\n","Batch [38/105] Loss: 77.09439086914062\n","Batch [39/105] Loss: 36.28410720825195\n","Batch [40/105] Loss: 21.70394515991211\n","Batch [41/105] Loss: 24.201658248901367\n","Batch [42/105] Loss: 37.94063949584961\n","Batch [43/105] Loss: 12.081825256347656\n","Batch [44/105] Loss: 24.840473175048828\n","Batch [45/105] Loss: 12.994915008544922\n","Batch [46/105] Loss: 17.312910079956055\n","Batch [47/105] Loss: 16.259307861328125\n","Batch [48/105] Loss: 23.138437271118164\n","Batch [49/105] Loss: 35.86691665649414\n","Batch [50/105] Loss: 24.613338470458984\n","Batch [51/105] Loss: 33.01494598388672\n","Batch [52/105] Loss: 14.370729446411133\n","Batch [53/105] Loss: 8.444608688354492\n","Batch [54/105] Loss: 22.374292373657227\n","Batch [55/105] Loss: 41.42604064941406\n","Batch [56/105] Loss: 54.328468322753906\n","Batch [57/105] Loss: 22.684959411621094\n","Batch [58/105] Loss: 12.490361213684082\n","Batch [59/105] Loss: 13.988495826721191\n","Batch [60/105] Loss: 10.211666107177734\n","Batch [61/105] Loss: 25.317602157592773\n","Batch [62/105] Loss: 10.88209342956543\n","Batch [63/105] Loss: 13.222650527954102\n","Batch [64/105] Loss: 12.877086639404297\n","Batch [65/105] Loss: 20.736589431762695\n","Batch [66/105] Loss: 39.958770751953125\n","Batch [67/105] Loss: 15.391498565673828\n","Batch [68/105] Loss: 19.224096298217773\n","Batch [69/105] Loss: 6.780998229980469\n","Batch [70/105] Loss: 58.5362434387207\n","Batch [71/105] Loss: 21.49138641357422\n","Batch [72/105] Loss: 11.565940856933594\n","Batch [73/105] Loss: 15.19485855102539\n","Batch [74/105] Loss: 16.186359405517578\n","Batch [75/105] Loss: 31.509883880615234\n","Batch [76/105] Loss: 26.986726760864258\n","Batch [77/105] Loss: 13.098440170288086\n","Batch [78/105] Loss: 14.734052658081055\n","Batch [79/105] Loss: 13.130142211914062\n","Batch [80/105] Loss: 9.990242958068848\n","Batch [81/105] Loss: 24.246719360351562\n","Batch [82/105] Loss: 18.055498123168945\n","Batch [83/105] Loss: 15.719131469726562\n","Batch [84/105] Loss: 4.181931495666504\n","Batch [85/105] Loss: 13.523033142089844\n","Batch [86/105] Loss: 8.366395950317383\n","Batch [87/105] Loss: 23.505136489868164\n","Batch [88/105] Loss: 24.971038818359375\n","Batch [89/105] Loss: 18.528486251831055\n","Batch [90/105] Loss: 8.434959411621094\n","Batch [91/105] Loss: 24.3915958404541\n","Batch [92/105] Loss: 10.753238677978516\n","Batch [93/105] Loss: 20.92259407043457\n","Batch [94/105] Loss: 13.23265266418457\n","Batch [95/105] Loss: 10.87917709350586\n","Batch [96/105] Loss: 7.560323715209961\n","Batch [97/105] Loss: 18.740676879882812\n","Batch [98/105] Loss: 4.955323219299316\n","Batch [99/105] Loss: 29.62744903564453\n","Batch [100/105] Loss: 11.293360710144043\n","Batch [101/105] Loss: 12.553637504577637\n","Batch [102/105] Loss: 9.64753532409668\n","Batch [103/105] Loss: 42.814632415771484\n","Batch [104/105] Loss: 16.623794555664062\n","Batch [105/105] Loss: 23.410085678100586\n","Epoch [37/50], Loss: 20.833181957971483\n","Batch [1/105] Loss: 24.05304527282715\n","Batch [2/105] Loss: 12.355045318603516\n","Batch [3/105] Loss: 19.977733612060547\n","Batch [4/105] Loss: 11.7675142288208\n","Batch [5/105] Loss: 9.557193756103516\n","Batch [6/105] Loss: 28.13172721862793\n","Batch [7/105] Loss: 17.086124420166016\n","Batch [8/105] Loss: 17.27244758605957\n","Batch [9/105] Loss: 25.5938720703125\n","Batch [10/105] Loss: 14.616966247558594\n","Batch [11/105] Loss: 11.233772277832031\n","Batch [12/105] Loss: 8.700291633605957\n","Batch [13/105] Loss: 6.805304527282715\n","Batch [14/105] Loss: 9.774826049804688\n","Batch [15/105] Loss: 30.022050857543945\n","Batch [16/105] Loss: 16.51608657836914\n","Batch [17/105] Loss: 17.89885711669922\n","Batch [18/105] Loss: 38.114356994628906\n","Batch [19/105] Loss: 24.552227020263672\n","Batch [20/105] Loss: 23.73040771484375\n","Batch [21/105] Loss: 21.52033233642578\n","Batch [22/105] Loss: 16.200580596923828\n","Batch [23/105] Loss: 43.049102783203125\n","Batch [24/105] Loss: 35.09188461303711\n","Batch [25/105] Loss: 21.805706024169922\n","Batch [26/105] Loss: 18.302547454833984\n","Batch [27/105] Loss: 27.19355010986328\n","Batch [28/105] Loss: 29.972192764282227\n","Batch [29/105] Loss: 36.18069839477539\n","Batch [30/105] Loss: 3.870647430419922\n","Batch [31/105] Loss: 11.599632263183594\n","Batch [32/105] Loss: 21.52349853515625\n","Batch [33/105] Loss: 16.63880729675293\n","Batch [34/105] Loss: 7.450915336608887\n","Batch [35/105] Loss: 30.26287841796875\n","Batch [36/105] Loss: 29.980257034301758\n","Batch [37/105] Loss: 4.038162708282471\n","Batch [38/105] Loss: 16.67606544494629\n","Batch [39/105] Loss: 21.91735076904297\n","Batch [40/105] Loss: 18.24665641784668\n","Batch [41/105] Loss: 21.709938049316406\n","Batch [42/105] Loss: 33.39451217651367\n","Batch [43/105] Loss: 21.891490936279297\n","Batch [44/105] Loss: 21.283666610717773\n","Batch [45/105] Loss: 16.426342010498047\n","Batch [46/105] Loss: 12.742382049560547\n","Batch [47/105] Loss: 5.641676425933838\n","Batch [48/105] Loss: 40.33116149902344\n","Batch [49/105] Loss: 21.401254653930664\n","Batch [50/105] Loss: 13.596453666687012\n","Batch [51/105] Loss: 22.68738555908203\n","Batch [52/105] Loss: 11.903929710388184\n","Batch [53/105] Loss: 6.872915267944336\n","Batch [54/105] Loss: 14.794023513793945\n","Batch [55/105] Loss: 31.01457977294922\n","Batch [56/105] Loss: 17.91692543029785\n","Batch [57/105] Loss: 13.301567077636719\n","Batch [58/105] Loss: 16.63689422607422\n","Batch [59/105] Loss: 33.99032211303711\n","Batch [60/105] Loss: 19.733890533447266\n","Batch [61/105] Loss: 3.4997053146362305\n","Batch [62/105] Loss: 25.56795883178711\n","Batch [63/105] Loss: 11.211063385009766\n","Batch [64/105] Loss: 17.921693801879883\n","Batch [65/105] Loss: 27.604209899902344\n","Batch [66/105] Loss: 27.31517791748047\n","Batch [67/105] Loss: 39.396812438964844\n","Batch [68/105] Loss: 11.629743576049805\n","Batch [69/105] Loss: 16.89385414123535\n","Batch [70/105] Loss: 28.26390266418457\n","Batch [71/105] Loss: 27.28421401977539\n","Batch [72/105] Loss: 17.677448272705078\n","Batch [73/105] Loss: 6.739774703979492\n","Batch [74/105] Loss: 4.114277362823486\n","Batch [75/105] Loss: 35.855594635009766\n","Batch [76/105] Loss: 7.969061374664307\n","Batch [77/105] Loss: 31.825958251953125\n","Batch [78/105] Loss: 16.84934425354004\n","Batch [79/105] Loss: 48.08800506591797\n","Batch [80/105] Loss: 31.80026626586914\n","Batch [81/105] Loss: 13.747747421264648\n","Batch [82/105] Loss: 45.30133819580078\n","Batch [83/105] Loss: 15.34164810180664\n","Batch [84/105] Loss: 26.62125015258789\n","Batch [85/105] Loss: 37.322052001953125\n","Batch [86/105] Loss: 26.669742584228516\n","Batch [87/105] Loss: 44.796878814697266\n","Batch [88/105] Loss: 10.754388809204102\n","Batch [89/105] Loss: 20.293865203857422\n","Batch [90/105] Loss: 12.539374351501465\n","Batch [91/105] Loss: 24.231380462646484\n","Batch [92/105] Loss: 24.082839965820312\n","Batch [93/105] Loss: 39.96369934082031\n","Batch [94/105] Loss: 17.730344772338867\n","Batch [95/105] Loss: 9.579240798950195\n","Batch [96/105] Loss: 13.026544570922852\n","Batch [97/105] Loss: 30.546707153320312\n","Batch [98/105] Loss: 15.978657722473145\n","Batch [99/105] Loss: 19.072330474853516\n","Batch [100/105] Loss: 28.393117904663086\n","Batch [101/105] Loss: 14.095051765441895\n","Batch [102/105] Loss: 17.47606658935547\n","Batch [103/105] Loss: 14.56784439086914\n","Batch [104/105] Loss: 18.738271713256836\n","Batch [105/105] Loss: 27.040441513061523\n","Epoch [38/50], Loss: 20.97115732828776\n","Batch [1/105] Loss: 22.498750686645508\n","Batch [2/105] Loss: 39.12492370605469\n","Batch [3/105] Loss: 17.849472045898438\n","Batch [4/105] Loss: 20.09416961669922\n","Batch [5/105] Loss: 20.637020111083984\n","Batch [6/105] Loss: 15.869487762451172\n","Batch [7/105] Loss: 13.084771156311035\n","Batch [8/105] Loss: 8.744535446166992\n","Batch [9/105] Loss: 15.1062650680542\n","Batch [10/105] Loss: 15.523859977722168\n","Batch [11/105] Loss: 12.123037338256836\n","Batch [12/105] Loss: 21.796173095703125\n","Batch [13/105] Loss: 21.858604431152344\n","Batch [14/105] Loss: 10.647760391235352\n","Batch [15/105] Loss: 11.926287651062012\n","Batch [16/105] Loss: 20.758827209472656\n","Batch [17/105] Loss: 50.13562774658203\n","Batch [18/105] Loss: 4.61745548248291\n","Batch [19/105] Loss: 35.33999252319336\n","Batch [20/105] Loss: 15.878963470458984\n","Batch [21/105] Loss: 45.76626968383789\n","Batch [22/105] Loss: 12.184061050415039\n","Batch [23/105] Loss: 6.214001178741455\n","Batch [24/105] Loss: 7.72054386138916\n","Batch [25/105] Loss: 9.99243450164795\n","Batch [26/105] Loss: 51.316001892089844\n","Batch [27/105] Loss: 23.807880401611328\n","Batch [28/105] Loss: 12.51054573059082\n","Batch [29/105] Loss: 18.67040252685547\n","Batch [30/105] Loss: 7.232108116149902\n","Batch [31/105] Loss: 10.291257858276367\n","Batch [32/105] Loss: 19.563892364501953\n","Batch [33/105] Loss: 31.798320770263672\n","Batch [34/105] Loss: 41.85310363769531\n","Batch [35/105] Loss: 28.594036102294922\n","Batch [36/105] Loss: 10.395015716552734\n","Batch [37/105] Loss: 15.144359588623047\n","Batch [38/105] Loss: 18.48514747619629\n","Batch [39/105] Loss: 24.709423065185547\n","Batch [40/105] Loss: 12.789830207824707\n","Batch [41/105] Loss: 8.118831634521484\n","Batch [42/105] Loss: 13.499247550964355\n","Batch [43/105] Loss: 16.103368759155273\n","Batch [44/105] Loss: 52.59634017944336\n","Batch [45/105] Loss: 18.29189682006836\n","Batch [46/105] Loss: 10.774740219116211\n","Batch [47/105] Loss: 33.98894119262695\n","Batch [48/105] Loss: 28.442493438720703\n","Batch [49/105] Loss: 16.745922088623047\n","Batch [50/105] Loss: 9.731141090393066\n","Batch [51/105] Loss: 8.498230934143066\n","Batch [52/105] Loss: 26.46687126159668\n","Batch [53/105] Loss: 9.622771263122559\n","Batch [54/105] Loss: 5.575815200805664\n","Batch [55/105] Loss: 15.688790321350098\n","Batch [56/105] Loss: 13.017354965209961\n","Batch [57/105] Loss: 12.060314178466797\n","Batch [58/105] Loss: 28.165306091308594\n","Batch [59/105] Loss: 9.939870834350586\n","Batch [60/105] Loss: 26.92947769165039\n","Batch [61/105] Loss: 17.16258430480957\n","Batch [62/105] Loss: 19.406984329223633\n","Batch [63/105] Loss: 14.750510215759277\n","Batch [64/105] Loss: 18.804582595825195\n","Batch [65/105] Loss: 6.629281520843506\n","Batch [66/105] Loss: 9.036018371582031\n","Batch [67/105] Loss: 18.0367374420166\n","Batch [68/105] Loss: 21.685575485229492\n","Batch [69/105] Loss: 16.245885848999023\n","Batch [70/105] Loss: 66.1664810180664\n","Batch [71/105] Loss: 30.477237701416016\n","Batch [72/105] Loss: 64.58740234375\n","Batch [73/105] Loss: 26.01040267944336\n","Batch [74/105] Loss: 8.700141906738281\n","Batch [75/105] Loss: 13.6160306930542\n","Batch [76/105] Loss: 50.230220794677734\n","Batch [77/105] Loss: 7.097815036773682\n","Batch [78/105] Loss: 16.75507354736328\n","Batch [79/105] Loss: 21.408681869506836\n","Batch [80/105] Loss: 11.717228889465332\n","Batch [81/105] Loss: 6.132498741149902\n","Batch [82/105] Loss: 17.224185943603516\n","Batch [83/105] Loss: 30.688955307006836\n","Batch [84/105] Loss: 24.68410873413086\n","Batch [85/105] Loss: 12.443340301513672\n","Batch [86/105] Loss: 55.27105712890625\n","Batch [87/105] Loss: 25.12769889831543\n","Batch [88/105] Loss: 34.947235107421875\n","Batch [89/105] Loss: 9.19957160949707\n","Batch [90/105] Loss: 33.19593048095703\n","Batch [91/105] Loss: 18.485538482666016\n","Batch [92/105] Loss: 9.314788818359375\n","Batch [93/105] Loss: 11.827579498291016\n","Batch [94/105] Loss: 5.196258544921875\n","Batch [95/105] Loss: 32.64608383178711\n","Batch [96/105] Loss: 25.212474822998047\n","Batch [97/105] Loss: 16.194019317626953\n","Batch [98/105] Loss: 62.54466247558594\n","Batch [99/105] Loss: 25.518659591674805\n","Batch [100/105] Loss: 25.172950744628906\n","Batch [101/105] Loss: 22.297542572021484\n","Batch [102/105] Loss: 22.200313568115234\n","Batch [103/105] Loss: 31.191471099853516\n","Batch [104/105] Loss: 40.381385803222656\n","Batch [105/105] Loss: 12.178031921386719\n","Epoch [39/50], Loss: 21.282986345745268\n","Batch [1/105] Loss: 26.829097747802734\n","Batch [2/105] Loss: 3.7755565643310547\n","Batch [3/105] Loss: 45.11592483520508\n","Batch [4/105] Loss: 15.777501106262207\n","Batch [5/105] Loss: 18.725704193115234\n","Batch [6/105] Loss: 13.422138214111328\n","Batch [7/105] Loss: 16.90083122253418\n","Batch [8/105] Loss: 27.490848541259766\n","Batch [9/105] Loss: 8.297547340393066\n","Batch [10/105] Loss: 4.985701560974121\n","Batch [11/105] Loss: 56.674659729003906\n","Batch [12/105] Loss: 18.899200439453125\n","Batch [13/105] Loss: 9.400035858154297\n","Batch [14/105] Loss: 15.02414321899414\n","Batch [15/105] Loss: 49.11027145385742\n","Batch [16/105] Loss: 10.45866584777832\n","Batch [17/105] Loss: 23.085914611816406\n","Batch [18/105] Loss: 14.072166442871094\n","Batch [19/105] Loss: 60.911460876464844\n","Batch [20/105] Loss: 7.549481391906738\n","Batch [21/105] Loss: 14.902488708496094\n","Batch [22/105] Loss: 44.811920166015625\n","Batch [23/105] Loss: 21.152084350585938\n","Batch [24/105] Loss: 13.534903526306152\n","Batch [25/105] Loss: 47.43849182128906\n","Batch [26/105] Loss: 23.210006713867188\n","Batch [27/105] Loss: 23.663249969482422\n","Batch [28/105] Loss: 8.401544570922852\n","Batch [29/105] Loss: 10.483068466186523\n","Batch [30/105] Loss: 14.821124076843262\n","Batch [31/105] Loss: 52.23970031738281\n","Batch [32/105] Loss: 57.84175109863281\n","Batch [33/105] Loss: 10.717423439025879\n","Batch [34/105] Loss: 18.881500244140625\n","Batch [35/105] Loss: 11.351273536682129\n","Batch [36/105] Loss: 14.492198944091797\n","Batch [37/105] Loss: 3.609968423843384\n","Batch [38/105] Loss: 14.473221778869629\n","Batch [39/105] Loss: 11.02810287475586\n","Batch [40/105] Loss: 15.044971466064453\n","Batch [41/105] Loss: 16.466501235961914\n","Batch [42/105] Loss: 6.056633949279785\n","Batch [43/105] Loss: 40.033653259277344\n","Batch [44/105] Loss: 4.288106918334961\n","Batch [45/105] Loss: 18.154102325439453\n","Batch [46/105] Loss: 15.368268966674805\n","Batch [47/105] Loss: 4.300663471221924\n","Batch [48/105] Loss: 9.39034366607666\n","Batch [49/105] Loss: 20.512693405151367\n","Batch [50/105] Loss: 11.361370086669922\n","Batch [51/105] Loss: 12.041860580444336\n","Batch [52/105] Loss: 8.39372730255127\n","Batch [53/105] Loss: 16.437034606933594\n","Batch [54/105] Loss: 11.811969757080078\n","Batch [55/105] Loss: 42.13224792480469\n","Batch [56/105] Loss: 45.86668395996094\n","Batch [57/105] Loss: 10.006819725036621\n","Batch [58/105] Loss: 23.188669204711914\n","Batch [59/105] Loss: 17.87403106689453\n","Batch [60/105] Loss: 17.019187927246094\n","Batch [61/105] Loss: 55.46127700805664\n","Batch [62/105] Loss: 16.13202667236328\n","Batch [63/105] Loss: 53.6937255859375\n","Batch [64/105] Loss: 47.433353424072266\n","Batch [65/105] Loss: 18.25459861755371\n","Batch [66/105] Loss: 8.020383834838867\n","Batch [67/105] Loss: 12.346753120422363\n","Batch [68/105] Loss: 19.265724182128906\n","Batch [69/105] Loss: 15.684516906738281\n","Batch [70/105] Loss: 13.772294044494629\n","Batch [71/105] Loss: 8.467755317687988\n","Batch [72/105] Loss: 14.403579711914062\n","Batch [73/105] Loss: 4.655191898345947\n","Batch [74/105] Loss: 7.980907440185547\n","Batch [75/105] Loss: 12.264274597167969\n","Batch [76/105] Loss: 21.091880798339844\n","Batch [77/105] Loss: 16.162952423095703\n","Batch [78/105] Loss: 8.685949325561523\n","Batch [79/105] Loss: 18.575302124023438\n","Batch [80/105] Loss: 28.09091567993164\n","Batch [81/105] Loss: 11.574078559875488\n","Batch [82/105] Loss: 17.149911880493164\n","Batch [83/105] Loss: 45.906028747558594\n","Batch [84/105] Loss: 10.872238159179688\n","Batch [85/105] Loss: 9.508731842041016\n","Batch [86/105] Loss: 16.75436782836914\n","Batch [87/105] Loss: 38.312767028808594\n","Batch [88/105] Loss: 36.735450744628906\n","Batch [89/105] Loss: 11.627528190612793\n","Batch [90/105] Loss: 24.85717010498047\n","Batch [91/105] Loss: 5.492519855499268\n","Batch [92/105] Loss: 22.03333282470703\n","Batch [93/105] Loss: 13.420629501342773\n","Batch [94/105] Loss: 10.201478958129883\n","Batch [95/105] Loss: 14.141239166259766\n","Batch [96/105] Loss: 6.986302375793457\n","Batch [97/105] Loss: 3.8621323108673096\n","Batch [98/105] Loss: 9.968475341796875\n","Batch [99/105] Loss: 8.207893371582031\n","Batch [100/105] Loss: 12.008913040161133\n","Batch [101/105] Loss: 5.561193943023682\n","Batch [102/105] Loss: 6.658230781555176\n","Batch [103/105] Loss: 38.503334045410156\n","Batch [104/105] Loss: 11.37777328491211\n","Batch [105/105] Loss: 2.6330089569091797\n","Epoch [40/50], Loss: 19.277223891303652\n","New minimum loss achieved: 19.277223891303652. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 27.503013610839844\n","Batch [2/105] Loss: 11.495004653930664\n","Batch [3/105] Loss: 16.98937225341797\n","Batch [4/105] Loss: 11.625360488891602\n","Batch [5/105] Loss: 14.873598098754883\n","Batch [6/105] Loss: 45.143890380859375\n","Batch [7/105] Loss: 5.266749382019043\n","Batch [8/105] Loss: 9.182899475097656\n","Batch [9/105] Loss: 13.583883285522461\n","Batch [10/105] Loss: 21.121471405029297\n","Batch [11/105] Loss: 2.4588305950164795\n","Batch [12/105] Loss: 14.413137435913086\n","Batch [13/105] Loss: 8.986743927001953\n","Batch [14/105] Loss: 7.198075771331787\n","Batch [15/105] Loss: 39.22535705566406\n","Batch [16/105] Loss: 11.029873847961426\n","Batch [17/105] Loss: 13.913164138793945\n","Batch [18/105] Loss: 23.361743927001953\n","Batch [19/105] Loss: 107.3802490234375\n","Batch [20/105] Loss: 10.987943649291992\n","Batch [21/105] Loss: 3.2435102462768555\n","Batch [22/105] Loss: 11.587240219116211\n","Batch [23/105] Loss: 19.574750900268555\n","Batch [24/105] Loss: 7.946866512298584\n","Batch [25/105] Loss: 64.50993347167969\n","Batch [26/105] Loss: 10.268815994262695\n","Batch [27/105] Loss: 41.18688201904297\n","Batch [28/105] Loss: 28.350078582763672\n","Batch [29/105] Loss: 14.632335662841797\n","Batch [30/105] Loss: 25.107955932617188\n","Batch [31/105] Loss: 7.375827789306641\n","Batch [32/105] Loss: 56.382240295410156\n","Batch [33/105] Loss: 18.368955612182617\n","Batch [34/105] Loss: 15.686910629272461\n","Batch [35/105] Loss: 16.799179077148438\n","Batch [36/105] Loss: 10.071743965148926\n","Batch [37/105] Loss: 12.021453857421875\n","Batch [38/105] Loss: 23.638303756713867\n","Batch [39/105] Loss: 16.19533348083496\n","Batch [40/105] Loss: 19.360193252563477\n","Batch [41/105] Loss: 12.045413970947266\n","Batch [42/105] Loss: 7.542631149291992\n","Batch [43/105] Loss: 21.03055763244629\n","Batch [44/105] Loss: 6.110681056976318\n","Batch [45/105] Loss: 49.67617416381836\n","Batch [46/105] Loss: 6.634173393249512\n","Batch [47/105] Loss: 30.178760528564453\n","Batch [48/105] Loss: 7.278967380523682\n","Batch [49/105] Loss: 11.601701736450195\n","Batch [50/105] Loss: 25.903791427612305\n","Batch [51/105] Loss: 79.06509399414062\n","Batch [52/105] Loss: 29.929208755493164\n","Batch [53/105] Loss: 3.682943344116211\n","Batch [54/105] Loss: 7.561683654785156\n","Batch [55/105] Loss: 13.668880462646484\n","Batch [56/105] Loss: 29.926776885986328\n","Batch [57/105] Loss: 10.236344337463379\n","Batch [58/105] Loss: 10.770660400390625\n","Batch [59/105] Loss: 6.3065385818481445\n","Batch [60/105] Loss: 31.285985946655273\n","Batch [61/105] Loss: 18.346708297729492\n","Batch [62/105] Loss: 27.926708221435547\n","Batch [63/105] Loss: 29.273054122924805\n","Batch [64/105] Loss: 13.003951072692871\n","Batch [65/105] Loss: 14.214803695678711\n","Batch [66/105] Loss: 49.972129821777344\n","Batch [67/105] Loss: 12.99718189239502\n","Batch [68/105] Loss: 42.061790466308594\n","Batch [69/105] Loss: 8.060976028442383\n","Batch [70/105] Loss: 21.589214324951172\n","Batch [71/105] Loss: 11.756256103515625\n","Batch [72/105] Loss: 25.304824829101562\n","Batch [73/105] Loss: 18.997337341308594\n","Batch [74/105] Loss: 12.171920776367188\n","Batch [75/105] Loss: 30.564922332763672\n","Batch [76/105] Loss: 17.353904724121094\n","Batch [77/105] Loss: 21.829952239990234\n","Batch [78/105] Loss: 10.61252212524414\n","Batch [79/105] Loss: 9.957250595092773\n","Batch [80/105] Loss: 6.578453063964844\n","Batch [81/105] Loss: 76.3146743774414\n","Batch [82/105] Loss: 12.969686508178711\n","Batch [83/105] Loss: 5.923318862915039\n","Batch [84/105] Loss: 35.41329574584961\n","Batch [85/105] Loss: 106.81011962890625\n","Batch [86/105] Loss: 50.17963790893555\n","Batch [87/105] Loss: 12.053526878356934\n","Batch [88/105] Loss: 24.693283081054688\n","Batch [89/105] Loss: 29.071908950805664\n","Batch [90/105] Loss: 10.109831809997559\n","Batch [91/105] Loss: 29.505287170410156\n","Batch [92/105] Loss: 19.517597198486328\n","Batch [93/105] Loss: 28.250356674194336\n","Batch [94/105] Loss: 11.71135139465332\n","Batch [95/105] Loss: 34.84919357299805\n","Batch [96/105] Loss: 13.603334426879883\n","Batch [97/105] Loss: 15.62881088256836\n","Batch [98/105] Loss: 41.65575408935547\n","Batch [99/105] Loss: 32.48738479614258\n","Batch [100/105] Loss: 45.16337966918945\n","Batch [101/105] Loss: 22.636890411376953\n","Batch [102/105] Loss: 22.017118453979492\n","Batch [103/105] Loss: 13.05809211730957\n","Batch [104/105] Loss: 7.133731842041016\n","Batch [105/105] Loss: 23.62300682067871\n","Epoch [41/50], Loss: 22.528002645855857\n","Batch [1/105] Loss: 6.9762725830078125\n","Batch [2/105] Loss: 7.473941802978516\n","Batch [3/105] Loss: 24.878496170043945\n","Batch [4/105] Loss: 24.04135513305664\n","Batch [5/105] Loss: 18.917043685913086\n","Batch [6/105] Loss: 11.662036895751953\n","Batch [7/105] Loss: 20.791015625\n","Batch [8/105] Loss: 14.739304542541504\n","Batch [9/105] Loss: 9.170738220214844\n","Batch [10/105] Loss: 14.568201065063477\n","Batch [11/105] Loss: 19.25623893737793\n","Batch [12/105] Loss: 21.154077529907227\n","Batch [13/105] Loss: 42.06414031982422\n","Batch [14/105] Loss: 18.44963836669922\n","Batch [15/105] Loss: 14.872406005859375\n","Batch [16/105] Loss: 8.92830753326416\n","Batch [17/105] Loss: 4.6922831535339355\n","Batch [18/105] Loss: 11.370820045471191\n","Batch [19/105] Loss: 7.263044357299805\n","Batch [20/105] Loss: 23.67577362060547\n","Batch [21/105] Loss: 11.56472396850586\n","Batch [22/105] Loss: 10.484140396118164\n","Batch [23/105] Loss: 5.411870002746582\n","Batch [24/105] Loss: 19.88949203491211\n","Batch [25/105] Loss: 26.5716495513916\n","Batch [26/105] Loss: 11.289238929748535\n","Batch [27/105] Loss: 11.932218551635742\n","Batch [28/105] Loss: 11.3840970993042\n","Batch [29/105] Loss: 19.881389617919922\n","Batch [30/105] Loss: 7.452846527099609\n","Batch [31/105] Loss: 11.826374053955078\n","Batch [32/105] Loss: 35.23339080810547\n","Batch [33/105] Loss: 18.907014846801758\n","Batch [34/105] Loss: 23.6794376373291\n","Batch [35/105] Loss: 8.02194881439209\n","Batch [36/105] Loss: 27.482112884521484\n","Batch [37/105] Loss: 12.194822311401367\n","Batch [38/105] Loss: 43.031463623046875\n","Batch [39/105] Loss: 17.446460723876953\n","Batch [40/105] Loss: 13.565492630004883\n","Batch [41/105] Loss: 12.491272926330566\n","Batch [42/105] Loss: 9.142144203186035\n","Batch [43/105] Loss: 7.437763214111328\n","Batch [44/105] Loss: 8.600846290588379\n","Batch [45/105] Loss: 31.61758041381836\n","Batch [46/105] Loss: 10.641101837158203\n","Batch [47/105] Loss: 6.8280158042907715\n","Batch [48/105] Loss: 52.830177307128906\n","Batch [49/105] Loss: 9.978256225585938\n","Batch [50/105] Loss: 9.010858535766602\n","Batch [51/105] Loss: 22.652475357055664\n","Batch [52/105] Loss: 22.212871551513672\n","Batch [53/105] Loss: 12.730995178222656\n","Batch [54/105] Loss: 4.0223894119262695\n","Batch [55/105] Loss: 15.812078475952148\n","Batch [56/105] Loss: 17.14742088317871\n","Batch [57/105] Loss: 21.457225799560547\n","Batch [58/105] Loss: 16.44173812866211\n","Batch [59/105] Loss: 11.627769470214844\n","Batch [60/105] Loss: 18.255916595458984\n","Batch [61/105] Loss: 18.79079246520996\n","Batch [62/105] Loss: 6.1240739822387695\n","Batch [63/105] Loss: 9.714679718017578\n","Batch [64/105] Loss: 11.610382080078125\n","Batch [65/105] Loss: 7.976876735687256\n","Batch [66/105] Loss: 23.53885269165039\n","Batch [67/105] Loss: 25.032920837402344\n","Batch [68/105] Loss: 10.855719566345215\n","Batch [69/105] Loss: 13.652615547180176\n","Batch [70/105] Loss: 22.81745147705078\n","Batch [71/105] Loss: 18.897266387939453\n","Batch [72/105] Loss: 30.188539505004883\n","Batch [73/105] Loss: 20.52093505859375\n","Batch [74/105] Loss: 18.989734649658203\n","Batch [75/105] Loss: 12.068668365478516\n","Batch [76/105] Loss: 32.850502014160156\n","Batch [77/105] Loss: 15.757357597351074\n","Batch [78/105] Loss: 10.879746437072754\n","Batch [79/105] Loss: 19.86509132385254\n","Batch [80/105] Loss: 23.314945220947266\n","Batch [81/105] Loss: 39.281532287597656\n","Batch [82/105] Loss: 15.707645416259766\n","Batch [83/105] Loss: 10.00259017944336\n","Batch [84/105] Loss: 15.998265266418457\n","Batch [85/105] Loss: 40.53861618041992\n","Batch [86/105] Loss: 24.74536895751953\n","Batch [87/105] Loss: 24.928546905517578\n","Batch [88/105] Loss: 15.821393966674805\n","Batch [89/105] Loss: 13.23047161102295\n","Batch [90/105] Loss: 22.583484649658203\n","Batch [91/105] Loss: 10.822481155395508\n","Batch [92/105] Loss: 23.231853485107422\n","Batch [93/105] Loss: 44.358516693115234\n","Batch [94/105] Loss: 7.305887222290039\n","Batch [95/105] Loss: 24.726430892944336\n","Batch [96/105] Loss: 17.50039291381836\n","Batch [97/105] Loss: 13.019600868225098\n","Batch [98/105] Loss: 10.650304794311523\n","Batch [99/105] Loss: 16.65262222290039\n","Batch [100/105] Loss: 15.342766761779785\n","Batch [101/105] Loss: 10.239463806152344\n","Batch [102/105] Loss: 13.8140230178833\n","Batch [103/105] Loss: 13.634257316589355\n","Batch [104/105] Loss: 9.77798080444336\n","Batch [105/105] Loss: 14.9647855758667\n","Epoch [42/50], Loss: 17.290101455506825\n","New minimum loss achieved: 17.290101455506825. Model saved as 'siamese_model_min_loss.pth'.\n","Batch [1/105] Loss: 12.168912887573242\n","Batch [2/105] Loss: 25.925838470458984\n","Batch [3/105] Loss: 18.783336639404297\n","Batch [4/105] Loss: 13.554956436157227\n","Batch [5/105] Loss: 13.530301094055176\n","Batch [6/105] Loss: 5.7747650146484375\n","Batch [7/105] Loss: 14.343628883361816\n","Batch [8/105] Loss: 10.897005081176758\n","Batch [9/105] Loss: 24.637805938720703\n","Batch [10/105] Loss: 32.789695739746094\n","Batch [11/105] Loss: 24.791900634765625\n","Batch [12/105] Loss: 37.06163024902344\n","Batch [13/105] Loss: 25.619953155517578\n","Batch [14/105] Loss: 30.410795211791992\n","Batch [15/105] Loss: 10.109611511230469\n","Batch [16/105] Loss: 21.079832077026367\n","Batch [17/105] Loss: 10.340775489807129\n","Batch [18/105] Loss: 25.095844268798828\n","Batch [19/105] Loss: 4.226509094238281\n","Batch [20/105] Loss: 17.647029876708984\n","Batch [21/105] Loss: 24.652528762817383\n","Batch [22/105] Loss: 30.41391944885254\n","Batch [23/105] Loss: 38.136512756347656\n","Batch [24/105] Loss: 19.590726852416992\n","Batch [25/105] Loss: 24.089366912841797\n","Batch [26/105] Loss: 47.72481918334961\n","Batch [27/105] Loss: 29.76630973815918\n","Batch [28/105] Loss: 5.529456615447998\n","Batch [29/105] Loss: 59.49299240112305\n","Batch [30/105] Loss: 5.123662948608398\n","Batch [31/105] Loss: 16.165122985839844\n","Batch [32/105] Loss: 14.647668838500977\n","Batch [33/105] Loss: 23.249950408935547\n","Batch [34/105] Loss: 14.488330841064453\n","Batch [35/105] Loss: 22.609176635742188\n","Batch [36/105] Loss: 8.827502250671387\n","Batch [37/105] Loss: 29.330402374267578\n","Batch [38/105] Loss: 12.949572563171387\n","Batch [39/105] Loss: 8.327611923217773\n","Batch [40/105] Loss: 18.789974212646484\n","Batch [41/105] Loss: 15.458518981933594\n","Batch [42/105] Loss: 16.121429443359375\n","Batch [43/105] Loss: 23.76885986328125\n","Batch [44/105] Loss: 5.707318305969238\n","Batch [45/105] Loss: 11.892969131469727\n","Batch [46/105] Loss: 10.36644172668457\n","Batch [47/105] Loss: 23.930294036865234\n","Batch [48/105] Loss: 36.782501220703125\n","Batch [49/105] Loss: 6.351783752441406\n","Batch [50/105] Loss: 20.264684677124023\n","Batch [51/105] Loss: 23.00766372680664\n","Batch [52/105] Loss: 28.63906478881836\n","Batch [53/105] Loss: 3.617337703704834\n","Batch [54/105] Loss: 7.857339859008789\n","Batch [55/105] Loss: 27.7374267578125\n","Batch [56/105] Loss: 16.77928924560547\n","Batch [57/105] Loss: 14.241914749145508\n","Batch [58/105] Loss: 24.334796905517578\n","Batch [59/105] Loss: 62.797603607177734\n","Batch [60/105] Loss: 22.92101287841797\n","Batch [61/105] Loss: 26.004234313964844\n","Batch [62/105] Loss: 15.416093826293945\n","Batch [63/105] Loss: 58.986572265625\n","Batch [64/105] Loss: 9.387968063354492\n","Batch [65/105] Loss: 10.000466346740723\n","Batch [66/105] Loss: 10.906102180480957\n","Batch [67/105] Loss: 21.638824462890625\n","Batch [68/105] Loss: 19.95435905456543\n","Batch [69/105] Loss: 18.989044189453125\n","Batch [70/105] Loss: 12.30692195892334\n","Batch [71/105] Loss: 44.59699249267578\n","Batch [72/105] Loss: 11.735332489013672\n","Batch [73/105] Loss: 29.70285987854004\n","Batch [74/105] Loss: 17.587757110595703\n","Batch [75/105] Loss: 50.97642517089844\n","Batch [76/105] Loss: 20.55569076538086\n","Batch [77/105] Loss: 25.283061981201172\n","Batch [78/105] Loss: 18.820232391357422\n","Batch [79/105] Loss: 61.411895751953125\n","Batch [80/105] Loss: 12.924388885498047\n","Batch [81/105] Loss: 21.135055541992188\n","Batch [82/105] Loss: 30.257984161376953\n","Batch [83/105] Loss: 9.587630271911621\n","Batch [84/105] Loss: 7.262295722961426\n","Batch [85/105] Loss: 13.267900466918945\n","Batch [86/105] Loss: 19.215744018554688\n","Batch [87/105] Loss: 38.82536315917969\n","Batch [88/105] Loss: 30.631988525390625\n","Batch [89/105] Loss: 21.151735305786133\n","Batch [90/105] Loss: 25.065370559692383\n","Batch [91/105] Loss: 19.408964157104492\n","Batch [92/105] Loss: 10.020301818847656\n","Batch [93/105] Loss: 40.373085021972656\n","Batch [94/105] Loss: 16.293773651123047\n","Batch [95/105] Loss: 35.973445892333984\n","Batch [96/105] Loss: 23.607166290283203\n","Batch [97/105] Loss: 11.88416576385498\n","Batch [98/105] Loss: 41.01575469970703\n","Batch [99/105] Loss: 10.801006317138672\n","Batch [100/105] Loss: 21.180280685424805\n","Batch [101/105] Loss: 30.646278381347656\n","Batch [102/105] Loss: 42.12189483642578\n","Batch [103/105] Loss: 20.454870223999023\n","Batch [104/105] Loss: 27.59073829650879\n","Batch [105/105] Loss: 14.148839950561523\n","Epoch [43/50], Loss: 22.04172233399891\n","Batch [1/105] Loss: 48.314022064208984\n","Batch [2/105] Loss: 18.009716033935547\n","Batch [3/105] Loss: 64.84790802001953\n","Batch [4/105] Loss: 44.24555969238281\n","Batch [5/105] Loss: 39.350341796875\n","Batch [6/105] Loss: 15.442593574523926\n","Batch [7/105] Loss: 8.115156173706055\n","Batch [8/105] Loss: 12.910995483398438\n","Batch [9/105] Loss: 14.069938659667969\n","Batch [10/105] Loss: 15.265368461608887\n","Batch [11/105] Loss: 7.024531364440918\n","Batch [12/105] Loss: 12.273295402526855\n","Batch [13/105] Loss: 43.60931396484375\n","Batch [14/105] Loss: 16.66862678527832\n","Batch [15/105] Loss: 6.611583709716797\n","Batch [16/105] Loss: 12.999141693115234\n","Batch [17/105] Loss: 6.327298641204834\n","Batch [18/105] Loss: 43.4137077331543\n","Batch [19/105] Loss: 27.52994155883789\n","Batch [20/105] Loss: 37.81915283203125\n","Batch [21/105] Loss: 15.635736465454102\n","Batch [22/105] Loss: 11.8057222366333\n","Batch [23/105] Loss: 30.143484115600586\n","Batch [24/105] Loss: 24.99904441833496\n","Batch [25/105] Loss: 24.987384796142578\n","Batch [26/105] Loss: 28.616313934326172\n","Batch [27/105] Loss: 24.945846557617188\n","Batch [28/105] Loss: 16.53211212158203\n","Batch [29/105] Loss: 30.046154022216797\n","Batch [30/105] Loss: 12.37614631652832\n","Batch [31/105] Loss: 21.183521270751953\n","Batch [32/105] Loss: 10.176010131835938\n","Batch [33/105] Loss: 18.67165756225586\n","Batch [34/105] Loss: 36.67634201049805\n","Batch [35/105] Loss: 28.175416946411133\n","Batch [36/105] Loss: 14.461915016174316\n","Batch [37/105] Loss: 50.60569763183594\n","Batch [38/105] Loss: 8.9259672164917\n","Batch [39/105] Loss: 64.54602813720703\n","Batch [40/105] Loss: 11.94195556640625\n","Batch [41/105] Loss: 12.366039276123047\n","Batch [42/105] Loss: 8.321706771850586\n","Batch [43/105] Loss: 9.316810607910156\n","Batch [44/105] Loss: 22.322795867919922\n","Batch [45/105] Loss: 12.796842575073242\n","Batch [46/105] Loss: 4.683184623718262\n","Batch [47/105] Loss: 15.95025634765625\n","Batch [48/105] Loss: 16.08794403076172\n","Batch [49/105] Loss: 22.615795135498047\n","Batch [50/105] Loss: 8.224072456359863\n","Batch [51/105] Loss: 20.779006958007812\n","Batch [52/105] Loss: 14.373089790344238\n","Batch [53/105] Loss: 32.526145935058594\n","Batch [54/105] Loss: 46.71646499633789\n","Batch [55/105] Loss: 9.39212417602539\n","Batch [56/105] Loss: 13.15489387512207\n","Batch [57/105] Loss: 15.30361557006836\n","Batch [58/105] Loss: 59.11411666870117\n","Batch [59/105] Loss: 60.892513275146484\n","Batch [60/105] Loss: 22.496244430541992\n","Batch [61/105] Loss: 78.00678253173828\n","Batch [62/105] Loss: 19.2229061126709\n","Batch [63/105] Loss: 19.061534881591797\n","Batch [64/105] Loss: 14.146026611328125\n","Batch [65/105] Loss: 22.409523010253906\n","Batch [66/105] Loss: 20.514225006103516\n","Batch [67/105] Loss: 8.212362289428711\n","Batch [68/105] Loss: 21.001224517822266\n","Batch [69/105] Loss: 14.352578163146973\n","Batch [70/105] Loss: 14.12542724609375\n","Batch [71/105] Loss: 11.739921569824219\n","Batch [72/105] Loss: 21.606252670288086\n","Batch [73/105] Loss: 20.59743881225586\n","Batch [74/105] Loss: 21.287765502929688\n","Batch [75/105] Loss: 18.630491256713867\n","Batch [76/105] Loss: 15.62451171875\n","Batch [77/105] Loss: 14.391952514648438\n","Batch [78/105] Loss: 39.77226638793945\n","Batch [79/105] Loss: 12.085836410522461\n","Batch [80/105] Loss: 12.198150634765625\n","Batch [81/105] Loss: 64.40940856933594\n","Batch [82/105] Loss: 13.805334091186523\n","Batch [83/105] Loss: 41.051456451416016\n","Batch [84/105] Loss: 18.356658935546875\n","Batch [85/105] Loss: 8.826677322387695\n","Batch [86/105] Loss: 13.837847709655762\n","Batch [87/105] Loss: 32.2805061340332\n","Batch [88/105] Loss: 22.932395935058594\n","Batch [89/105] Loss: 19.85857391357422\n","Batch [90/105] Loss: 12.634614944458008\n","Batch [91/105] Loss: 14.092616081237793\n","Batch [92/105] Loss: 20.125167846679688\n","Batch [93/105] Loss: 110.96833801269531\n","Batch [94/105] Loss: 13.304437637329102\n","Batch [95/105] Loss: 14.223053932189941\n","Batch [96/105] Loss: 3.0970089435577393\n","Batch [97/105] Loss: 78.44723510742188\n","Batch [98/105] Loss: 11.216986656188965\n","Batch [99/105] Loss: 8.312690734863281\n","Batch [100/105] Loss: 2.0410473346710205\n","Batch [101/105] Loss: 13.092824935913086\n","Batch [102/105] Loss: 37.38423156738281\n","Batch [103/105] Loss: 11.729844093322754\n","Batch [104/105] Loss: 21.795530319213867\n","Batch [105/105] Loss: 22.428316116333008\n","Epoch [44/50], Loss: 23.399755187261672\n","Batch [1/105] Loss: 11.418647766113281\n","Batch [2/105] Loss: 14.932184219360352\n","Batch [3/105] Loss: 13.702659606933594\n","Batch [4/105] Loss: 25.14108657836914\n","Batch [5/105] Loss: 25.67416763305664\n","Batch [6/105] Loss: 7.255491733551025\n","Batch [7/105] Loss: 19.718143463134766\n","Batch [8/105] Loss: 36.71209716796875\n","Batch [9/105] Loss: 45.416324615478516\n","Batch [10/105] Loss: 29.665178298950195\n","Batch [11/105] Loss: 5.2998151779174805\n","Batch [12/105] Loss: 15.176103591918945\n","Batch [13/105] Loss: 8.349825859069824\n","Batch [14/105] Loss: 20.377534866333008\n","Batch [15/105] Loss: 11.587084770202637\n","Batch [16/105] Loss: 13.062013626098633\n","Batch [17/105] Loss: 16.398696899414062\n","Batch [18/105] Loss: 15.953749656677246\n","Batch [19/105] Loss: 9.66390609741211\n","Batch [20/105] Loss: 10.043067932128906\n","Batch [21/105] Loss: 8.390380859375\n","Batch [22/105] Loss: 70.64340209960938\n","Batch [23/105] Loss: 8.336512565612793\n","Batch [24/105] Loss: 10.446793556213379\n","Batch [25/105] Loss: 20.355056762695312\n","Batch [26/105] Loss: 25.087709426879883\n","Batch [27/105] Loss: 67.12232208251953\n","Batch [28/105] Loss: 16.072599411010742\n","Batch [29/105] Loss: 21.336502075195312\n","Batch [30/105] Loss: 20.317975997924805\n","Batch [31/105] Loss: 19.507917404174805\n","Batch [32/105] Loss: 10.643129348754883\n","Batch [33/105] Loss: 12.962127685546875\n","Batch [34/105] Loss: 10.207942008972168\n","Batch [35/105] Loss: 16.231735229492188\n","Batch [36/105] Loss: 10.749420166015625\n","Batch [37/105] Loss: 41.55807876586914\n","Batch [38/105] Loss: 22.142812728881836\n","Batch [39/105] Loss: 5.112048149108887\n","Batch [40/105] Loss: 16.95832633972168\n","Batch [41/105] Loss: 5.848757743835449\n","Batch [42/105] Loss: 28.162094116210938\n","Batch [43/105] Loss: 22.83441162109375\n","Batch [44/105] Loss: 16.61110496520996\n","Batch [45/105] Loss: 10.93078899383545\n","Batch [46/105] Loss: 23.57577133178711\n","Batch [47/105] Loss: 12.801202774047852\n","Batch [48/105] Loss: 11.371295928955078\n","Batch [49/105] Loss: 12.117674827575684\n","Batch [50/105] Loss: 17.30598258972168\n","Batch [51/105] Loss: 35.771183013916016\n","Batch [52/105] Loss: 12.990453720092773\n","Batch [53/105] Loss: 3.688889503479004\n","Batch [54/105] Loss: 19.934471130371094\n","Batch [55/105] Loss: 4.950901031494141\n","Batch [56/105] Loss: 47.54289627075195\n","Batch [57/105] Loss: 14.373189926147461\n","Batch [58/105] Loss: 22.024394989013672\n","Batch [59/105] Loss: 58.802490234375\n","Batch [60/105] Loss: 21.659957885742188\n","Batch [61/105] Loss: 5.464818000793457\n","Batch [62/105] Loss: 9.352940559387207\n","Batch [63/105] Loss: 32.5465087890625\n","Batch [64/105] Loss: 13.241355895996094\n","Batch [65/105] Loss: 7.8904218673706055\n","Batch [66/105] Loss: 25.944507598876953\n","Batch [67/105] Loss: 17.967775344848633\n","Batch [68/105] Loss: 11.841991424560547\n","Batch [69/105] Loss: 10.450102806091309\n","Batch [70/105] Loss: 9.114728927612305\n","Batch [71/105] Loss: 45.85093688964844\n","Batch [72/105] Loss: 10.722006797790527\n","Batch [73/105] Loss: 7.0210723876953125\n","Batch [74/105] Loss: 15.127130508422852\n","Batch [75/105] Loss: 16.345561981201172\n","Batch [76/105] Loss: 32.402278900146484\n","Batch [77/105] Loss: 19.395111083984375\n","Batch [78/105] Loss: 6.6472086906433105\n","Batch [79/105] Loss: 15.055449485778809\n","Batch [80/105] Loss: 26.246990203857422\n","Batch [81/105] Loss: 13.377351760864258\n","Batch [82/105] Loss: 31.163490295410156\n","Batch [83/105] Loss: 7.642757892608643\n","Batch [84/105] Loss: 32.33511734008789\n","Batch [85/105] Loss: 9.590826034545898\n","Batch [86/105] Loss: 9.857693672180176\n","Batch [87/105] Loss: 6.825468063354492\n","Batch [88/105] Loss: 17.871219635009766\n","Batch [89/105] Loss: 40.11900329589844\n","Batch [90/105] Loss: 18.928489685058594\n","Batch [91/105] Loss: 16.557363510131836\n","Batch [92/105] Loss: 16.09210205078125\n","Batch [93/105] Loss: 27.28728675842285\n","Batch [94/105] Loss: 53.76923751831055\n","Batch [95/105] Loss: 8.767118453979492\n","Batch [96/105] Loss: 16.926700592041016\n","Batch [97/105] Loss: 6.609627723693848\n","Batch [98/105] Loss: 11.39344596862793\n","Batch [99/105] Loss: 15.644554138183594\n","Batch [100/105] Loss: 29.347702026367188\n","Batch [101/105] Loss: 11.186415672302246\n","Batch [102/105] Loss: 25.11699676513672\n","Batch [103/105] Loss: 16.925800323486328\n","Batch [104/105] Loss: 20.926427841186523\n","Batch [105/105] Loss: 13.997221946716309\n","Epoch [45/50], Loss: 19.142064780280705\n","Batch [1/105] Loss: 17.991283416748047\n","Batch [2/105] Loss: 5.522675514221191\n","Batch [3/105] Loss: 31.843589782714844\n","Batch [4/105] Loss: 25.033992767333984\n","Batch [5/105] Loss: 8.501718521118164\n","Batch [6/105] Loss: 15.581855773925781\n","Batch [7/105] Loss: 11.424675941467285\n","Batch [8/105] Loss: 19.364044189453125\n","Batch [9/105] Loss: 20.821563720703125\n","Batch [10/105] Loss: 7.3132429122924805\n","Batch [11/105] Loss: 18.842830657958984\n","Batch [12/105] Loss: 21.145172119140625\n","Batch [13/105] Loss: 9.199456214904785\n","Batch [14/105] Loss: 4.990784645080566\n","Batch [15/105] Loss: 20.655261993408203\n","Batch [16/105] Loss: 46.12523651123047\n","Batch [17/105] Loss: 11.392081260681152\n","Batch [18/105] Loss: 32.45607376098633\n","Batch [19/105] Loss: 15.557373046875\n","Batch [20/105] Loss: 10.930890083312988\n","Batch [21/105] Loss: 11.627263069152832\n","Batch [22/105] Loss: 14.925989151000977\n","Batch [23/105] Loss: 12.217717170715332\n","Batch [24/105] Loss: 12.744200706481934\n","Batch [25/105] Loss: 16.431987762451172\n","Batch [26/105] Loss: 13.266790390014648\n","Batch [27/105] Loss: 24.325542449951172\n","Batch [28/105] Loss: 18.13896942138672\n","Batch [29/105] Loss: 62.793907165527344\n","Batch [30/105] Loss: 21.789836883544922\n","Batch [31/105] Loss: 11.153650283813477\n","Batch [32/105] Loss: 11.250560760498047\n","Batch [33/105] Loss: 11.676307678222656\n","Batch [34/105] Loss: 25.89031982421875\n","Batch [35/105] Loss: 21.67401123046875\n","Batch [36/105] Loss: 21.397594451904297\n","Batch [37/105] Loss: 10.433791160583496\n","Batch [38/105] Loss: 9.706069946289062\n","Batch [39/105] Loss: 4.97125768661499\n","Batch [40/105] Loss: 13.04903793334961\n","Batch [41/105] Loss: 4.966070175170898\n","Batch [42/105] Loss: 30.24932098388672\n","Batch [43/105] Loss: 8.468315124511719\n","Batch [44/105] Loss: 8.322184562683105\n","Batch [45/105] Loss: 7.8839850425720215\n","Batch [46/105] Loss: 19.263578414916992\n","Batch [47/105] Loss: 13.82046127319336\n","Batch [48/105] Loss: 21.45168113708496\n","Batch [49/105] Loss: 5.800478935241699\n","Batch [50/105] Loss: 24.876386642456055\n","Batch [51/105] Loss: 31.509746551513672\n","Batch [52/105] Loss: 5.204907417297363\n","Batch [53/105] Loss: 22.980789184570312\n","Batch [54/105] Loss: 14.993301391601562\n","Batch [55/105] Loss: 34.10344696044922\n","Batch [56/105] Loss: 7.672608852386475\n","Batch [57/105] Loss: 57.996299743652344\n","Batch [58/105] Loss: 14.823110580444336\n","Batch [59/105] Loss: 11.19454574584961\n","Batch [60/105] Loss: 13.389466285705566\n","Batch [61/105] Loss: 10.085834503173828\n","Batch [62/105] Loss: 22.26746368408203\n","Batch [63/105] Loss: 17.348377227783203\n","Batch [64/105] Loss: 10.47915267944336\n","Batch [65/105] Loss: 10.426824569702148\n","Batch [66/105] Loss: 9.864274024963379\n","Batch [67/105] Loss: 5.916772842407227\n","Batch [68/105] Loss: 34.1786994934082\n","Batch [69/105] Loss: 19.534509658813477\n","Batch [70/105] Loss: 23.231096267700195\n","Batch [71/105] Loss: 15.159303665161133\n","Batch [72/105] Loss: 21.104705810546875\n","Batch [73/105] Loss: 15.859125137329102\n","Batch [74/105] Loss: 41.359989166259766\n","Batch [75/105] Loss: 13.446045875549316\n","Batch [76/105] Loss: 35.855140686035156\n","Batch [77/105] Loss: 8.035329818725586\n","Batch [78/105] Loss: 17.793975830078125\n","Batch [79/105] Loss: 3.837207794189453\n","Batch [80/105] Loss: 12.677958488464355\n","Batch [81/105] Loss: 14.227910995483398\n","Batch [82/105] Loss: 13.117114067077637\n","Batch [83/105] Loss: 13.834915161132812\n","Batch [84/105] Loss: 23.166067123413086\n","Batch [85/105] Loss: 14.023134231567383\n","Batch [86/105] Loss: 8.03527545928955\n","Batch [87/105] Loss: 19.67544937133789\n","Batch [88/105] Loss: 20.382625579833984\n","Batch [89/105] Loss: 8.029485702514648\n","Batch [90/105] Loss: 14.023478507995605\n","Batch [91/105] Loss: 19.407325744628906\n","Batch [92/105] Loss: 17.076892852783203\n","Batch [93/105] Loss: 19.78983497619629\n","Batch [94/105] Loss: 3.105879306793213\n","Batch [95/105] Loss: 9.791924476623535\n","Batch [96/105] Loss: 55.631343841552734\n","Batch [97/105] Loss: 11.365211486816406\n","Batch [98/105] Loss: 54.10137176513672\n","Batch [99/105] Loss: 15.65295696258545\n","Batch [100/105] Loss: 9.294227600097656\n","Batch [101/105] Loss: 41.42518615722656\n","Batch [102/105] Loss: 25.62476348876953\n","Batch [103/105] Loss: 44.501365661621094\n","Batch [104/105] Loss: 7.03989315032959\n","Batch [105/105] Loss: 8.05179214477539\n","Epoch [46/50], Loss: 18.113966723850794\n","Batch [1/105] Loss: 36.15909194946289\n","Batch [2/105] Loss: 48.167015075683594\n","Batch [3/105] Loss: 15.928230285644531\n","Batch [4/105] Loss: 11.03497314453125\n","Batch [5/105] Loss: 16.8371524810791\n","Batch [6/105] Loss: 11.767881393432617\n","Batch [7/105] Loss: 9.315327644348145\n","Batch [8/105] Loss: 40.59154510498047\n","Batch [9/105] Loss: 7.828182220458984\n","Batch [10/105] Loss: 14.596110343933105\n","Batch [11/105] Loss: 22.02690315246582\n","Batch [12/105] Loss: 8.664375305175781\n","Batch [13/105] Loss: 7.427307605743408\n","Batch [14/105] Loss: 10.39358139038086\n","Batch [15/105] Loss: 61.04587173461914\n","Batch [16/105] Loss: 8.112606048583984\n","Batch [17/105] Loss: 23.431955337524414\n","Batch [18/105] Loss: 37.88917922973633\n","Batch [19/105] Loss: 7.316610336303711\n","Batch [20/105] Loss: 53.29896545410156\n","Batch [21/105] Loss: 19.565799713134766\n","Batch [22/105] Loss: 12.462862968444824\n","Batch [23/105] Loss: 32.44243621826172\n","Batch [24/105] Loss: 25.881938934326172\n","Batch [25/105] Loss: 31.244403839111328\n","Batch [26/105] Loss: 10.494955062866211\n","Batch [27/105] Loss: 22.365680694580078\n","Batch [28/105] Loss: 20.17638397216797\n","Batch [29/105] Loss: 12.16158676147461\n","Batch [30/105] Loss: 27.01312255859375\n","Batch [31/105] Loss: 13.552362442016602\n","Batch [32/105] Loss: 16.938692092895508\n","Batch [33/105] Loss: 24.545578002929688\n","Batch [34/105] Loss: 13.011944770812988\n","Batch [35/105] Loss: 48.779598236083984\n","Batch [36/105] Loss: 30.890819549560547\n","Batch [37/105] Loss: 10.070357322692871\n","Batch [38/105] Loss: 29.349058151245117\n","Batch [39/105] Loss: 61.80588912963867\n","Batch [40/105] Loss: 25.380340576171875\n","Batch [41/105] Loss: 9.22554874420166\n","Batch [42/105] Loss: 6.711309432983398\n","Batch [43/105] Loss: 7.921507835388184\n","Batch [44/105] Loss: 10.436168670654297\n","Batch [45/105] Loss: 33.47771453857422\n","Batch [46/105] Loss: 20.015357971191406\n","Batch [47/105] Loss: 21.578052520751953\n","Batch [48/105] Loss: 11.007599830627441\n","Batch [49/105] Loss: 14.197056770324707\n","Batch [50/105] Loss: 29.685279846191406\n","Batch [51/105] Loss: 11.16769027709961\n","Batch [52/105] Loss: 28.1109676361084\n","Batch [53/105] Loss: 25.30984878540039\n","Batch [54/105] Loss: 16.07269287109375\n","Batch [55/105] Loss: 26.792064666748047\n","Batch [56/105] Loss: 19.800251007080078\n","Batch [57/105] Loss: 12.36356258392334\n","Batch [58/105] Loss: 29.78430938720703\n","Batch [59/105] Loss: 9.11452865600586\n","Batch [60/105] Loss: 10.587998390197754\n","Batch [61/105] Loss: 7.463691711425781\n","Batch [62/105] Loss: 37.60800552368164\n","Batch [63/105] Loss: 13.80727767944336\n","Batch [64/105] Loss: 10.487773895263672\n","Batch [65/105] Loss: 31.20047378540039\n","Batch [66/105] Loss: 31.980253219604492\n","Batch [67/105] Loss: 13.082680702209473\n","Batch [68/105] Loss: 31.201841354370117\n","Batch [69/105] Loss: 51.59912109375\n","Batch [70/105] Loss: 9.957972526550293\n","Batch [71/105] Loss: 16.977764129638672\n","Batch [72/105] Loss: 4.141798973083496\n","Batch [73/105] Loss: 12.193765640258789\n","Batch [74/105] Loss: 34.178009033203125\n","Batch [75/105] Loss: 11.402374267578125\n","Batch [76/105] Loss: 17.235578536987305\n","Batch [77/105] Loss: 18.952829360961914\n","Batch [78/105] Loss: 17.233142852783203\n","Batch [79/105] Loss: 31.408838272094727\n","Batch [80/105] Loss: 23.797266006469727\n","Batch [81/105] Loss: 8.043140411376953\n","Batch [82/105] Loss: 15.272798538208008\n","Batch [83/105] Loss: 16.53251075744629\n","Batch [84/105] Loss: 9.399140357971191\n","Batch [85/105] Loss: 26.862628936767578\n","Batch [86/105] Loss: 13.16032886505127\n","Batch [87/105] Loss: 19.299697875976562\n","Batch [88/105] Loss: 3.802985906600952\n","Batch [89/105] Loss: 4.519723892211914\n","Batch [90/105] Loss: 16.985410690307617\n","Batch [91/105] Loss: 13.489160537719727\n","Batch [92/105] Loss: 22.62908172607422\n","Batch [93/105] Loss: 9.797587394714355\n","Batch [94/105] Loss: 14.137662887573242\n","Batch [95/105] Loss: 18.933956146240234\n","Batch [96/105] Loss: 19.002559661865234\n","Batch [97/105] Loss: 20.00366973876953\n","Batch [98/105] Loss: 14.561790466308594\n","Batch [99/105] Loss: 50.582157135009766\n","Batch [100/105] Loss: 13.634716033935547\n","Batch [101/105] Loss: 44.84918212890625\n","Batch [102/105] Loss: 10.205893516540527\n","Batch [103/105] Loss: 11.274887084960938\n","Batch [104/105] Loss: 17.025981903076172\n","Batch [105/105] Loss: 16.511137008666992\n","Epoch [47/50], Loss: 20.473851760228474\n","Batch [1/105] Loss: 33.87725830078125\n","Batch [2/105] Loss: 28.14813232421875\n","Batch [3/105] Loss: 19.64667320251465\n","Batch [4/105] Loss: 14.612020492553711\n","Batch [5/105] Loss: 8.066594123840332\n","Batch [6/105] Loss: 18.279104232788086\n","Batch [7/105] Loss: 19.45050048828125\n","Batch [8/105] Loss: 23.790813446044922\n","Batch [9/105] Loss: 4.629327774047852\n","Batch [10/105] Loss: 14.614131927490234\n","Batch [11/105] Loss: 37.75608825683594\n","Batch [12/105] Loss: 11.784663200378418\n","Batch [13/105] Loss: 9.772918701171875\n","Batch [14/105] Loss: 26.999624252319336\n","Batch [15/105] Loss: 9.512823104858398\n","Batch [16/105] Loss: 19.20380401611328\n","Batch [17/105] Loss: 21.11216926574707\n","Batch [18/105] Loss: 22.886722564697266\n","Batch [19/105] Loss: 13.689584732055664\n","Batch [20/105] Loss: 14.062555313110352\n","Batch [21/105] Loss: 27.812583923339844\n","Batch [22/105] Loss: 7.349536895751953\n","Batch [23/105] Loss: 22.915260314941406\n","Batch [24/105] Loss: 13.021771430969238\n","Batch [25/105] Loss: 3.331125497817993\n","Batch [26/105] Loss: 19.27938461303711\n","Batch [27/105] Loss: 46.61581802368164\n","Batch [28/105] Loss: 12.232799530029297\n","Batch [29/105] Loss: 6.95013427734375\n","Batch [30/105] Loss: 9.96703815460205\n","Batch [31/105] Loss: 40.10757827758789\n","Batch [32/105] Loss: 24.072858810424805\n","Batch [33/105] Loss: 16.118209838867188\n","Batch [34/105] Loss: 22.567485809326172\n","Batch [35/105] Loss: 15.525962829589844\n","Batch [36/105] Loss: 8.413593292236328\n","Batch [37/105] Loss: 26.76120376586914\n","Batch [38/105] Loss: 22.017501831054688\n","Batch [39/105] Loss: 44.55202865600586\n","Batch [40/105] Loss: 13.548484802246094\n","Batch [41/105] Loss: 15.703941345214844\n","Batch [42/105] Loss: 29.176183700561523\n","Batch [43/105] Loss: 70.579833984375\n","Batch [44/105] Loss: 22.507280349731445\n","Batch [45/105] Loss: 5.054412841796875\n","Batch [46/105] Loss: 24.746932983398438\n","Batch [47/105] Loss: 47.128379821777344\n","Batch [48/105] Loss: 33.63426971435547\n","Batch [49/105] Loss: 18.299732208251953\n","Batch [50/105] Loss: 9.360809326171875\n","Batch [51/105] Loss: 21.912742614746094\n","Batch [52/105] Loss: 18.010520935058594\n","Batch [53/105] Loss: 7.808920860290527\n","Batch [54/105] Loss: 17.33673095703125\n","Batch [55/105] Loss: 12.876068115234375\n","Batch [56/105] Loss: 7.829108238220215\n","Batch [57/105] Loss: 11.766996383666992\n","Batch [58/105] Loss: 25.37371826171875\n","Batch [59/105] Loss: 14.303000450134277\n","Batch [60/105] Loss: 16.773263931274414\n","Batch [61/105] Loss: 13.19251823425293\n","Batch [62/105] Loss: 30.4420166015625\n","Batch [63/105] Loss: 28.361093521118164\n","Batch [64/105] Loss: 8.610840797424316\n","Batch [65/105] Loss: 14.9224214553833\n","Batch [66/105] Loss: 5.803643226623535\n","Batch [67/105] Loss: 18.098094940185547\n","Batch [68/105] Loss: 34.087257385253906\n","Batch [69/105] Loss: 9.272906303405762\n","Batch [70/105] Loss: 15.761360168457031\n","Batch [71/105] Loss: 25.71137809753418\n","Batch [72/105] Loss: 15.623980522155762\n","Batch [73/105] Loss: 6.207459449768066\n","Batch [74/105] Loss: 5.298042297363281\n","Batch [75/105] Loss: 31.517425537109375\n","Batch [76/105] Loss: 9.757915496826172\n","Batch [77/105] Loss: 22.604963302612305\n","Batch [78/105] Loss: 23.756792068481445\n","Batch [79/105] Loss: 54.644813537597656\n","Batch [80/105] Loss: 19.04399871826172\n","Batch [81/105] Loss: 18.978023529052734\n","Batch [82/105] Loss: 14.038955688476562\n","Batch [83/105] Loss: 8.578439712524414\n","Batch [84/105] Loss: 23.44155502319336\n","Batch [85/105] Loss: 41.70109176635742\n","Batch [86/105] Loss: 27.027353286743164\n","Batch [87/105] Loss: 43.99004364013672\n","Batch [88/105] Loss: 12.226234436035156\n","Batch [89/105] Loss: 15.564212799072266\n","Batch [90/105] Loss: 74.22250366210938\n","Batch [91/105] Loss: 19.735122680664062\n","Batch [92/105] Loss: 57.448646545410156\n","Batch [93/105] Loss: 10.029821395874023\n","Batch [94/105] Loss: 12.289079666137695\n","Batch [95/105] Loss: 21.758996963500977\n","Batch [96/105] Loss: 16.325668334960938\n","Batch [97/105] Loss: 21.520366668701172\n","Batch [98/105] Loss: 19.537582397460938\n","Batch [99/105] Loss: 16.67154884338379\n","Batch [100/105] Loss: 36.93818664550781\n","Batch [101/105] Loss: 25.396060943603516\n","Batch [102/105] Loss: 20.520278930664062\n","Batch [103/105] Loss: 5.577798843383789\n","Batch [104/105] Loss: 7.357405185699463\n","Batch [105/105] Loss: 9.362996101379395\n","Epoch [48/50], Loss: 20.744720120657057\n","Batch [1/105] Loss: 6.593146324157715\n","Batch [2/105] Loss: 31.204524993896484\n","Batch [3/105] Loss: 47.97191619873047\n","Batch [4/105] Loss: 9.27563762664795\n","Batch [5/105] Loss: 5.481168746948242\n","Batch [6/105] Loss: 18.16460609436035\n","Batch [7/105] Loss: 12.344246864318848\n","Batch [8/105] Loss: 62.6602783203125\n","Batch [9/105] Loss: 10.794952392578125\n","Batch [10/105] Loss: 18.023101806640625\n","Batch [11/105] Loss: 13.081351280212402\n","Batch [12/105] Loss: 12.951484680175781\n","Batch [13/105] Loss: 9.836763381958008\n","Batch [14/105] Loss: 17.149566650390625\n","Batch [15/105] Loss: 18.084259033203125\n","Batch [16/105] Loss: 12.592706680297852\n","Batch [17/105] Loss: 17.785480499267578\n","Batch [18/105] Loss: 12.307263374328613\n","Batch [19/105] Loss: 8.824145317077637\n","Batch [20/105] Loss: 12.356645584106445\n","Batch [21/105] Loss: 4.671679496765137\n","Batch [22/105] Loss: 21.282020568847656\n","Batch [23/105] Loss: 58.75934982299805\n","Batch [24/105] Loss: 8.757787704467773\n","Batch [25/105] Loss: 18.22844886779785\n","Batch [26/105] Loss: 7.50350284576416\n","Batch [27/105] Loss: 23.836074829101562\n","Batch [28/105] Loss: 9.934332847595215\n","Batch [29/105] Loss: 8.1422119140625\n","Batch [30/105] Loss: 20.257457733154297\n","Batch [31/105] Loss: 76.7330551147461\n","Batch [32/105] Loss: 21.734325408935547\n","Batch [33/105] Loss: 20.41091537475586\n","Batch [34/105] Loss: 21.229825973510742\n","Batch [35/105] Loss: 16.92535400390625\n","Batch [36/105] Loss: 17.124834060668945\n","Batch [37/105] Loss: 12.532564163208008\n","Batch [38/105] Loss: 15.244577407836914\n","Batch [39/105] Loss: 9.854089736938477\n","Batch [40/105] Loss: 63.325992584228516\n","Batch [41/105] Loss: 39.559783935546875\n","Batch [42/105] Loss: 25.7629451751709\n","Batch [43/105] Loss: 12.011333465576172\n","Batch [44/105] Loss: 13.158882141113281\n","Batch [45/105] Loss: 28.619531631469727\n","Batch [46/105] Loss: 7.420825004577637\n","Batch [47/105] Loss: 60.79379653930664\n","Batch [48/105] Loss: 65.75611877441406\n","Batch [49/105] Loss: 14.87503433227539\n","Batch [50/105] Loss: 15.283530235290527\n","Batch [51/105] Loss: 27.542343139648438\n","Batch [52/105] Loss: 7.02834939956665\n","Batch [53/105] Loss: 26.748210906982422\n","Batch [54/105] Loss: 35.18761444091797\n","Batch [55/105] Loss: 13.082905769348145\n","Batch [56/105] Loss: 25.521747589111328\n","Batch [57/105] Loss: 14.962945938110352\n","Batch [58/105] Loss: 14.382129669189453\n","Batch [59/105] Loss: 11.02898120880127\n","Batch [60/105] Loss: 23.862564086914062\n","Batch [61/105] Loss: 10.493619918823242\n","Batch [62/105] Loss: 9.66110897064209\n","Batch [63/105] Loss: 8.289306640625\n","Batch [64/105] Loss: 12.444208145141602\n","Batch [65/105] Loss: 29.2014217376709\n","Batch [66/105] Loss: 21.963191986083984\n","Batch [67/105] Loss: 9.301284790039062\n","Batch [68/105] Loss: 9.023482322692871\n","Batch [69/105] Loss: 14.443374633789062\n","Batch [70/105] Loss: 20.95228385925293\n","Batch [71/105] Loss: 36.95112991333008\n","Batch [72/105] Loss: 10.269804000854492\n","Batch [73/105] Loss: 32.66878128051758\n","Batch [74/105] Loss: 14.132941246032715\n","Batch [75/105] Loss: 14.866089820861816\n","Batch [76/105] Loss: 14.009255409240723\n","Batch [77/105] Loss: 13.390932083129883\n","Batch [78/105] Loss: 17.145614624023438\n","Batch [79/105] Loss: 14.641115188598633\n","Batch [80/105] Loss: 62.28654861450195\n","Batch [81/105] Loss: 20.007949829101562\n","Batch [82/105] Loss: 11.897249221801758\n","Batch [83/105] Loss: 28.08681869506836\n","Batch [84/105] Loss: 45.65791320800781\n","Batch [85/105] Loss: 23.367490768432617\n","Batch [86/105] Loss: 6.717768669128418\n","Batch [87/105] Loss: 20.54474639892578\n","Batch [88/105] Loss: 33.08989715576172\n","Batch [89/105] Loss: 33.007389068603516\n","Batch [90/105] Loss: 16.944116592407227\n","Batch [91/105] Loss: 33.94557571411133\n","Batch [92/105] Loss: 18.286151885986328\n","Batch [93/105] Loss: 42.99066162109375\n","Batch [94/105] Loss: 16.744247436523438\n","Batch [95/105] Loss: 18.191606521606445\n","Batch [96/105] Loss: 14.521331787109375\n","Batch [97/105] Loss: 9.654417991638184\n","Batch [98/105] Loss: 20.787132263183594\n","Batch [99/105] Loss: 9.557636260986328\n","Batch [100/105] Loss: 47.54600524902344\n","Batch [101/105] Loss: 6.991851329803467\n","Batch [102/105] Loss: 27.753955841064453\n","Batch [103/105] Loss: 6.06203031539917\n","Batch [104/105] Loss: 12.636423110961914\n","Batch [105/105] Loss: 7.87846040725708\n","Epoch [49/50], Loss: 21.005386116391136\n","Batch [1/105] Loss: 10.252965927124023\n","Batch [2/105] Loss: 18.363388061523438\n","Batch [3/105] Loss: 38.32822799682617\n","Batch [4/105] Loss: 12.765193939208984\n","Batch [5/105] Loss: 25.268657684326172\n","Batch [6/105] Loss: 14.327802658081055\n","Batch [7/105] Loss: 39.6460075378418\n","Batch [8/105] Loss: 18.865680694580078\n","Batch [9/105] Loss: 8.124675750732422\n","Batch [10/105] Loss: 18.115747451782227\n","Batch [11/105] Loss: 7.816895961761475\n","Batch [12/105] Loss: 44.11479187011719\n","Batch [13/105] Loss: 9.604663848876953\n","Batch [14/105] Loss: 16.794174194335938\n","Batch [15/105] Loss: 34.79987716674805\n","Batch [16/105] Loss: 61.08860397338867\n","Batch [17/105] Loss: 8.087458610534668\n","Batch [18/105] Loss: 23.266504287719727\n","Batch [19/105] Loss: 35.96070861816406\n","Batch [20/105] Loss: 17.095966339111328\n","Batch [21/105] Loss: 16.480140686035156\n","Batch [22/105] Loss: 7.316869735717773\n","Batch [23/105] Loss: 12.272123336791992\n","Batch [24/105] Loss: 6.500669956207275\n","Batch [25/105] Loss: 12.132425308227539\n","Batch [26/105] Loss: 14.204519271850586\n","Batch [27/105] Loss: 5.605974197387695\n","Batch [28/105] Loss: 4.850926399230957\n","Batch [29/105] Loss: 27.033517837524414\n","Batch [30/105] Loss: 10.36861801147461\n","Batch [31/105] Loss: 21.97979736328125\n","Batch [32/105] Loss: 20.796781539916992\n","Batch [33/105] Loss: 21.439712524414062\n","Batch [34/105] Loss: 24.389480590820312\n","Batch [35/105] Loss: 3.8655200004577637\n","Batch [36/105] Loss: 41.823246002197266\n","Batch [37/105] Loss: 10.324176788330078\n","Batch [38/105] Loss: 20.747886657714844\n","Batch [39/105] Loss: 13.533502578735352\n","Batch [40/105] Loss: 14.10273551940918\n","Batch [41/105] Loss: 30.805889129638672\n","Batch [42/105] Loss: 19.231050491333008\n","Batch [43/105] Loss: 16.737709045410156\n","Batch [44/105] Loss: 22.802040100097656\n","Batch [45/105] Loss: 19.69524574279785\n","Batch [46/105] Loss: 15.448756217956543\n","Batch [47/105] Loss: 30.481468200683594\n","Batch [48/105] Loss: 107.8768081665039\n","Batch [49/105] Loss: 9.941272735595703\n","Batch [50/105] Loss: 16.574382781982422\n","Batch [51/105] Loss: 23.01248550415039\n","Batch [52/105] Loss: 16.365943908691406\n","Batch [53/105] Loss: 5.724001884460449\n","Batch [54/105] Loss: 5.3015594482421875\n","Batch [55/105] Loss: 21.143869400024414\n","Batch [56/105] Loss: 5.6169633865356445\n","Batch [57/105] Loss: 14.758159637451172\n","Batch [58/105] Loss: 5.042893886566162\n","Batch [59/105] Loss: 11.513813972473145\n","Batch [60/105] Loss: 14.059135437011719\n","Batch [61/105] Loss: 12.280051231384277\n","Batch [62/105] Loss: 20.94951629638672\n","Batch [63/105] Loss: 13.745640754699707\n","Batch [64/105] Loss: 12.58816909790039\n","Batch [65/105] Loss: 7.909149646759033\n","Batch [66/105] Loss: 20.55933380126953\n","Batch [67/105] Loss: 8.104656219482422\n","Batch [68/105] Loss: 20.941572189331055\n","Batch [69/105] Loss: 10.706324577331543\n","Batch [70/105] Loss: 4.502641677856445\n","Batch [71/105] Loss: 29.024974822998047\n","Batch [72/105] Loss: 19.480607986450195\n","Batch [73/105] Loss: 20.325855255126953\n","Batch [74/105] Loss: 15.989608764648438\n","Batch [75/105] Loss: 33.424137115478516\n","Batch [76/105] Loss: 10.034465789794922\n","Batch [77/105] Loss: 20.109272003173828\n","Batch [78/105] Loss: 12.465128898620605\n","Batch [79/105] Loss: 12.432056427001953\n","Batch [80/105] Loss: 16.61023712158203\n","Batch [81/105] Loss: 10.17411994934082\n","Batch [82/105] Loss: 12.157394409179688\n","Batch [83/105] Loss: 18.52411460876465\n","Batch [84/105] Loss: 11.876275062561035\n","Batch [85/105] Loss: 6.756016731262207\n","Batch [86/105] Loss: 20.881847381591797\n","Batch [87/105] Loss: 11.974498748779297\n","Batch [88/105] Loss: 12.52954387664795\n","Batch [89/105] Loss: 20.425243377685547\n","Batch [90/105] Loss: 10.419382095336914\n","Batch [91/105] Loss: 13.430864334106445\n","Batch [92/105] Loss: 50.51732635498047\n","Batch [93/105] Loss: 16.084672927856445\n","Batch [94/105] Loss: 19.81253433227539\n","Batch [95/105] Loss: 26.380542755126953\n","Batch [96/105] Loss: 1.7775535583496094\n","Batch [97/105] Loss: 21.554882049560547\n","Batch [98/105] Loss: 12.117189407348633\n","Batch [99/105] Loss: 10.426339149475098\n","Batch [100/105] Loss: 9.578522682189941\n","Batch [101/105] Loss: 43.95478820800781\n","Batch [102/105] Loss: 45.23706817626953\n","Batch [103/105] Loss: 20.622920989990234\n","Batch [104/105] Loss: 13.719423294067383\n","Batch [105/105] Loss: 7.418785572052002\n","Epoch [50/50], Loss: 18.620241101582845\n","Training finished!\n"]}]}]}