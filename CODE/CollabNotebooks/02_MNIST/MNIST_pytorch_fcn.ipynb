{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzj5cTsjYEBpQ4yNHz5gLZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MNIST implementat in retea neuroanala complet conectata"],"metadata":{"id":"jIvBzNtH5_CD"}},{"cell_type":"markdown","source":["MNIST (Modified National Institute of Standards and Technology) este un set de date foarte popular folosit pentru antrenarea și testarea algoritmilor de învățare automată și recunoaștere a imaginilor.\n","\n","**Ce conține setul de date?**\n","- Imagini alb-negru (tonuri de gri) de dimensiune 28x28 pixeli.\n","- Fiecare imagine conține o cifră scrisă de mână (de la 0 la 9).\n","- Imaginile sunt centrate și normalizate în dimensiune.\n","\n","**Structura datelor**\n","- 60.000 de imagini pentru antrenare (training).\n","- 10.000 de imagini pentru testare (testing).\n","- Fiecare imagine este asociată cu o etichetă (label) între 0 și 9, care indică cifra reprezentată.\n"],"metadata":{"id":"sAwZmYfg23NG"}},{"cell_type":"markdown","source":["## Initializarea collab, mnist, etc"],"metadata":{"id":"9S9dpsI5hBw7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"efv-N-eLg_ef"},"outputs":[],"source":["import google.colab\n","import sys\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from scipy.ndimage import grey_dilation\n","from pathlib import PureWindowsPath\n","from PIL import Image\n","import skimage.io as io\n","import skimage.color as color"]},{"cell_type":"code","source":["!pip install idx2numpy\n","!pip install import-ipynb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFQMvx_qwHz3","executionInfo":{"status":"ok","timestamp":1744994096495,"user_tz":-180,"elapsed":5631,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"e4e27d7a-0f31-43ee-d12f-e573e2b64624"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: idx2numpy in /usr/local/lib/python3.11/dist-packages (1.2.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from idx2numpy) (2.0.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from idx2numpy) (1.17.0)\n","Requirement already satisfied: import-ipynb in /usr/local/lib/python3.11/dist-packages (0.2)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from import-ipynb) (7.34.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from import-ipynb) (5.10.4)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (75.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (3.0.50)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->import-ipynb) (4.9.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->import-ipynb) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->import-ipynb) (4.23.0)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat->import-ipynb) (5.7.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.24.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (4.3.7)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->import-ipynb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->import-ipynb) (0.2.13)\n","Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->import-ipynb) (4.13.1)\n"]}]},{"cell_type":"markdown","source":["## Import biblioteci, etc."],"metadata":{"id":"fLIbMZFfhH6R"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","from google.colab.patches import cv2_imshow\n","from google.colab import files\n","import idx2numpy\n","\n","# Check Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"lhzGhclqvFIp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Incarcarea datelor"],"metadata":{"id":"TOiYnrLBNWuX"}},{"cell_type":"markdown","source":["Datele MNIST sunt stocate intr-un format compact indexat"],"metadata":{"id":"NXuWnAsUOIgx"}},{"cell_type":"code","source":["print(\"Upload the MNIST training images (train-images-idx3-ubyte)\")\n","uploaded_train_images = files.upload()  # Allows user to upload a file\n","# Get the first uploaded file\n","train_images_path = list(uploaded_train_images.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"zTbC8R9uNY1P","executionInfo":{"status":"ok","timestamp":1744993638818,"user_tz":-180,"elapsed":304734,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"dfd9178e-aad3-4be8-ce5c-fa5551364764"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload the MNIST training images (train-images-idx3-ubyte)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c71ec3e9-dbc9-4ffe-af9a-3f0690d53287\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c71ec3e9-dbc9-4ffe-af9a-3f0690d53287\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train-images-idx3-ubyte to train-images-idx3-ubyte\n"]}]},{"cell_type":"code","source":["print(\"Upload the MNIST training labels (train-labels-idx3-ubyte)\")\n","uploaded_train_labels = files.upload()  # Allows user to upload a file\n","# Get the first uploaded file\n","train_labels_path = list(uploaded_train_labels.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"4A04HH5FN2Rn","executionInfo":{"status":"ok","timestamp":1744993784943,"user_tz":-180,"elapsed":10795,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"273efb8d-3b9b-44ed-d9ff-b5aa5796e9b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload the MNIST training labels (train-images-idx3-ubyte)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-92a2a41f-293c-43ba-ad6d-6dc61b89b52a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-92a2a41f-293c-43ba-ad6d-6dc61b89b52a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving train-labels-idx1-ubyte to train-labels-idx1-ubyte\n"]}]},{"cell_type":"code","source":["print(\"Upload the MNIST testing images (t10k-images-idx3-ubyte)\")\n","uploaded_test_images = files.upload()  # Allows user to upload a file\n","# Get the first uploaded file\n","test_images_path = list(uploaded_test_images.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"9YUo8olQsSqo","executionInfo":{"status":"ok","timestamp":1744993855038,"user_tz":-180,"elapsed":62638,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"2724603e-52f4-49b5-ffcf-736b4f785850"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload the MNIST testing images (t10k-images-idx3-ubyte)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-df64316f-cf05-470c-b7c9-8e5726647e60\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-df64316f-cf05-470c-b7c9-8e5726647e60\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving t10k-images-idx3-ubyte to t10k-images-idx3-ubyte\n"]}]},{"cell_type":"code","source":["print(\"Upload the MNIST testing labels (t10k-labels-idx1-ubyte)\")\n","uploaded_test_labels = files.upload()  # Allows user to upload a file\n","# Get the first uploaded file\n","test_labels_path = list(uploaded_test_labels.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"GZsM4SFHsyZj","executionInfo":{"status":"ok","timestamp":1744993868843,"user_tz":-180,"elapsed":10183,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"a5a25bd3-a2ed-4dfd-b541-acc0a512bc53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload the MNIST testing labels (t10k-labels-idx1-ubyte)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a4abf9a4-5a04-4374-adfa-123b6f0526e9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a4abf9a4-5a04-4374-adfa-123b6f0526e9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving t10k-labels-idx1-ubyte to t10k-labels-idx1-ubyte\n"]}]},{"cell_type":"markdown","source":["## Conversia datelor din format idx in format numpy"],"metadata":{"id":"IL6QXMXAtOO5"}},{"cell_type":"code","source":["mnist_data = {}\n","\n","if os.path.isfile(train_images_path):\n","    mnist_data['train_images'] = idx2numpy.convert_from_file(train_images_path)\n","else:\n","      raise Exception (train_images_path + \" does not exist\")\n","\n","if os.path.isfile(train_labels_path):\n","    mnist_data['train_labels'] = idx2numpy.convert_from_file(train_labels_path)\n","else:\n","    raise Exception (train_labels_path + \" does not exist\")\n","\n","if os.path.isfile(test_images_path):\n","    mnist_data['test_images'] = idx2numpy.convert_from_file(test_images_path)\n","else:\n","    raise Exception (test_images_path + \" does not exist\")\n","\n","if os.path.isfile(test_labels_path):\n","    mnist_data['test_labels'] = idx2numpy.convert_from_file(test_labels_path)\n","else:\n","    raise Exception (test_labels_path + \" does not exist\")"],"metadata":{"id":"xMhr5_catNg6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["show_many_mnists este o functie care afiseaza sub formă de imagini câteva dintre cifrele stocate în baza de date MNIST."],"metadata":{"id":"fGjXmIaT3WM5"}},{"cell_type":"code","source":["def show_many_mnists(indices):\n","    if isinstance(indices, list):\n","        num_images = len(indices)\n","        rows = int(np.sqrt(num_images))\n","        cols = int(np.ceil(num_images / rows))\n","        fig, axes = plt.subplots(rows, cols, figsize=(cols * 1.5, rows * 1.5))\n","        for i, ax in enumerate(axes.flat):\n","            if i < num_images:\n","                # Get the image and label at the specified index\n","                image = mnist_data['train_images'][indices[i]]\n","                label = mnist_data['train_labels'][indices[i]]\n","\n","        \t\t# Display the image and label\n","                ax.imshow(image, cmap='gray')\n","                ax.set_title(f\"Label: {label}\")\n","                ax.axis('off')\n","            else:\n","                # Hide empty subplots\n","                ax.axis('off')\n","        plt.tight_layout()\n","        plt.show()\n","    else:\n","        raise Exception(\"The input argument has to be a list \" + type(indices))"],"metadata":{"id":"RxdnxARfwnkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["show_many_mnists([14,18,19,21,22,100])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"1Bng8PT_xHc9","executionInfo":{"status":"ok","timestamp":1744994355824,"user_tz":-180,"elapsed":913,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"5b859c6f-e776-49dd-af47-3abef1cab746"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 450x300 with 6 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Pregatirea datelor - dataloader"],"metadata":{"id":"Eays11uX6WBs"}},{"cell_type":"markdown","source":["Un DataLoader în PyTorch este o clasă care facilitează încărcarea datelor într-un model de învățare automată în timpul antrenării sau evaluării. Acesta oferă o abordare eficientă și convenabilă pentru a itera prin setul de date, împărțindu-l în loturi (batches) de dimensiuni fixe. Acest lucru ajută la gestionarea memoriei și la paralelizarea sarcinilor de prelucrare a datelor.\n","\n","Iată o descriere a fiecărei componente a unui DataLoader în PyTorch:\n","\n","1. **Setul de date (Dataset)**: Aceasta este clasa responsabilă pentru reprezentarea și accesul la datele tale. Aceasta trebuie să fie o subclasă a clasei torch.utils.data.Dataset și să implementeze metodele __len__ și __getitem__. În metoda __getitem__, se obțin datele corespunzătoare unui anumit index, de obicei returnând o pereche de intrare (exemplu) și etichetă.\n","\n","2. **Transformările datelor (transforms)**: Aceasta este o serie de transformări aplicate asupra datelor pentru a le pregăti înainte de utilizare în modelul de învățare automată. PyTorch furnizează clasa torchvision.transforms care conține o varietate de transformări comune, cum ar fi convertirea în tensori și normalizarea.\n","\n","3. **DataLoader**: Aceasta este clasa principală care preia setul de date și aplică diverse operații pentru a facilita procesul de încărcare a datelor. Parametrii importanți includ dimensiunea lotului (batch_size), opțiunea de amestecare (shuffle), numărul de procese pentru încărcarea datelor în paralel (num_workers), precum și alți parametri de control al memoriei și vitezei de încărcare.\n","\n","Un DataLoader îți permite să iterezi prin loturile de date folosind o buclă for obișnuită. În fiecare iterație, vei primi un lot de dimensiune batch_size care conține intrări și etichete corespunzătoare. Acest lucru îți permite să antrenezi sau să evaluezi modelul utilizând aceste loturi de date.\n","\n","Prin folosirea unui DataLoader, procesul de încărcare a datelor devine mai eficient și mai ușor de gestionat, permițându-ți să te concentrezi mai mult pe procesul de antrenare sau evaluare a modelului de învățare automată."],"metadata":{"id":"j_-qra_y1uIp"}},{"cell_type":"markdown","source":["transformarile implica conversia catre tensor (tipul de date cu care opereaza PyTorch) si normalizarea datelor"],"metadata":{"id":"BnjpypPT3IDP"}},{"cell_type":"markdown","source":["Datasetul trebuie implementat obiectual, ca o clasa care subclaseaza clasa Dataset si implementeaza (obligatoriu) metoda __getitem__ si, recomandat, metoda __len__"],"metadata":{"id":"BNwxvJzC4iBC"}},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))\n","])\n","\n","\n","class MNISTDataset(Dataset):\n","    def __init__(self, images, labels, transform=None):\n","        self.images = images\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, index):\n","        image = self.images[index]\n","        label = self.labels[index]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n"],"metadata":{"id":"CQtSkDz8hHUZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Hiperparametrii\n","\n","Hiperparametrii sunt variabile care influenteaza rezultatul modelarii"],"metadata":{"id":"jJuAaZvU5ZOE"}},{"cell_type":"code","source":["#forma rete;ei neuronale\n","input_size = 784\n","hidden_size = 500\n","num_classes = 10\n","\n","#parametrii de antrenament\n","num_epochs = 10\n","batch_size = 100\n","learning_rate = 0.001"],"metadata":{"id":"ZuYxY6Na5YPJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Pregatim datele pentru a fi incorporate in dataset si dataloader"],"metadata":{"id":"naUhHkxD5JGW"}},{"cell_type":"code","source":["train_images = mnist_data['train_images']\n","train_labels = mnist_data['train_labels']\n","test_images = mnist_data['test_images']\n","test_labels = mnist_data['test_labels']\n","\n","\n","train_dataset = MNISTDataset(train_images, train_labels, transform=transform)\n","test_dataset = MNISTDataset(test_images, test_labels, transform=transform)\n","\n","# Data loadere\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                          batch_size=1,\n","                                          shuffle=True)"],"metadata":{"id":"U89S-jKd5H3G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Construim reteaua neuronala"],"metadata":{"id":"w7IShcj86r6T"}},{"cell_type":"code","source":["# Fully connected neural network\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        return out\n","\n"],"metadata":{"id":"7GF6adLj6rNz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Antrenarea modelului"],"metadata":{"id":"N-M084Qv60TV"}},{"cell_type":"markdown","source":["## Criterion (functia de cost)\n","\n","În contextul rețelelor neuronale, criterion se referă la funcția de cost, adică metoda prin care modelul evaluează cât de greșite sunt predicțiile sale în comparație cu valorile reale. În linia\n","\n","```python\n","criterion = nn.CrossEntropyLoss()\n","```\n","\n","se utilizează funcția de pierdere Cross Entropy (entropie încrucișată), care este potrivită pentru probleme de clasificare multi-clasă. Aceasta compară distribuția de probabilități generată de model pentru fiecare clasă cu eticheta corectă și calculează o valoare numerică ce reflectă cât de bine sau prost se comportă modelul. Această valoare este apoi folosită de optimizator pentru a ajusta parametrii modelului în direcția corectă."],"metadata":{"id":"MG_ZF9wF4ePt"}},{"cell_type":"markdown","source":["## Optimizer\n","\n","În învățarea automată, un optimizer (optimizator) este un algoritm care ajustează automat valorile parametrilor unui model, cum ar fi ponderile unei rețele neuronale, pentru a reduce eroarea dintre predicțiile modelului și valorile reale. În linia\n","\n","```python\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","```\n","se creează un optimizator de tip Adam, care este o versiune avansată și eficientă a algoritmului de tip gradient descendent. Parametrul model.parameters() îi spune optimizatorului ce valori să actualizeze, iar lr=learning_rate stabilește cât de mari să fie pașii de ajustare la fiecare iterație."],"metadata":{"id":"GP5BHM7z4CRd"}},{"cell_type":"code","source":["\n","model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","\n","# Configuram functia de cost si optimizatorul\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Bucla propriu-zisa de antrenament\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        # redimensionează fiecare imagine dintr-o matrice 2D de dimensiune 28x28 într-un vector unidimensional de lungime 784 (28 * 28 = 784)\n","        # to(device) se foloseste pentru a copia structurile de date in memoria dispozitivului folosit, fie cpu, fie cuda (daca avem o placa nvidia la dispozitie)\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","\n","        # resetarea gradienților optimizatorului inainte de noua trecere prin model\n","        optimizer.zero_grad()\n","\n","        # Trcem imaginile prin model obtinand rezultatele in variabila outputs\n","        outputs = model(images)\n","\n","        # calculam pierderea (diferenta dintre detectie si adevar)\n","        loss = criterion(outputs, labels)\n","\n","        # recalcularea coeficientilor astfel incat sa se micsoreze valoarea functiei de cost.\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i+1) % 100 == 0:\n","            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzSUi688hhWM","executionInfo":{"status":"ok","timestamp":1744994514442,"user_tz":-180,"elapsed":132027,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"d8273522-d92a-4d1e-b505-f86c7de6dfe9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n","  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Step [100/600], Loss: 0.2985\n","Epoch [1/10], Step [200/600], Loss: 0.3675\n","Epoch [1/10], Step [300/600], Loss: 0.3416\n","Epoch [1/10], Step [400/600], Loss: 0.2151\n","Epoch [1/10], Step [500/600], Loss: 0.2770\n","Epoch [1/10], Step [600/600], Loss: 0.2441\n","Epoch [2/10], Step [100/600], Loss: 0.1468\n","Epoch [2/10], Step [200/600], Loss: 0.1020\n","Epoch [2/10], Step [300/600], Loss: 0.0827\n","Epoch [2/10], Step [400/600], Loss: 0.0938\n","Epoch [2/10], Step [500/600], Loss: 0.0752\n","Epoch [2/10], Step [600/600], Loss: 0.1025\n","Epoch [3/10], Step [100/600], Loss: 0.1293\n","Epoch [3/10], Step [200/600], Loss: 0.0770\n","Epoch [3/10], Step [300/600], Loss: 0.1129\n","Epoch [3/10], Step [400/600], Loss: 0.0550\n","Epoch [3/10], Step [500/600], Loss: 0.1093\n","Epoch [3/10], Step [600/600], Loss: 0.0891\n","Epoch [4/10], Step [100/600], Loss: 0.0882\n","Epoch [4/10], Step [200/600], Loss: 0.1540\n","Epoch [4/10], Step [300/600], Loss: 0.1135\n","Epoch [4/10], Step [400/600], Loss: 0.0905\n","Epoch [4/10], Step [500/600], Loss: 0.0954\n","Epoch [4/10], Step [600/600], Loss: 0.1474\n","Epoch [5/10], Step [100/600], Loss: 0.0770\n","Epoch [5/10], Step [200/600], Loss: 0.0744\n","Epoch [5/10], Step [300/600], Loss: 0.0401\n","Epoch [5/10], Step [400/600], Loss: 0.0825\n","Epoch [5/10], Step [500/600], Loss: 0.1010\n","Epoch [5/10], Step [600/600], Loss: 0.0955\n","Epoch [6/10], Step [100/600], Loss: 0.1348\n","Epoch [6/10], Step [200/600], Loss: 0.0522\n","Epoch [6/10], Step [300/600], Loss: 0.0290\n","Epoch [6/10], Step [400/600], Loss: 0.0282\n","Epoch [6/10], Step [500/600], Loss: 0.0177\n","Epoch [6/10], Step [600/600], Loss: 0.0448\n","Epoch [7/10], Step [100/600], Loss: 0.0583\n","Epoch [7/10], Step [200/600], Loss: 0.0221\n","Epoch [7/10], Step [300/600], Loss: 0.0348\n","Epoch [7/10], Step [400/600], Loss: 0.0195\n","Epoch [7/10], Step [500/600], Loss: 0.0428\n","Epoch [7/10], Step [600/600], Loss: 0.0508\n","Epoch [8/10], Step [100/600], Loss: 0.0524\n","Epoch [8/10], Step [200/600], Loss: 0.0343\n","Epoch [8/10], Step [300/600], Loss: 0.2145\n","Epoch [8/10], Step [400/600], Loss: 0.0349\n","Epoch [8/10], Step [500/600], Loss: 0.0318\n","Epoch [8/10], Step [600/600], Loss: 0.0028\n","Epoch [9/10], Step [100/600], Loss: 0.0082\n","Epoch [9/10], Step [200/600], Loss: 0.0730\n","Epoch [9/10], Step [300/600], Loss: 0.0258\n","Epoch [9/10], Step [400/600], Loss: 0.0281\n","Epoch [9/10], Step [500/600], Loss: 0.0465\n","Epoch [9/10], Step [600/600], Loss: 0.1320\n","Epoch [10/10], Step [100/600], Loss: 0.1072\n","Epoch [10/10], Step [200/600], Loss: 0.0133\n","Epoch [10/10], Step [300/600], Loss: 0.0324\n","Epoch [10/10], Step [400/600], Loss: 0.0107\n","Epoch [10/10], Step [500/600], Loss: 0.0994\n","Epoch [10/10], Step [600/600], Loss: 0.0947\n"]}]},{"cell_type":"markdown","source":["## Testarea modelului cu ajutorul datelor de test"],"metadata":{"id":"JmDq5wsF6848"}},{"cell_type":"code","source":["# Test the model\n","# In the test phase, don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    index = 0\n","    for images, labels in test_loader:\n","      if index > 2:\n","        break\n","      print('index: ' + str(index))\n","      images = images.reshape(-1, 28*28).to(device)\n","      labels = labels.to(device)\n","      outputs = model(images)\n","      print(outputs)\n","      print('label:' + str(labels))\n","      _, predicted = torch.max(outputs.data, 1)\n","      print(predicted)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","      index += 1\n","    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkykRHvM68I7","executionInfo":{"status":"ok","timestamp":1744994536251,"user_tz":-180,"elapsed":35,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"e1c76764-39eb-4349-c1ab-01bd060ad61e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["index: 0\n","tensor([[ -4.9841, -11.1406, -13.0419,   0.8043, -15.3319,  11.9045,  -9.1626,\n","          -5.9482,  -9.4631,  -1.5338]])\n","label:tensor([5], dtype=torch.uint8)\n","tensor([5])\n","index: 1\n","tensor([[ -7.1774,  -8.5769,  -7.3665,  -2.4492,  -9.8831,  -7.5285, -10.7964,\n","          -1.2610,   6.0498,  -0.5580]])\n","label:tensor([8], dtype=torch.uint8)\n","tensor([8])\n","index: 2\n","tensor([[ -4.2316,  -4.7761,  -6.4468, -18.1096,  -5.2432,  -5.7060,  -5.4533,\n","          -8.7862,  14.3751,  -3.7322]])\n","label:tensor([8], dtype=torch.uint8)\n","tensor([8])\n","Accuracy of the network on the 10000 test images: 100.0 %\n"]}]},{"cell_type":"markdown","source":["## Salvarea modelului"],"metadata":{"id":"DcHjJHA87cl_"}},{"cell_type":"code","source":["\n","# Save the model checkpoint\n","model_name = str(num_epochs) + '_model.ckpt'\n","print(model_name)\n","torch.save(model.state_dict(), model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B2SgJIwp7bwh","executionInfo":{"status":"ok","timestamp":1744994573622,"user_tz":-180,"elapsed":47,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"adbb6637-1aa7-4ff1-8bf4-60f96334c2d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10_model.ckpt\n"]}]},{"cell_type":"markdown","source":["# Verificarea imaginilor de test"],"metadata":{"id":"XuyN8tR_7tE7"}},{"cell_type":"markdown","source":["## Incarcarea modelului salvat"],"metadata":{"id":"KHWMvxPw7qJJ"}},{"cell_type":"code","source":["model_file = model_name #for now, this is the model that we have\n","\n","print(model_file)\n","mnist_model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n","\n","# Loss and optimizer\n","mnist_criterion = nn.CrossEntropyLoss()\n","mnist_optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","checkpoint = torch.load(model_file)\n","\n","mnist_model.load_state_dict(checkpoint)\n","mnist_model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTt-4L8g7zm2","executionInfo":{"status":"ok","timestamp":1744994603700,"user_tz":-180,"elapsed":60,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"bc90fa13-5a98-4f92-f879-beeefea3de50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10_model.ckpt\n"]},{"output_type":"execute_result","data":{"text/plain":["NeuralNet(\n","  (fc1): Linear(in_features=784, out_features=500, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print(\"Upload the test data\")\n","uploaded_test_file = files.upload()  # Allows user to upload a file\n","# Get the first uploaded file\n","test_file_path = list(uploaded_test_file.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"83SEwRhRyTih","executionInfo":{"status":"ok","timestamp":1744994834486,"user_tz":-180,"elapsed":5790,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"85037291-5d30-48d3-b2eb-4dcc5b9a8ea3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Upload the test data\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-3c54cf0d-827e-4f38-ac8f-051aacb915cf\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-3c54cf0d-827e-4f38-ac8f-051aacb915cf\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 6_1.png to 6_1.png\n"]}]},{"cell_type":"markdown","source":["Incarcarea imaginilor de test"],"metadata":{"id":"XnzGWjZldDgp"}},{"cell_type":"markdown","source":["## Testam doar una dintre imaginile de test"],"metadata":{"id":"7Jl9ilCkLpRr"}},{"cell_type":"code","source":["singular_image = io.imread(test_file_path)\n","\n","if singular_image.shape[2] == 4:\n","    # ditch the alpha channel\n","    singular_image = singular_image[:, :, :3]\n","    # convert to grayscale\n","    singular_image_gray = color.rgb2gray(singular_image)\n","elif singular_image.shape[2] == 2:\n","    # ditch the alpha channel\n","    singular_image_gray = singular_image[:, :, 0]\n","    plt.imshow(singular_image_gray, cmap='gray')\n","    plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"UUlRguNfuLeX","executionInfo":{"status":"ok","timestamp":1744994837298,"user_tz":-180,"elapsed":160,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"91b718b5-6a2f-4402-f895-164f9a04d886"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","singular_image_array = np.array(singular_image_gray)          #transformam imaginea inapoi la matrice\n","singular_image_flattened = singular_image_array.reshape(1,28*28)\n","\n","singular_image_flattened = transform(singular_image_flattened)\n","output = mnist_model(singular_image_flattened)\n","print(output)\n","_, predicted = torch.max(output.data[0], 1)\n","print(f\"Predicted: {predicted.item()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nn2D4Y88GvTP","executionInfo":{"status":"ok","timestamp":1744994840521,"user_tz":-180,"elapsed":22,"user":{"displayName":"Sorin Milutinovici","userId":"06090978200139614225"}},"outputId":"2a64ca40-b1aa-4c51-b537-4025704c92ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ -4.6453, -11.9559, -12.0460,  -0.7680, -10.6108,   7.6711,  -3.5713,\n","           -7.4012,  -2.0367,  -2.6809]]], grad_fn=<ViewBackward0>)\n","Predicted: 5\n"]}]}]}